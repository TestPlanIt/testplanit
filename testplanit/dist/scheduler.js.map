{
  "version": 3,
  "sources": ["../lib/queues.ts", "../lib/valkey.ts", "../lib/queueNames.ts", "../workers/forecastWorker.ts", "../lib/prisma.ts", "../services/repositoryCaseSync.ts", "../services/elasticsearchService.ts", "../env.js", "../services/elasticsearchIndexing.ts", "../utils/extractTextFromJson.ts", "../services/unifiedElasticsearchService.ts", "../services/testRunSearch.ts", "../services/sessionSearch.ts", "../services/sharedStepSearch.ts", "../services/issueSearch.ts", "../services/milestoneSearch.ts", "../services/projectSearch.ts", "../services/forecastService.ts", "../workers/notificationWorker.ts", "../scheduler.ts"],
  "sourcesContent": ["import { Queue } from \"bullmq\";\nimport valkeyConnection from \"./valkey\";\nimport {\n  FORECAST_QUEUE_NAME,\n  NOTIFICATION_QUEUE_NAME,\n  EMAIL_QUEUE_NAME,\n  SYNC_QUEUE_NAME,\n  TESTMO_IMPORT_QUEUE_NAME,\n  ELASTICSEARCH_REINDEX_QUEUE_NAME,\n} from \"./queueNames\";\n\n// Re-export queue names for backward compatibility\nexport {\n  FORECAST_QUEUE_NAME,\n  NOTIFICATION_QUEUE_NAME,\n  EMAIL_QUEUE_NAME,\n  SYNC_QUEUE_NAME,\n  TESTMO_IMPORT_QUEUE_NAME,\n  ELASTICSEARCH_REINDEX_QUEUE_NAME,\n};\n\nlet forecastQueue: Queue | null = null;\nlet notificationQueue: Queue | null = null;\nlet emailQueue: Queue | null = null;\nlet syncQueue: Queue | null = null;\nlet testmoImportQueue: Queue | null = null;\nlet elasticsearchReindexQueue: Queue | null = null;\n\n// Initialize queue only if Valkey connection exists\nif (valkeyConnection) {\n  // Create and export the forecast queue instance\n  forecastQueue = new Queue(FORECAST_QUEUE_NAME, {\n    connection: valkeyConnection,\n    defaultJobOptions: {\n      // Configuration for jobs in this queue (optional)\n      attempts: 3, // Number of times to retry a failed job\n      backoff: {\n        type: \"exponential\", // Exponential backoff strategy\n        delay: 5000, // Initial delay 5s\n      },\n      removeOnComplete: {\n        age: 3600 * 24 * 7, // keep up to 7 days\n        count: 1000, // keep up to 1000 jobs\n      },\n      removeOnFail: {\n        age: 3600 * 24 * 14, // keep up to 14 days\n      },\n    },\n  });\n\n  console.log(`Queue \"${FORECAST_QUEUE_NAME}\" initialized.`);\n\n  // Optional: Add basic event listeners for logging/monitoring\n  forecastQueue.on(\"error\", (error) => {\n    console.error(`Queue ${FORECAST_QUEUE_NAME} error:`, error);\n  });\n} else {\n  console.warn(\n    `Valkey connection not available, Queue \"${FORECAST_QUEUE_NAME}\" not initialized.`\n  );\n}\n\n// Initialize notification queue\nif (valkeyConnection) {\n  notificationQueue = new Queue(NOTIFICATION_QUEUE_NAME, {\n    connection: valkeyConnection,\n    defaultJobOptions: {\n      attempts: 3,\n      backoff: {\n        type: \"exponential\",\n        delay: 5000,\n      },\n      removeOnComplete: {\n        age: 3600 * 24 * 7, // keep up to 7 days\n        count: 1000,\n      },\n      removeOnFail: {\n        age: 3600 * 24 * 14, // keep up to 14 days\n      },\n    },\n  });\n\n  console.log(`Queue \"${NOTIFICATION_QUEUE_NAME}\" initialized.`);\n\n  notificationQueue.on(\"error\", (error) => {\n    console.error(`Queue ${NOTIFICATION_QUEUE_NAME} error:`, error);\n  });\n} else {\n  console.warn(\n    `Valkey connection not available, Queue \"${NOTIFICATION_QUEUE_NAME}\" not initialized.`\n  );\n}\n\n// Initialize email queue\nif (valkeyConnection) {\n  emailQueue = new Queue(EMAIL_QUEUE_NAME, {\n    connection: valkeyConnection,\n    defaultJobOptions: {\n      attempts: 5,\n      backoff: {\n        type: \"exponential\",\n        delay: 10000,\n      },\n      removeOnComplete: {\n        age: 3600 * 24 * 30, // keep up to 30 days\n        count: 5000,\n      },\n      removeOnFail: {\n        age: 3600 * 24 * 30, // keep up to 30 days\n      },\n    },\n  });\n\n  console.log(`Queue \"${EMAIL_QUEUE_NAME}\" initialized.`);\n\n  emailQueue.on(\"error\", (error) => {\n    console.error(`Queue ${EMAIL_QUEUE_NAME} error:`, error);\n  });\n} else {\n  console.warn(\n    `Valkey connection not available, Queue \"${EMAIL_QUEUE_NAME}\" not initialized.`\n  );\n}\n\n// Initialize sync queue\nif (valkeyConnection) {\n  syncQueue = new Queue(SYNC_QUEUE_NAME, {\n    connection: valkeyConnection,\n    defaultJobOptions: {\n      attempts: 3,\n      backoff: {\n        type: \"exponential\",\n        delay: 5000,\n      },\n      removeOnComplete: {\n        age: 3600 * 24 * 3, // keep up to 3 days\n        count: 500,\n      },\n      removeOnFail: {\n        age: 3600 * 24 * 7, // keep up to 7 days\n      },\n    },\n  });\n\n  console.log(`Queue \"${SYNC_QUEUE_NAME}\" initialized.`);\n\n  syncQueue.on(\"error\", (error) => {\n    console.error(`Queue ${SYNC_QUEUE_NAME} error:`, error);\n  });\n} else {\n  console.warn(\n    `Valkey connection not available, Queue \"${SYNC_QUEUE_NAME}\" not initialized.`\n  );\n}\n\n// Initialize Testmo import queue\nif (valkeyConnection) {\n  testmoImportQueue = new Queue(TESTMO_IMPORT_QUEUE_NAME, {\n    connection: valkeyConnection,\n    defaultJobOptions: {\n      attempts: 1,\n      removeOnComplete: {\n        age: 3600 * 24 * 30,\n        count: 100,\n      },\n      removeOnFail: {\n        age: 3600 * 24 * 30,\n      },\n    },\n  });\n\n  console.log(`Queue \"${TESTMO_IMPORT_QUEUE_NAME}\" initialized.`);\n\n  testmoImportQueue.on(\"error\", (error) => {\n    console.error(`Queue ${TESTMO_IMPORT_QUEUE_NAME} error:`, error);\n  });\n} else {\n  console.warn(\n    `Valkey connection not available, Queue \"${TESTMO_IMPORT_QUEUE_NAME}\" not initialized.`\n  );\n}\n\n// Initialize Elasticsearch reindex queue\nif (valkeyConnection) {\n  elasticsearchReindexQueue = new Queue(ELASTICSEARCH_REINDEX_QUEUE_NAME, {\n    connection: valkeyConnection,\n    defaultJobOptions: {\n      attempts: 1, // Don't retry reindex jobs automatically\n      removeOnComplete: {\n        age: 3600 * 24 * 7, // keep up to 7 days\n        count: 50,\n      },\n      removeOnFail: {\n        age: 3600 * 24 * 14, // keep up to 14 days\n      },\n    },\n  });\n\n  console.log(`Queue \"${ELASTICSEARCH_REINDEX_QUEUE_NAME}\" initialized.`);\n\n  elasticsearchReindexQueue.on(\"error\", (error) => {\n    console.error(`Queue ${ELASTICSEARCH_REINDEX_QUEUE_NAME} error:`, error);\n  });\n} else {\n  console.warn(\n    `Valkey connection not available, Queue \"${ELASTICSEARCH_REINDEX_QUEUE_NAME}\" not initialized.`\n  );\n}\n\n// Export the potentially null queues\nexport { forecastQueue, notificationQueue, emailQueue, syncQueue, testmoImportQueue, elasticsearchReindexQueue };\n", "import IORedis from \"ioredis\";\n\n// Check if we should skip Valkey connection (useful during build)\nconst skipConnection = process.env.SKIP_VALKEY_CONNECTION === \"true\";\n\n// Get Valkey URL from environment\nconst valkeyUrl = process.env.VALKEY_URL;\n\nif (!valkeyUrl && !skipConnection) {\n  // Log an error, but maybe don't throw immediately\n  // depending on whether Valkey is strictly required at startup\n  console.error(\n    \"VALKEY_URL environment variable is not set. Background jobs may fail.\"\n  );\n  // Optional: throw new Error('VALKEY_URL environment variable is not set.');\n}\n\n// Configure the connection options\nconst connectionOptions = {\n  maxRetriesPerRequest: null, // Required by BullMQ\n  enableReadyCheck: false, // Optional: Sometimes helps with startup race conditions\n};\n\nlet valkeyConnection: IORedis | null = null;\n\nif (valkeyUrl && !skipConnection) {\n  // Convert valkey:// to redis:// for ioredis compatibility\n  // ioredis expects redis:// protocol but we're connecting to Valkey\n  const connectionUrl = valkeyUrl.replace(/^valkey:\\/\\//, 'redis://');\n  \n  // Create and export the connection instance only if URL is provided\n  valkeyConnection = new IORedis(connectionUrl, connectionOptions);\n\n  valkeyConnection.on(\"connect\", () => {\n    console.log(\"Successfully connected to Valkey.\");\n  });\n\n  valkeyConnection.on(\"error\", (err) => {\n    console.error(\"Valkey connection error:\", err);\n  });\n} else {\n  console.warn(\"Valkey URL not provided. Valkey connection not established.\");\n}\n\nexport default valkeyConnection;", "// Queue name constants - no initialization, just names\nexport const FORECAST_QUEUE_NAME = \"forecast-updates\";\nexport const NOTIFICATION_QUEUE_NAME = \"notifications\";\nexport const EMAIL_QUEUE_NAME = \"emails\";\nexport const SYNC_QUEUE_NAME = \"issue-sync\";\nexport const TESTMO_IMPORT_QUEUE_NAME = \"testmo-imports\";\nexport const ELASTICSEARCH_REINDEX_QUEUE_NAME = \"elasticsearch-reindex\";\n", "import { Worker, Job } from \"bullmq\";\nimport valkeyConnection from \"../lib/valkey\";\nimport { FORECAST_QUEUE_NAME } from \"../lib/queueNames\";\nimport {\n  updateRepositoryCaseForecast,\n  getUniqueCaseGroupIds,\n  updateTestRunForecast,\n} from \"../services/forecastService\";\nimport { pathToFileURL } from \"node:url\";\nimport { prisma } from \"../lib/prisma\";\n\n// Define expected job data structures (optional but good practice)\ninterface UpdateSingleCaseJobData {\n  repositoryCaseId: number;\n}\n\n// Define job names for clarity and export them for the scheduler\nexport const JOB_UPDATE_SINGLE_CASE = \"update-single-case-forecast\";\nexport const JOB_UPDATE_ALL_CASES = \"update-all-cases-forecast\";\n\nconst processor = async (job: Job) => {\n  console.log(`Processing job ${job.id} of type ${job.name}`);\n  let successCount = 0;\n  let failCount = 0;\n\n  switch (job.name) {\n    case JOB_UPDATE_SINGLE_CASE:\n      const singleData = job.data as UpdateSingleCaseJobData;\n      if (!singleData || typeof singleData.repositoryCaseId !== \"number\") {\n        throw new Error(\n          `Invalid data for job ${job.id}: repositoryCaseId missing or not a number.`\n        );\n      }\n      try {\n        await updateRepositoryCaseForecast(singleData.repositoryCaseId);\n        successCount = 1;\n        console.log(\n          `Job ${job.id} completed: Updated forecast for case ${singleData.repositoryCaseId}`\n        );\n      } catch (error) {\n        failCount = 1;\n        console.error(\n          `Job ${job.id} failed for case ${singleData.repositoryCaseId}`,\n          error\n        );\n        throw error; // Re-throw to mark job as failed\n      }\n      break;\n\n    case JOB_UPDATE_ALL_CASES:\n      console.log(`Job ${job.id}: Starting update for all active cases.`);\n      // Reset counters for batch job\n      successCount = 0;\n      failCount = 0;\n      // Use unique case group IDs to avoid recalculating the same linked groups multiple times\n      const caseIds = await getUniqueCaseGroupIds();\n\n      // Track affected TestRuns to update them once at the end\n      const affectedTestRunIds = new Set<number>();\n\n      // Process cases sequentially, skipping TestRun updates and collecting affected TestRuns\n      for (const caseId of caseIds) {\n        try {\n          const result = await updateRepositoryCaseForecast(caseId, {\n            skipTestRunUpdate: true,\n            collectAffectedTestRuns: true,\n          });\n\n          // Collect affected TestRun IDs\n          for (const testRunId of result.affectedTestRunIds) {\n            affectedTestRunIds.add(testRunId);\n          }\n\n          successCount++;\n        } catch (error) {\n          console.error(\n            `Job ${job.id}: Failed to update forecast for case ${caseId}`,\n            error\n          );\n          failCount++;\n          // Continue processing other cases even if one fails\n        }\n      }\n\n      console.log(\n        `Job ${job.id}: Processed ${caseIds.length} unique case groups. Success: ${successCount}, Failed: ${failCount}`\n      );\n\n      // Filter out completed test runs (they're locked and don't need forecast updates)\n      console.log(\n        `Job ${job.id}: Filtering ${affectedTestRunIds.size} affected test runs...`\n      );\n\n      const activeTestRuns = await prisma.testRuns.findMany({\n        where: {\n          id: { in: Array.from(affectedTestRunIds) },\n          isCompleted: false,\n        },\n        select: { id: true },\n      });\n\n      const activeTestRunIds = activeTestRuns.map((tr) => tr.id);\n      const skippedCompletedCount =\n        affectedTestRunIds.size - activeTestRunIds.length;\n\n      console.log(\n        `Job ${job.id}: Updating ${activeTestRunIds.length} active test runs (skipped ${skippedCompletedCount} completed)...`\n      );\n      let testRunSuccessCount = 0;\n      let testRunFailCount = 0;\n\n      for (const testRunId of activeTestRunIds) {\n        try {\n          await updateTestRunForecast(testRunId);\n          testRunSuccessCount++;\n        } catch (error) {\n          console.error(\n            `Job ${job.id}: Failed to update forecast for test run ${testRunId}`,\n            error\n          );\n          testRunFailCount++;\n        }\n      }\n\n      console.log(\n        `Job ${job.id} completed: Updated ${testRunSuccessCount} test runs. Failed: ${testRunFailCount}. Skipped ${skippedCompletedCount} completed.`\n      );\n\n      if (failCount > 0 || testRunFailCount > 0) {\n        // Indicate partial failure but don't necessarily throw to allow job completion\n        console.warn(\n          `Job ${job.id} finished with ${failCount} case failures and ${testRunFailCount} test run failures.`\n        );\n        // throw new Error(`Completed with failures.`); // Uncomment to mark job as failed\n      }\n      break;\n\n    default:\n      throw new Error(`Unknown job type: ${job.name}`);\n  }\n\n  return { status: \"completed\", successCount, failCount }; // Return summary\n};\n\nasync function startWorker() {\n  // Initialize the worker only if Valkey connection exists\n  if (valkeyConnection) {\n    const worker = new Worker(FORECAST_QUEUE_NAME, processor, {\n      connection: valkeyConnection,\n      concurrency: 5,\n      limiter: {\n        max: 100,\n        duration: 1000,\n      },\n    });\n\n    worker.on(\"completed\", (job, result) => {\n      console.info(\n        `Worker: Job ${job.id} (${job.name}) completed successfully. Result:`,\n        result\n      );\n    });\n\n    worker.on(\"failed\", (job, err) => {\n      console.error(\n        `Worker: Job ${job?.id} (${job?.name}) failed with error:`,\n        err\n      );\n    });\n\n    worker.on(\"error\", (err) => {\n      console.error(\"Worker encountered an error:\", err);\n    });\n\n    console.log(\"Forecast worker started and listening for jobs...\");\n\n    // Graceful shutdown handling\n    const shutdown = async () => {\n      console.log(\"Shutting down forecast worker...\");\n      await worker.close();\n      console.log(\"Forecast worker shut down gracefully.\");\n      process.exit(0);\n    };\n\n    process.on(\"SIGTERM\", shutdown);\n    process.on(\"SIGINT\", shutdown);\n  } else {\n    console.warn(\n      \"Valkey connection not available. Forecast worker cannot start.\"\n    );\n    process.exit(1);\n  }\n}\n\n// Conditionally call startWorker only when this file is executed directly\n// This check ensures importing the file doesn't automatically start the worker\n// Works with both ESM and CommonJS\nif (\n  (typeof import.meta !== \"undefined\" &&\n    import.meta.url === pathToFileURL(process.argv[1]).href) ||\n  typeof import.meta === \"undefined\" ||\n  (import.meta as any).url === undefined\n) {\n  startWorker().catch((err) => {\n    console.error(\"Failed to start worker:\", err);\n    process.exit(1);\n  });\n}\n", "// app/lib/prisma.ts\nimport { PrismaClient } from \"@prisma/client\";\nimport { enhance } from \"@zenstackhq/runtime\";\nimport { syncRepositoryCaseToElasticsearch } from \"../services/repositoryCaseSync\";\nimport { syncTestRunToElasticsearch } from \"../services/testRunSearch\";\nimport { syncSessionToElasticsearch } from \"../services/sessionSearch\";\nimport { syncSharedStepToElasticsearch } from \"../services/sharedStepSearch\";\nimport { syncIssueToElasticsearch } from \"../services/issueSearch\";\nimport { syncMilestoneToElasticsearch } from \"../services/milestoneSearch\";\nimport { syncProjectToElasticsearch } from \"../services/projectSearch\";\n\n// Declare global types\ndeclare global {\n  var prisma: PrismaClient | undefined;\n  var db: any;\n}\n\n// Use different variable names to avoid redeclaration\nlet prismaClient: PrismaClient;\nlet dbClient: any;\n\n// Helper function to create and configure PrismaClient with Elasticsearch sync\nfunction createPrismaClient(errorFormat: \"pretty\" | \"colorless\") {\n  const baseClient = new PrismaClient({ errorFormat });\n  \n  // Add Elasticsearch sync using client extensions\n  const client = baseClient.$extends({\n    query: {\n      repositoryCases: {\n        async create({ args, query }: any) {\n          const result = await query(args);\n          // Sync to Elasticsearch asynchronously\n          if (result?.id) {\n            syncRepositoryCaseToElasticsearch(result.id).catch((error: any) => {\n              console.error(`Failed to sync repository case ${result.id} to Elasticsearch:`, error);\n            });\n          }\n          return result;\n        },\n        async update({ args, query }: any) {\n          const result = await query(args);\n          // Sync to Elasticsearch asynchronously\n          if (result?.id) {\n            syncRepositoryCaseToElasticsearch(result.id).catch((error: any) => {\n              console.error(`Failed to sync repository case ${result.id} to Elasticsearch:`, error);\n            });\n          }\n          return result;\n        },\n        async upsert({ args, query }: any) {\n          const result = await query(args);\n          // Sync to Elasticsearch asynchronously\n          if (result?.id) {\n            syncRepositoryCaseToElasticsearch(result.id).catch((error: any) => {\n              console.error(`Failed to sync repository case ${result.id} to Elasticsearch:`, error);\n            });\n          }\n          return result;\n        },\n        async delete({ args, query }: any) {\n          const result = await query(args);\n          // Sync to Elasticsearch asynchronously (will handle removal if needed)\n          if (result?.id) {\n            syncRepositoryCaseToElasticsearch(result.id).catch((error: any) => {\n              console.error(`Failed to sync repository case ${result.id} to Elasticsearch after delete:`, error);\n            });\n          }\n          return result;\n        },\n      },\n      testRuns: {\n        async create({ args, query }: any) {\n          const result = await query(args);\n          if (result?.id) {\n            syncTestRunToElasticsearch(result.id).catch((error: any) => {\n              console.error(`Failed to sync test run ${result.id} to Elasticsearch:`, error);\n            });\n          }\n          return result;\n        },\n        async update({ args, query }: any) {\n          const result = await query(args);\n          if (result?.id) {\n            syncTestRunToElasticsearch(result.id).catch((error: any) => {\n              console.error(`Failed to sync test run ${result.id} to Elasticsearch:`, error);\n            });\n          }\n          return result;\n        },\n      },\n      sessions: {\n        async create({ args, query }: any) {\n          const result = await query(args);\n          if (result?.id) {\n            syncSessionToElasticsearch(result.id).catch((error: any) => {\n              console.error(`Failed to sync session ${result.id} to Elasticsearch:`, error);\n            });\n          }\n          return result;\n        },\n        async update({ args, query }: any) {\n          const result = await query(args);\n          if (result?.id) {\n            syncSessionToElasticsearch(result.id).catch((error: any) => {\n              console.error(`Failed to sync session ${result.id} to Elasticsearch:`, error);\n            });\n          }\n          return result;\n        },\n        async upsert({ args, query }: any) {\n          const result = await query(args);\n          if (result?.id) {\n            syncSessionToElasticsearch(result.id).catch((error: any) => {\n              console.error(`Failed to sync session ${result.id} to Elasticsearch:`, error);\n            });\n          }\n          return result;\n        },\n        async delete({ args, query }: any) {\n          const result = await query(args);\n          if (result?.id) {\n            syncSessionToElasticsearch(result.id).catch((error: any) => {\n              console.error(`Failed to sync session ${result.id} to Elasticsearch:`, error);\n            });\n          }\n          return result;\n        },\n      },\n      sharedStepGroups: {\n        async create({ args, query }: any) {\n          const result = await query(args);\n          if (result?.id) {\n            syncSharedStepToElasticsearch(result.id).catch((error: any) => {\n              console.error(`Failed to sync shared step ${result.id} to Elasticsearch:`, error);\n            });\n          }\n          return result;\n        },\n        async update({ args, query }: any) {\n          const result = await query(args);\n          if (result?.id) {\n            syncSharedStepToElasticsearch(result.id).catch((error: any) => {\n              console.error(`Failed to sync shared step ${result.id} to Elasticsearch:`, error);\n            });\n          }\n          return result;\n        },\n      },\n      issues: {\n        async create({ args, query }: any) {\n          const result = await query(args);\n          if (result?.id) {\n            syncIssueToElasticsearch(result.id).catch((error: any) => {\n              console.error(`Failed to sync issue ${result.id} to Elasticsearch:`, error);\n            });\n          }\n          return result;\n        },\n        async update({ args, query }: any) {\n          const result = await query(args);\n          if (result?.id) {\n            syncIssueToElasticsearch(result.id).catch((error: any) => {\n              console.error(`Failed to sync issue ${result.id} to Elasticsearch:`, error);\n            });\n          }\n          return result;\n        },\n      },\n      milestones: {\n        async create({ args, query }: any) {\n          const result = await query(args);\n          if (result?.id) {\n            syncMilestoneToElasticsearch(result.id).catch((error: any) => {\n              console.error(`Failed to sync milestone ${result.id} to Elasticsearch:`, error);\n            });\n          }\n          return result;\n        },\n        async update({ args, query }: any) {\n          const result = await query(args);\n          if (result?.id) {\n            syncMilestoneToElasticsearch(result.id).catch((error: any) => {\n              console.error(`Failed to sync milestone ${result.id} to Elasticsearch:`, error);\n            });\n          }\n          return result;\n        },\n      },\n      projects: {\n        async create({ args, query }: any) {\n          const result = await query(args);\n          if (result?.id) {\n            syncProjectToElasticsearch(result.id).catch((error: any) => {\n              console.error(`Failed to sync project ${result.id} to Elasticsearch:`, error);\n            });\n          }\n          return result;\n        },\n        async update({ args, query }: any) {\n          const result = await query(args);\n          if (result?.id) {\n            syncProjectToElasticsearch(result.id).catch((error: any) => {\n              console.error(`Failed to sync project ${result.id} to Elasticsearch:`, error);\n            });\n          }\n          return result;\n        },\n      },\n    } as any,\n  });\n  \n  return client as unknown as PrismaClient;\n}\n\n// Check if we're in a production environment or not.\n// In development, Next.js might hot-reload and create new instances, so we prevent that.\nif (process.env.NODE_ENV === \"production\") {\n  prismaClient = createPrismaClient(\"pretty\");\n  dbClient = enhance(prismaClient);\n} else {\n  // Check if there's already a global instance of PrismaClient\n  if (!global.prisma) {\n    global.prisma = createPrismaClient(\"colorless\");\n    global.db = enhance(global.prisma);\n  }\n  prismaClient = global.prisma;\n  dbClient = global.db;\n}\n\nexport const prisma = prismaClient;\nexport const db = dbClient;\n", "import { PrismaClient } from \"@prisma/client\";\nimport {\n  createRepositoryCaseIndex,\n  RepositoryCaseDocument,\n} from \"./elasticsearchService\";\nimport {\n  indexRepositoryCase,\n  deleteRepositoryCase,\n  bulkIndexRepositoryCases,\n} from \"./elasticsearchIndexing\";\nimport { extractTextFromNode } from \"../utils/extractTextFromJson\";\nimport { buildCustomFieldDocuments } from \"./unifiedElasticsearchService\";\n\nconst prisma = new PrismaClient();\n\n/**\n * Safely extract text from a step field that might be JSON string or object\n */\nfunction extractStepText(stepData: any): string {\n  if (!stepData) return \"\";\n\n  try {\n    // If it's a string, try to parse it as JSON\n    if (typeof stepData === \"string\") {\n      const parsed = JSON.parse(stepData);\n      return extractTextFromNode(parsed);\n    }\n    // Otherwise, assume it's already an object\n    return extractTextFromNode(stepData);\n  } catch (error) {\n    // If parsing fails, return the original string\n    return typeof stepData === \"string\" ? stepData : \"\";\n  }\n}\n\n/**\n * Build a repository case document for Elasticsearch from Prisma data\n */\nexport async function buildRepositoryCaseDocument(\n  caseId: number\n): Promise<RepositoryCaseDocument | null> {\n  const repoCase = await prisma.repositoryCases.findUnique({\n    where: { id: caseId },\n    include: {\n      project: true,\n      folder: true,\n      template: true,\n      state: {\n        include: {\n          icon: true,\n          color: true,\n        },\n      },\n      creator: true,\n      tags: true,\n      steps: {\n        orderBy: { order: \"asc\" },\n        include: {\n          sharedStepGroup: {\n            include: {\n              items: {\n                orderBy: { order: \"asc\" },\n              },\n            },\n          },\n        },\n      },\n      caseFieldValues: {\n        include: {\n          field: {\n            include: {\n              type: true,\n              fieldOptions: {\n                include: {\n                  fieldOption: {\n                    include: {\n                      icon: true,\n                      iconColor: true,\n                    },\n                  },\n                },\n              },\n            },\n          },\n        },\n      },\n    },\n  });\n\n  if (!repoCase) return null;\n\n  // Build folder path\n  const folderPath = await buildFolderPath(repoCase.folderId);\n\n  return {\n    id: repoCase.id,\n    projectId: repoCase.projectId,\n    projectName: repoCase.project.name,\n    projectIconUrl: repoCase.project.iconUrl,\n    repositoryId: repoCase.repositoryId,\n    folderId: repoCase.folderId,\n    folderPath,\n    templateId: repoCase.templateId,\n    templateName: repoCase.template.templateName,\n    name: repoCase.name,\n    className: repoCase.className,\n    source: repoCase.source,\n    stateId: repoCase.stateId,\n    stateName: repoCase.state.name,\n    stateIcon: repoCase.state.icon.name,\n    stateColor: repoCase.state.color.value,\n    estimate: repoCase.estimate,\n    forecastManual: repoCase.forecastManual,\n    forecastAutomated: repoCase.forecastAutomated,\n    automated: repoCase.automated,\n    isArchived: repoCase.isArchived,\n    isDeleted: repoCase.isDeleted,\n    createdAt: repoCase.createdAt,\n    creatorId: repoCase.creatorId,\n    creatorName: repoCase.creator.name,\n    creatorImage: repoCase.creator.image,\n    tags: repoCase.tags.map((tag) => ({\n      id: tag.id,\n      name: tag.name,\n    })),\n    customFields: buildCustomFieldDocuments(\n      repoCase.caseFieldValues.map((cfv) => ({\n        fieldId: cfv.fieldId,\n        field: {\n          displayName: cfv.field.displayName,\n          systemName: cfv.field.systemName,\n          type: cfv.field.type ? { type: cfv.field.type.type } : undefined,\n          fieldOptions: cfv.field.fieldOptions?.map((fo) => ({\n            fieldOption: {\n              id: fo.fieldOption.id,\n              name: fo.fieldOption.name,\n              icon: fo.fieldOption.icon\n                ? { name: fo.fieldOption.icon.name }\n                : undefined,\n              iconColor: fo.fieldOption.iconColor\n                ? { value: fo.fieldOption.iconColor.value }\n                : undefined,\n            },\n          })),\n        },\n        value: cfv.value,\n      }))\n    )\n      .filter(\n        (cf) => cf.value !== null && cf.value !== undefined && cf.value !== \"\"\n      )\n      .map((cf) => ({\n        fieldId: cf.fieldId,\n        fieldName: cf.fieldName,\n        fieldType: cf.fieldType,\n        value: cf.value || \"\", // Ensure value is always present\n      })),\n    steps: repoCase.steps.flatMap((step): any[] => {\n      // If this is a shared step, expand all items from the group\n      if (step.sharedStepGroupId && step.sharedStepGroup) {\n        return step.sharedStepGroup.items.map((item, index) => ({\n          id: step.id * 1000 + index, // Generate unique ID for each shared step item\n          order: step.order,\n          step: extractStepText(item.step),\n          expectedResult: extractStepText(item.expectedResult),\n          isSharedStep: true,\n          sharedStepGroupId: step.sharedStepGroupId,\n          sharedStepGroupName: step.sharedStepGroup?.name,\n        }));\n      }\n      // Regular step\n      return [\n        {\n          id: step.id,\n          order: step.order,\n          step: extractStepText(step.step),\n          expectedResult: extractStepText(step.expectedResult),\n          isSharedStep: false,\n          sharedStepGroupId: undefined,\n          sharedStepGroupName: undefined,\n        },\n      ];\n    }),\n  };\n}\n\n/**\n * Build the full folder path for a folder\n */\nasync function buildFolderPath(folderId: number): Promise<string> {\n  const folder = await prisma.repositoryFolders.findUnique({\n    where: { id: folderId },\n    include: { parent: true },\n  });\n\n  if (!folder) return \"/\";\n\n  const path = [folder.name];\n  let current: any = folder;\n\n  while (current.parent) {\n    path.unshift(current.parent.name);\n    const nextParent = await prisma.repositoryFolders.findUnique({\n      where: { id: current.parent.id },\n      include: { parent: true },\n    });\n    if (!nextParent) break;\n    current = nextParent;\n  }\n\n  return \"/\" + path.join(\"/\");\n}\n\n/**\n * Sync a repository case to Elasticsearch after create/update\n */\nexport async function syncRepositoryCaseToElasticsearch(\n  caseId: number\n): Promise<boolean> {\n  const doc = await buildRepositoryCaseDocument(caseId);\n  if (!doc) {\n    // Case no longer exists (hard deleted) - remove from Elasticsearch\n    await deleteRepositoryCase(caseId);\n    return true;\n  }\n\n  // Index all cases including deleted ones (they'll be filtered in search based on admin permissions)\n  // Only exclude archived cases as they're typically not meant to be searchable\n  if (doc.isArchived) {\n    await deleteRepositoryCase(caseId);\n    return true;\n  }\n\n  return await indexRepositoryCase(doc);\n}\n\n/**\n * Sync all repository cases for a project to Elasticsearch\n */\nexport async function syncProjectCasesToElasticsearch(\n  projectId: number,\n  batchSize: number = 100,\n  progressCallback?: (processed: number, total: number, message: string) => void | Promise<void>\n): Promise<boolean> {\n  try {\n    // Ensure index exists\n    await createRepositoryCaseIndex();\n\n    const totalCases = await prisma.repositoryCases.count({\n      where: {\n        projectId,\n        isArchived: false, // Only exclude archived, include deleted items\n      },\n    });\n\n    const message = `Syncing ${totalCases} cases for project ${projectId}...`;\n    console.log(message);\n    if (progressCallback) {\n      await progressCallback(0, totalCases, message);\n    }\n\n    let processed = 0;\n    let hasMore = true;\n\n    while (hasMore) {\n      const cases = await prisma.repositoryCases.findMany({\n        where: {\n          projectId,\n          isArchived: false, // Only exclude archived, include deleted items\n        },\n        skip: processed,\n        take: batchSize,\n        orderBy: { id: \"asc\" },\n      });\n\n      if (cases.length === 0) {\n        hasMore = false;\n        break;\n      }\n\n      // Build documents for this batch\n      const documents: RepositoryCaseDocument[] = [];\n\n      for (const caseItem of cases) {\n        const doc = await buildRepositoryCaseDocument(caseItem.id);\n        if (doc) {\n          documents.push(doc);\n        }\n      }\n\n      // Bulk index this batch\n      if (documents.length > 0) {\n        const success = await bulkIndexRepositoryCases(documents);\n        if (!success) {\n          console.error(`Failed to index batch starting at ${processed}`);\n          return false;\n        }\n      }\n\n      processed += cases.length;\n      const progressMessage = `Indexed ${processed}/${totalCases} cases...`;\n      console.log(progressMessage);\n      if (progressCallback) {\n        await progressCallback(processed, totalCases, progressMessage);\n      }\n    }\n\n    const finalMessage = `Successfully synced ${processed} cases to Elasticsearch`;\n    console.log(finalMessage);\n    if (progressCallback) {\n      await progressCallback(processed, totalCases, finalMessage);\n    }\n    return true;\n  } catch (error) {\n    console.error(\"Error syncing project cases to Elasticsearch:\", error);\n    return false;\n  }\n}\n\n/**\n * Initialize Elasticsearch indexes on application startup\n */\nexport async function initializeElasticsearchIndexes(): Promise<void> {\n  try {\n    const created = await createRepositoryCaseIndex();\n    if (created) {\n      console.log(\"Elasticsearch indexes initialized successfully\");\n    }\n  } catch (error) {\n    console.error(\"Failed to initialize Elasticsearch indexes:\", error);\n  }\n}\n", "import { Client } from \"@elastic/elasticsearch\";\nimport { env } from \"../env.js\";\n\n// Create singleton instance\nlet esClient: Client | null = null;\n\n/**\n * Get or create Elasticsearch client instance\n */\nexport function getElasticsearchClient(): Client | null {\n  if (!env.ELASTICSEARCH_NODE) {\n    console.warn(\n      \"ELASTICSEARCH_NODE environment variable not set. Elasticsearch integration disabled.\"\n    );\n    return null;\n  }\n\n  if (!esClient) {\n    try {\n      esClient = new Client({\n        node: env.ELASTICSEARCH_NODE,\n        // Add additional configuration as needed\n        maxRetries: 3,\n        requestTimeout: 30000,\n        sniffOnStart: false, // Disable sniffing for custom ports\n      });\n\n    } catch (error) {\n      console.error(\"Failed to initialize Elasticsearch client:\", error);\n      return null;\n    }\n  }\n\n  return esClient;\n}\n\n/**\n * Test Elasticsearch connection\n */\nexport async function testElasticsearchConnection(): Promise<boolean> {\n  const client = getElasticsearchClient();\n  if (!client) return false;\n\n  try {\n    const response = await client.ping();\n    return true;\n  } catch (error) {\n    console.error(\"Elasticsearch connection failed:\", error);\n    return false;\n  }\n}\n\n/**\n * Repository Case index configuration\n */\nexport const REPOSITORY_CASE_INDEX = \"testplanit-repository-cases\";\n\n/**\n * Repository Case mapping for Elasticsearch\n */\nexport const repositoryCaseMapping = {\n  properties: {\n    id: { type: \"integer\" as const },\n    projectId: { type: \"integer\" as const },\n    projectName: { type: \"keyword\" as const },\n    projectIconUrl: { type: \"keyword\" as const },\n    repositoryId: { type: \"integer\" as const },\n    folderId: { type: \"integer\" as const },\n    folderPath: { type: \"keyword\" as const },\n    templateId: { type: \"integer\" as const },\n    templateName: { type: \"keyword\" as const },\n    name: {\n      type: \"text\" as const,\n      analyzer: \"standard\",\n      fields: {\n        keyword: { type: \"keyword\" as const },\n        suggest: { type: \"completion\" as const },\n      },\n    },\n    className: { type: \"keyword\" as const },\n    source: { type: \"keyword\" as const },\n    stateId: { type: \"integer\" as const },\n    stateName: { type: \"keyword\" as const },\n    stateIcon: { type: \"keyword\" as const },\n    stateColor: { type: \"keyword\" as const },\n    estimate: { type: \"integer\" as const },\n    forecastManual: { type: \"integer\" as const },\n    forecastAutomated: { type: \"float\" as const },\n    automated: { type: \"boolean\" as const },\n    isArchived: { type: \"boolean\" as const },\n    isDeleted: { type: \"boolean\" as const },\n    createdAt: { type: \"date\" as const },\n    creatorId: { type: \"keyword\" as const },\n    creatorName: { type: \"text\" as const },\n    tags: {\n      type: \"nested\" as const,\n      properties: {\n        id: { type: \"integer\" as const },\n        name: { type: \"keyword\" as const },\n      },\n    },\n    customFields: {\n      type: \"nested\" as const,\n      properties: {\n        fieldId: { type: \"integer\" as const },\n        fieldName: { type: \"keyword\" as const },\n        fieldType: { type: \"keyword\" as const },\n        value: { type: \"text\" as const },\n      },\n    },\n    steps: {\n      type: \"nested\" as const,\n      properties: {\n        id: { type: \"integer\" as const },\n        order: { type: \"integer\" as const },\n        step: { type: \"text\" as const },\n        expectedResult: { type: \"text\" as const },\n        isSharedStep: { type: \"boolean\" as const },\n        sharedStepGroupId: { type: \"integer\" as const },\n        sharedStepGroupName: { type: \"text\" as const },\n      },\n    },\n    // Full-text search field combining multiple fields\n    searchableContent: { type: \"text\" as const },\n  },\n};\n\n/**\n * Get Elasticsearch replica settings from database\n */\nasync function getElasticsearchSettings() {\n  try {\n    const { PrismaClient } = await import(\"@prisma/client\");\n    const prisma = new PrismaClient();\n    \n    const config = await prisma.appConfig.findUnique({\n      where: { key: \"elasticsearch_replicas\" }\n    });\n    \n    await prisma.$disconnect();\n    \n    // Default to 0 for single-node clusters\n    return {\n      numberOfReplicas: config?.value ? (config.value as number) : 0\n    };\n  } catch (error) {\n    console.warn(\"Failed to get Elasticsearch settings from database, using defaults:\", error);\n    return { numberOfReplicas: 0 };\n  }\n}\n\n/**\n * Create or update the repository cases index\n */\nexport async function createRepositoryCaseIndex(): Promise<boolean> {\n  const client = getElasticsearchClient();\n  if (!client) return false;\n\n  try {\n    // Get settings from database\n    const settings = await getElasticsearchSettings();\n    \n    // Check if index exists\n    const exists = await client.indices.exists({\n      index: REPOSITORY_CASE_INDEX,\n    });\n\n    if (!exists) {\n      // Create index with mapping\n      await client.indices.create({\n        index: REPOSITORY_CASE_INDEX,\n        settings: {\n          number_of_shards: 1,\n          number_of_replicas: settings.numberOfReplicas,\n          analysis: {\n            analyzer: {\n              standard: {\n                type: \"standard\",\n                stopwords: \"_english_\",\n              },\n            },\n          },\n        },\n        mappings: repositoryCaseMapping,\n      });\n    } else {\n      // Index already exists, skip update to avoid field type conflicts\n    }\n\n    return true;\n  } catch (error) {\n    console.error(\"Failed to create/update Elasticsearch index:\", error);\n    return false;\n  }\n}\n\n/**\n * Interface for indexing repository case data\n */\nexport interface RepositoryCaseDocument {\n  id: number;\n  projectId: number;\n  projectName: string;\n  projectIconUrl?: string | null;\n  repositoryId: number;\n  folderId: number;\n  folderPath: string;\n  templateId: number;\n  templateName: string;\n  name: string;\n  className?: string | null;\n  source: string;\n  stateId: number;\n  stateName: string;\n  stateIcon?: string;\n  stateColor?: string;\n  estimate?: number | null;\n  forecastManual?: number | null;\n  forecastAutomated?: number | null;\n  automated: boolean;\n  isArchived: boolean;\n  isDeleted: boolean;\n  createdAt: Date;\n  creatorId: string;\n  creatorName: string;\n  creatorImage?: string | null;\n  tags?: Array<{ id: number; name: string }>;\n  customFields?: Array<{\n    fieldId: number;\n    fieldName: string;\n    fieldType: string;\n    value: any;\n  }>;\n  steps?: Array<{\n    id: number;\n    order: number;\n    step: string;\n    expectedResult: string;\n    isSharedStep?: boolean;\n    sharedStepGroupId?: number;\n    sharedStepGroupName?: string;\n  }>;\n  searchableContent?: string;\n}\n", "import { createEnv } from \"@t3-oss/env-nextjs\";\nimport { z } from \"zod/v4\";\n\nexport const env = createEnv({\n  /**\n   * Specify your server-side environment variables schema here. This way you can ensure the app\n   * isn't built with invalid env vars.\n   */\n  server: {\n    DATABASE_URL: z\n      .string()\n      .refine(\n        (str) => !str.includes(\"YOUR_MYSQL_URL_HERE\"),\n        \"You forgot to change the default URL\",\n      ),\n    NODE_ENV: z\n      .enum([\"development\", \"test\", \"production\"])\n      .prefault(\"development\"),\n    NEXTAUTH_SECRET:\n      process.env.NODE_ENV === \"production\"\n        ? z.string()\n        : z.string().optional(),\n    NEXTAUTH_URL: z.preprocess(\n      // This makes Vercel deployments not fail if you don't set NEXTAUTH_URL\n      // Since NextAuth.js automatically uses the VERCEL_URL if present.\n      (str) => process.env.VERCEL_URL ?? str,\n      // VERCEL_URL doesn't include `https` so it cant be validated as a URL\n      process.env.VERCEL ? z.string() : z.url(),\n    ),\n    ELASTICSEARCH_NODE: z.url().optional(),\n  },\n\n  /**\n   * Specify your client-side environment variables schema here. This way you can ensure the app\n   * isn't built with invalid env vars. To expose them to the client, prefix them with\n   * `NEXT_PUBLIC_`.\n   */\n  client: {\n    // NEXT_PUBLIC_CLIENTVAR: z.string(),\n  },\n\n  /**\n   * You can't destruct `process.env` as a regular object in the Next.js edge runtimes (e.g.\n   * middlewares) or client-side so we need to destruct manually.\n   */\n  runtimeEnv: {\n    DATABASE_URL: process.env.DATABASE_URL,\n    NODE_ENV: process.env.NODE_ENV,\n    NEXTAUTH_SECRET: process.env.NEXTAUTH_SECRET,\n    NEXTAUTH_URL: process.env.NEXTAUTH_URL,\n    ELASTICSEARCH_NODE: process.env.ELASTICSEARCH_NODE,\n  },\n  /**\n   * Run `build` or `dev` with `SKIP_ENV_VALIDATION` to skip env validation. This is especially\n   * useful for Docker builds.\n   */\n  skipValidation: !!process.env.SKIP_ENV_VALIDATION,\n  /**\n   * Makes it so that empty strings are treated as undefined. `SOME_VAR: z.string()` and\n   * `SOME_VAR=''` will throw an error.\n   */\n  emptyStringAsUndefined: true,\n});\n", "import {\n  getElasticsearchClient,\n  REPOSITORY_CASE_INDEX,\n  RepositoryCaseDocument,\n} from \"./elasticsearchService\";\n\n/**\n * Index a repository case in Elasticsearch\n */\nexport async function indexRepositoryCase(\n  caseData: RepositoryCaseDocument\n): Promise<boolean> {\n  const client = getElasticsearchClient();\n  if (!client) return false;\n\n  try {\n    // Build searchable content from various fields\n    const searchableContent = [\n      caseData.name,\n      caseData.className,\n      caseData.tags?.map((t) => t.name).join(\" \"),\n      caseData.steps?.map((s) => {\n        const stepContent = `${s.step} ${s.expectedResult}`;\n        // Include shared step group name if it's a shared step\n        return s.isSharedStep && s.sharedStepGroupName \n          ? `${stepContent} ${s.sharedStepGroupName}`\n          : stepContent;\n      }).join(\" \"),\n      caseData.customFields?.map((cf) => cf.value).join(\" \"),\n    ]\n      .filter(Boolean)\n      .join(\" \");\n\n    await client.index({\n      index: REPOSITORY_CASE_INDEX,\n      id: caseData.id.toString(),\n      document: {\n        ...caseData,\n        searchableContent,\n      },\n    });\n\n    console.log(`Indexed repository case ${caseData.id} in Elasticsearch`);\n    return true;\n  } catch (error) {\n    console.error(`Failed to index repository case ${caseData.id}:`, error);\n    return false;\n  }\n}\n\n/**\n * Bulk index repository cases\n */\nexport async function bulkIndexRepositoryCases(\n  cases: RepositoryCaseDocument[]\n): Promise<boolean> {\n  const client = getElasticsearchClient();\n  if (!client || cases.length === 0) return false;\n\n  try {\n    const operations = cases.flatMap((caseData) => {\n      // Build searchable content\n      const searchableContent = [\n        caseData.name,\n        caseData.className,\n        caseData.tags?.map((t) => t.name).join(\" \"),\n        caseData.steps?.map((s) => {\n          const stepContent = `${s.step} ${s.expectedResult}`;\n          // Include shared step group name if it's a shared step\n          return s.isSharedStep && s.sharedStepGroupName \n            ? `${stepContent} ${s.sharedStepGroupName}`\n            : stepContent;\n        }).join(\" \"),\n        caseData.customFields?.map((cf) => cf.value).join(\" \"),\n      ]\n        .filter(Boolean)\n        .join(\" \");\n\n      return [\n        {\n          index: { _index: REPOSITORY_CASE_INDEX, _id: caseData.id.toString() },\n        },\n        { ...caseData, searchableContent },\n      ];\n    });\n\n    const bulkResponse = await client.bulk({\n      operations,\n      refresh: true,\n    });\n\n    if (bulkResponse.errors) {\n      const errorItems = bulkResponse.items.filter((item) => item.index?.error);\n      console.error(\"Bulk indexing errors:\", errorItems);\n      // Log detailed error information\n      errorItems.forEach((item) => {\n        if (item.index?.error) {\n          console.error(`Failed to index document ${item.index._id}:`);\n          console.error(`  Error type: ${item.index.error.type}`);\n          console.error(`  Error reason: ${item.index.error.reason}`);\n        }\n      });\n      return false;\n    }\n\n    console.log(\n      `Bulk indexed ${cases.length} repository cases in Elasticsearch`\n    );\n    return true;\n  } catch (error) {\n    console.error(\"Failed to bulk index repository cases:\", error);\n    return false;\n  }\n}\n\n/**\n * Delete a repository case from Elasticsearch\n */\nexport async function deleteRepositoryCase(caseId: number): Promise<boolean> {\n  const client = getElasticsearchClient();\n  if (!client) return false;\n\n  try {\n    await client.delete({\n      index: REPOSITORY_CASE_INDEX,\n      id: caseId.toString(),\n    });\n\n    console.log(`Deleted repository case ${caseId} from Elasticsearch`);\n    return true;\n  } catch (error) {\n    // 404 is expected if document doesn't exist\n    if ((error as any).statusCode === 404) {\n      console.log(\n        `Repository case ${caseId} not found in Elasticsearch (already deleted)`\n      );\n      return true;\n    }\n    console.error(`Failed to delete repository case ${caseId}:`, error);\n    return false;\n  }\n}\n", "/**\n * Recursively extracts text content from a JSON node structure\n * (commonly used in Tiptap/ProseMirror).\n */\nexport const extractTextFromNode = (node: any): string => {\n  if (!node) return \"\";\n\n  // If the node itself is just a string, return it\n  if (typeof node === \"string\") return node;\n\n  // If the node has a direct text property, return it\n  if (node.text && typeof node.text === \"string\") return node.text;\n\n  // If the node has a content array, recursively process each item\n  if (node.content && Array.isArray(node.content)) {\n    return node.content.map(extractTextFromNode).join(\"\"); // Join without spaces for raw text\n  }\n\n  // Return empty string if no text found or structure is unexpected\n  return \"\";\n};\n", "import { Client } from \"@elastic/elasticsearch\";\nimport { SearchableEntityType, CustomFieldDocument } from \"~/types/search\";\nimport { getElasticsearchClient } from \"./elasticsearchService\";\n\n// Re-export for convenience\nexport { getElasticsearchClient };\n\n// Index names for each entity type\nexport const ENTITY_INDICES = {\n  [SearchableEntityType.REPOSITORY_CASE]: \"testplanit-repository-cases\",\n  [SearchableEntityType.SHARED_STEP]: \"testplanit-shared-steps\",\n  [SearchableEntityType.TEST_RUN]: \"testplanit-test-runs\",\n  [SearchableEntityType.SESSION]: \"testplanit-sessions\",\n  [SearchableEntityType.PROJECT]: \"testplanit-projects\",\n  [SearchableEntityType.ISSUE]: \"testplanit-issues\",\n  [SearchableEntityType.MILESTONE]: \"testplanit-milestones\",\n} as const;\n\n// Base mapping for all entities\nconst baseMapping = {\n  properties: {\n    id: { type: \"integer\" as const },\n    projectId: { type: \"integer\" as const },\n    projectName: { type: \"keyword\" as const },\n    projectIconUrl: { type: \"keyword\" as const },\n    createdAt: { type: \"date\" as const },\n    updatedAt: { type: \"date\" as const },\n    createdById: { type: \"keyword\" as const },\n    createdByName: { type: \"keyword\" as const },\n    createdByImage: { type: \"keyword\" as const },\n    searchableContent: {\n      type: \"text\" as const,\n      analyzer: \"standard\",\n      fields: {\n        keyword: {\n          type: \"keyword\" as const,\n          ignore_above: 256,\n        },\n      },\n    },\n    customFields: {\n      type: \"nested\" as const,\n      properties: {\n        fieldId: { type: \"integer\" as const },\n        fieldName: { type: \"keyword\" as const },\n        fieldType: { type: \"keyword\" as const },\n        value: { type: \"text\" as const },\n        valueKeyword: { type: \"keyword\" as const },\n        valueNumeric: { type: \"double\" as const },\n        valueBoolean: { type: \"boolean\" as const },\n        valueDate: { type: \"date\" as const },\n        valueArray: { type: \"keyword\" as const },\n        fieldOption: {\n          type: \"object\" as const,\n          properties: {\n            id: { type: \"integer\" as const },\n            name: { type: \"keyword\" as const },\n            icon: {\n              type: \"object\" as const,\n              properties: {\n                name: { type: \"keyword\" as const },\n              },\n            },\n            iconColor: {\n              type: \"object\" as const,\n              properties: {\n                value: { type: \"keyword\" as const },\n              },\n            },\n          },\n        },\n        fieldOptions: {\n          type: \"nested\" as const,\n          properties: {\n            id: { type: \"integer\" as const },\n            name: { type: \"keyword\" as const },\n            icon: {\n              type: \"object\" as const,\n              properties: {\n                name: { type: \"keyword\" as const },\n              },\n            },\n            iconColor: {\n              type: \"object\" as const,\n              properties: {\n                value: { type: \"keyword\" as const },\n              },\n            },\n          },\n        },\n      },\n    },\n  },\n};\n\n// Entity-specific mappings\nexport const ENTITY_MAPPINGS = {\n  [SearchableEntityType.REPOSITORY_CASE]: {\n    properties: {\n      ...baseMapping.properties,\n      repositoryId: { type: \"integer\" as const },\n      folderId: { type: \"integer\" as const },\n      folderPath: { type: \"keyword\" as const },\n      templateId: { type: \"integer\" as const },\n      templateName: { type: \"keyword\" as const },\n      name: {\n        type: \"text\" as const,\n        analyzer: \"standard\",\n        fields: {\n          keyword: {\n            type: \"keyword\" as const,\n            ignore_above: 256,\n          },\n        },\n      },\n      className: { type: \"keyword\" as const },\n      source: { type: \"keyword\" as const },\n      stateId: { type: \"integer\" as const },\n      stateName: { type: \"keyword\" as const },\n      stateIcon: { type: \"keyword\" as const },\n      stateColor: { type: \"keyword\" as const },\n      estimate: { type: \"integer\" as const },\n      forecastManual: { type: \"integer\" as const },\n      forecastAutomated: { type: \"float\" as const },\n      automated: { type: \"boolean\" as const },\n      isArchived: { type: \"boolean\" as const },\n      isDeleted: { type: \"boolean\" as const },\n      tags: {\n        type: \"nested\" as const,\n        properties: {\n          id: { type: \"integer\" as const },\n          name: { type: \"keyword\" as const },\n        },\n      },\n      steps: {\n        type: \"nested\" as const,\n        properties: {\n          id: { type: \"integer\" as const },\n          order: { type: \"integer\" as const },\n          step: { type: \"text\" as const },\n          expectedResult: { type: \"text\" as const },\n          isSharedStep: { type: \"boolean\" as const },\n          sharedStepGroupId: { type: \"integer\" as const },\n          sharedStepGroupName: { type: \"text\" as const },\n        },\n      },\n    },\n  },\n  [SearchableEntityType.SHARED_STEP]: {\n    properties: {\n      ...baseMapping.properties,\n      name: {\n        type: \"text\" as const,\n        analyzer: \"standard\",\n        fields: {\n          keyword: {\n            type: \"keyword\" as const,\n            ignore_above: 256,\n          },\n        },\n      },\n      isDeleted: { type: \"boolean\" as const },\n      items: {\n        type: \"nested\" as const,\n        properties: {\n          id: { type: \"integer\" as const },\n          order: { type: \"integer\" as const },\n          step: { type: \"text\" as const },\n          expectedResult: { type: \"text\" as const },\n        },\n      },\n    },\n  },\n  [SearchableEntityType.TEST_RUN]: {\n    properties: {\n      ...baseMapping.properties,\n      name: {\n        type: \"text\" as const,\n        analyzer: \"standard\",\n        fields: {\n          keyword: {\n            type: \"keyword\" as const,\n            ignore_above: 256,\n          },\n        },\n      },\n      note: { type: \"text\" as const },\n      docs: { type: \"text\" as const },\n      configId: { type: \"integer\" as const },\n      configurationName: { type: \"keyword\" as const },\n      milestoneId: { type: \"integer\" as const },\n      milestoneName: { type: \"keyword\" as const },\n      stateId: { type: \"integer\" as const },\n      stateName: { type: \"keyword\" as const },\n      stateIcon: { type: \"keyword\" as const },\n      stateColor: { type: \"keyword\" as const },\n      forecastManual: { type: \"integer\" as const },\n      forecastAutomated: { type: \"float\" as const },\n      elapsed: { type: \"integer\" as const },\n      isCompleted: { type: \"boolean\" as const },\n      isDeleted: { type: \"boolean\" as const },\n      completedAt: { type: \"date\" as const },\n      testRunType: { type: \"keyword\" as const },\n      tags: {\n        type: \"nested\" as const,\n        properties: {\n          id: { type: \"integer\" as const },\n          name: { type: \"keyword\" as const },\n        },\n      },\n    },\n  },\n  [SearchableEntityType.SESSION]: {\n    properties: {\n      ...baseMapping.properties,\n      templateId: { type: \"integer\" as const },\n      templateName: { type: \"keyword\" as const },\n      name: {\n        type: \"text\" as const,\n        analyzer: \"standard\",\n        fields: {\n          keyword: {\n            type: \"keyword\" as const,\n            ignore_above: 256,\n          },\n        },\n      },\n      note: { type: \"text\" as const },\n      mission: { type: \"text\" as const },\n      configId: { type: \"integer\" as const },\n      configurationName: { type: \"keyword\" as const },\n      milestoneId: { type: \"integer\" as const },\n      milestoneName: { type: \"keyword\" as const },\n      stateId: { type: \"integer\" as const },\n      stateName: { type: \"keyword\" as const },\n      stateIcon: { type: \"keyword\" as const },\n      stateColor: { type: \"keyword\" as const },\n      assignedToId: { type: \"keyword\" as const },\n      assignedToName: { type: \"keyword\" as const },\n      assignedToImage: { type: \"keyword\" as const },\n      estimate: { type: \"integer\" as const },\n      forecastManual: { type: \"integer\" as const },\n      forecastAutomated: { type: \"float\" as const },\n      elapsed: { type: \"integer\" as const },\n      isCompleted: { type: \"boolean\" as const },\n      isDeleted: { type: \"boolean\" as const },\n      completedAt: { type: \"date\" as const },\n      tags: {\n        type: \"nested\" as const,\n        properties: {\n          id: { type: \"integer\" as const },\n          name: { type: \"keyword\" as const },\n        },\n      },\n    },\n  },\n  [SearchableEntityType.PROJECT]: {\n    properties: {\n      id: { type: \"integer\" as const },\n      name: {\n        type: \"text\" as const,\n        analyzer: \"standard\",\n        fields: {\n          keyword: {\n            type: \"keyword\" as const,\n            ignore_above: 256,\n          },\n        },\n      },\n      iconUrl: { type: \"keyword\" as const },\n      note: { type: \"text\" as const },\n      docs: { type: \"text\" as const },\n      isDeleted: { type: \"boolean\" as const },\n      createdAt: { type: \"date\" as const },\n      createdById: { type: \"keyword\" as const },\n      createdByName: { type: \"keyword\" as const },\n      createdByImage: { type: \"keyword\" as const },\n      searchableContent: { type: \"text\" as const },\n    },\n  },\n  [SearchableEntityType.ISSUE]: {\n    properties: {\n      ...baseMapping.properties,\n      name: {\n        type: \"text\" as const,\n        analyzer: \"standard\",\n        fields: {\n          keyword: {\n            type: \"keyword\" as const,\n            ignore_above: 256,\n          },\n        },\n      },\n      title: {\n        type: \"text\" as const,\n        analyzer: \"standard\",\n        fields: {\n          keyword: {\n            type: \"keyword\" as const,\n            ignore_above: 256,\n          },\n        },\n      },\n      description: { type: \"text\" as const },\n      externalId: { type: \"keyword\" as const },\n      note: { type: \"text\" as const },\n      url: { type: \"keyword\" as const },\n      issueSystem: { type: \"text\" as const },\n      isDeleted: { type: \"boolean\" as const },\n    },\n  },\n  [SearchableEntityType.MILESTONE]: {\n    properties: {\n      ...baseMapping.properties,\n      name: {\n        type: \"text\" as const,\n        analyzer: \"standard\",\n        fields: {\n          keyword: {\n            type: \"keyword\" as const,\n            ignore_above: 256,\n          },\n        },\n      },\n      note: { type: \"text\" as const },\n      docs: { type: \"text\" as const },\n      milestoneTypeId: { type: \"integer\" as const },\n      milestoneTypeName: { type: \"keyword\" as const },\n      milestoneTypeIcon: { type: \"keyword\" as const },\n      parentId: { type: \"integer\" as const },\n      parentName: { type: \"keyword\" as const },\n      dueDate: { type: \"date\" as const },\n      isCompleted: { type: \"boolean\" as const },\n      completedAt: { type: \"date\" as const },\n      isDeleted: { type: \"boolean\" as const },\n    },\n  },\n};\n\n/**\n * Get Elasticsearch replica settings from database\n */\nasync function getElasticsearchSettings() {\n  try {\n    const { PrismaClient } = await import(\"@prisma/client\");\n    const prisma = new PrismaClient();\n    \n    const config = await prisma.appConfig.findUnique({\n      where: { key: \"elasticsearch_replicas\" }\n    });\n    \n    await prisma.$disconnect();\n    \n    // Default to 0 for single-node clusters\n    return {\n      numberOfReplicas: config?.value ? (config.value as number) : 0\n    };\n  } catch (error) {\n    console.warn(\"Failed to get Elasticsearch settings from database, using defaults:\", error);\n    return { numberOfReplicas: 0 };\n  }\n}\n\n/**\n * Create index for a specific entity type\n */\nexport async function createEntityIndex(\n  entityType: SearchableEntityType\n): Promise<boolean> {\n  const client = getElasticsearchClient();\n  if (!client) return false;\n\n  const indexName = ENTITY_INDICES[entityType];\n  const mapping = ENTITY_MAPPINGS[entityType];\n\n  try {\n    // Get settings from database\n    const settings = await getElasticsearchSettings();\n    \n    const indexExists = await client.indices.exists({ index: indexName });\n\n    if (!indexExists) {\n      await client.indices.create({\n        index: indexName,\n        mappings: mapping,\n        settings: {\n          number_of_shards: 1,\n          number_of_replicas: settings.numberOfReplicas,\n          analysis: {\n            analyzer: {\n              standard: {\n                type: \"standard\",\n                stopwords: \"_english_\",\n              },\n            },\n          },\n        },\n      });\n\n      return true;\n    }\n\n    return true;\n  } catch (error) {\n    console.error(`Failed to create index for ${entityType}:`, error);\n    return false;\n  }\n}\n\n/**\n * Create all entity indices\n */\nexport async function createAllEntityIndices(): Promise<void> {\n  const entityTypes = Object.values(SearchableEntityType);\n\n  for (const entityType of entityTypes) {\n    await createEntityIndex(entityType);\n  }\n}\n\n/**\n * Transform custom field values based on field type\n */\nexport function transformCustomFieldValue(\n  fieldType: string,\n  value: any\n): Partial<CustomFieldDocument> {\n  const base: Partial<CustomFieldDocument> = {};\n\n  switch (fieldType) {\n    case \"Checkbox\":\n      base.valueBoolean = Boolean(value);\n      base.value = String(value);\n      break;\n\n    case \"Date\":\n      if (value) {\n        const date = new Date(value);\n        if (!isNaN(date.getTime())) {\n          base.valueDate = date.toISOString();\n          base.value = date.toISOString();\n        }\n      }\n      break;\n\n    case \"Number\":\n      base.valueNumeric = Number(value);\n      base.value = String(value);\n      break;\n\n    case \"Multi-Select\":\n      if (Array.isArray(value)) {\n        base.valueArray = value.map((v) => String(v));\n        base.value = value.join(\" \");\n      } else if (value) {\n        // Handle case where value might be a JSON string\n        try {\n          const parsed = JSON.parse(value);\n          if (Array.isArray(parsed)) {\n            base.valueArray = parsed.map((v) => String(v));\n            base.value = parsed.join(\" \");\n          }\n        } catch {\n          base.value = String(value);\n        }\n      }\n      break;\n\n    case \"Select\":\n      base.valueKeyword = String(value);\n      base.value = String(value);\n      break;\n\n    case \"Text String\":\n    case \"Link\":\n      base.valueKeyword = String(value);\n      base.value = String(value);\n      break;\n\n    case \"Text Long\":\n      // Extract text from TipTap JSON\n      if (value) {\n        try {\n          const content = typeof value === \"string\" ? JSON.parse(value) : value;\n          const textContent = extractTextFromTipTap(content);\n          base.value = textContent;\n        } catch {\n          base.value = String(value);\n        }\n      }\n      break;\n\n    case \"Steps\":\n      // Steps are handled separately in the steps array\n      if (value) {\n        base.value = String(value);\n      }\n      break;\n\n    default:\n      base.value = String(value);\n  }\n\n  return base;\n}\n\n/**\n * Extract plain text from TipTap JSON content\n */\nfunction extractTextFromTipTap(content: any): string {\n  if (!content || !content.content) return \"\";\n\n  let text = \"\";\n\n  function extractFromNode(node: any) {\n    if (node.text) {\n      text += node.text + \" \";\n    }\n    if (node.content) {\n      node.content.forEach(extractFromNode);\n    }\n  }\n\n  content.content.forEach(extractFromNode);\n  return text.trim();\n}\n\n/**\n * Build custom field documents for indexing\n */\nexport function buildCustomFieldDocuments(\n  fieldValues: Array<{\n    fieldId: number;\n    field: {\n      displayName: string;\n      systemName: string;\n      type?: { type: string };\n      fieldOptions?: Array<{\n        fieldOption: {\n          id: number;\n          name: string;\n          icon?: { name: string };\n          iconColor?: { value: string };\n        };\n      }>;\n    };\n    value: any;\n  }>\n): CustomFieldDocument[] {\n  return fieldValues.map((cfv) => {\n    const fieldType = cfv.field.type?.type || cfv.field.systemName;\n    const transformed = transformCustomFieldValue(fieldType, cfv.value);\n\n    const doc: CustomFieldDocument = {\n      fieldId: cfv.fieldId,\n      fieldName: cfv.field.displayName,\n      fieldType: fieldType,\n      ...transformed,\n    };\n\n    // For single select/dropdown fields, find the selected option\n    if (\n      cfv.value &&\n      cfv.field.fieldOptions &&\n      (fieldType === \"Select\" || fieldType === \"Dropdown\")\n    ) {\n      const selectedOption = cfv.field.fieldOptions.find(\n        (fo) => fo.fieldOption.id === cfv.value\n      );\n      if (selectedOption) {\n        doc.fieldOption = {\n          id: selectedOption.fieldOption.id,\n          name: selectedOption.fieldOption.name,\n          icon: selectedOption.fieldOption.icon,\n          iconColor: selectedOption.fieldOption.iconColor,\n        };\n      }\n    }\n\n    // Add all field options for multi-select fields\n    if (cfv.field.fieldOptions && fieldType === \"Multi-Select\") {\n      doc.fieldOptions = cfv.field.fieldOptions.map((fo) => ({\n        id: fo.fieldOption.id,\n        name: fo.fieldOption.name,\n        icon: fo.fieldOption.icon,\n        iconColor: fo.fieldOption.iconColor,\n      }));\n    }\n\n    return doc;\n  });\n}\n\n/**\n * Get all indices for a list of entity types\n */\nexport function getIndicesForEntityTypes(\n  entityTypes?: SearchableEntityType[]\n): string[] {\n  if (!entityTypes || entityTypes.length === 0) {\n    return Object.values(ENTITY_INDICES);\n  }\n\n  return entityTypes.map((type) => ENTITY_INDICES[type]);\n}\n\n/**\n * Build aggregations for faceted search\n */\nexport function buildAggregations(\n  facets: string[],\n  entityTypes?: SearchableEntityType[]\n): Record<string, any> {\n  const aggs: Record<string, any> = {};\n\n  // Common facets\n  if (facets.includes(\"projects\") || facets.includes(\"projectId\")) {\n    aggs.projects = {\n      terms: {\n        field: \"projectId\",\n        size: 100,\n      },\n    };\n  }\n\n  if (facets.includes(\"states\") || facets.includes(\"stateId\")) {\n    aggs.states = {\n      terms: {\n        field: \"stateId\",\n        size: 50,\n      },\n    };\n  }\n\n  if (facets.includes(\"tags\") || facets.includes(\"tagIds\")) {\n    aggs.tags = {\n      terms: {\n        field: \"tagIds\",\n        size: 100,\n      },\n    };\n  }\n\n  if (facets.includes(\"creators\") || facets.includes(\"creatorId\")) {\n    aggs.creators = {\n      terms: {\n        field: \"createdById.keyword\",\n        size: 100,\n      },\n    };\n  }\n\n  // Entity-specific aggregations\n  if (\n    !entityTypes ||\n    entityTypes.includes(SearchableEntityType.REPOSITORY_CASE)\n  ) {\n    if (facets.includes(\"folders\") || facets.includes(\"folderId\")) {\n      aggs.folders = {\n        terms: {\n          field: \"folderId\",\n          size: 50,\n        },\n      };\n    }\n\n    if (facets.includes(\"templates\") || facets.includes(\"templateId\")) {\n      aggs.templates = {\n        terms: {\n          field: \"templateId\",\n          size: 50,\n        },\n      };\n    }\n\n    if (facets.includes(\"automated\")) {\n      aggs.automated = {\n        terms: {\n          field: \"automated\",\n        },\n      };\n    }\n  }\n\n  if (!entityTypes || entityTypes.includes(SearchableEntityType.TEST_RUN)) {\n    if (\n      facets.includes(\"configurations\") ||\n      facets.includes(\"configurationId\")\n    ) {\n      aggs.configurations = {\n        terms: {\n          field: \"configurationId\",\n          size: 50,\n        },\n      };\n    }\n\n    if (facets.includes(\"milestones\") || facets.includes(\"milestoneId\")) {\n      aggs.milestones = {\n        terms: {\n          field: \"milestoneId\",\n          size: 50,\n        },\n      };\n    }\n\n    if (facets.includes(\"testRunType\")) {\n      aggs.testRunType = {\n        terms: {\n          field: \"testRunType\",\n        },\n      };\n    }\n  }\n\n  if (!entityTypes || entityTypes.includes(SearchableEntityType.SESSION)) {\n    if (facets.includes(\"assignedTo\") || facets.includes(\"assignedToId\")) {\n      aggs.assignedTo = {\n        terms: {\n          field: \"assignedToId.keyword\",\n          size: 100,\n        },\n      };\n    }\n  }\n\n  // Entity type counts\n  aggs.entityTypes = {\n    terms: {\n      field: \"_index\",\n      size: 10,\n    },\n  };\n\n  return aggs;\n}\n", "import {\n  getElasticsearchClient,\n  ENTITY_INDICES,\n} from \"./unifiedElasticsearchService\";\nimport { SearchableEntityType } from \"~/types/search\";\nimport type { TestRuns, Prisma } from \"@prisma/client\";\nimport { PrismaClient } from \"@prisma/client\";\nimport { extractTextFromNode } from \"~/utils/extractTextFromJson\";\n\nconst prisma = new PrismaClient();\n\n/**\n * Type for test run with all required relations for indexing\n */\ntype TestRunForIndexing = TestRuns & {\n  project: { name: string };\n  createdBy: { name: string };\n  state: { name: string };\n  configuration?: { name: string } | null;\n  milestone?: { name: string } | null;\n  tags: Array<{ id: number; name: string }>;\n};\n\n/**\n * Index a single test run to Elasticsearch\n */\nexport async function indexTestRun(testRun: TestRunForIndexing): Promise<void> {\n  const client = getElasticsearchClient();\n  if (!client) {\n    throw new Error(\"Elasticsearch client not available\");\n  }\n\n  const searchableContent = [\n    testRun.name,\n    testRun.note ? extractTextFromNode(testRun.note) : \"\",\n    testRun.docs ? extractTextFromNode(testRun.docs) : \"\",\n    testRun.tags.map((t) => t.name).join(\" \"),\n  ].join(\" \");\n\n  const document = {\n    id: testRun.id,\n    projectId: testRun.projectId,\n    projectName: testRun.project.name,\n    name: testRun.name,\n    note: testRun.note,\n    docs: testRun.docs,\n    configId: testRun.configId,\n    configurationName: testRun.configuration?.name,\n    milestoneId: testRun.milestoneId,\n    milestoneName: testRun.milestone?.name,\n    stateId: testRun.stateId,\n    stateName: testRun.state.name,\n    forecastManual: testRun.forecastManual,\n    forecastAutomated: testRun.forecastAutomated,\n    elapsed: testRun.elapsed,\n    isCompleted: testRun.isCompleted,\n    isDeleted: testRun.isDeleted,\n    completedAt: testRun.completedAt,\n    testRunType: testRun.testRunType,\n    createdAt: testRun.createdAt,\n    createdById: testRun.createdById,\n    createdByName: testRun.createdBy.name,\n    tags: testRun.tags.map((tag) => ({ id: tag.id, name: tag.name })),\n    searchableContent,\n  };\n\n  await client.index({\n    index: ENTITY_INDICES[SearchableEntityType.TEST_RUN],\n    id: testRun.id.toString(),\n    document,\n    refresh: true,\n  });\n}\n\n/**\n * Delete a test run from Elasticsearch\n */\nexport async function deleteTestRunFromIndex(testRunId: number): Promise<void> {\n  const client = getElasticsearchClient();\n  if (!client) {\n    console.warn(\"Elasticsearch client not available\");\n    return;\n  }\n\n  try {\n    await client.delete({\n      index: ENTITY_INDICES[SearchableEntityType.TEST_RUN],\n      id: testRunId.toString(),\n      refresh: true,\n    });\n  } catch (error: any) {\n    if (error.meta?.statusCode !== 404) {\n      console.error(\"Failed to delete test run from index:\", error);\n    }\n  }\n}\n\n/**\n * Sync a single test run to Elasticsearch\n */\nexport async function syncTestRunToElasticsearch(testRunId: number): Promise<boolean> {\n  const client = getElasticsearchClient();\n  if (!client) {\n    console.warn(\"Elasticsearch client not available\");\n    return false;\n  }\n\n  try {\n    const testRun = await prisma.testRuns.findUnique({\n      where: { id: testRunId },\n      include: {\n        project: true,\n        createdBy: true,\n        state: true,\n        configuration: true,\n        milestone: true,\n        tags: true,\n      },\n    });\n\n    if (!testRun) {\n      console.warn(`Test run ${testRunId} not found`);\n      return false;\n    }\n\n    // Index test run including deleted ones (filtering happens at search time based on admin permissions)\n\n    // Index the test run\n    await indexTestRun(testRun as TestRunForIndexing);\n    return true;\n  } catch (error) {\n    console.error(`Failed to sync test run ${testRunId}:`, error);\n    return false;\n  }\n}\n\n/**\n * Bulk index test runs for a project\n */\nexport async function syncProjectTestRunsToElasticsearch(\n  projectId: number,\n  db: any\n): Promise<void> {\n  const client = getElasticsearchClient();\n  if (!client) {\n    console.warn(\"Elasticsearch client not available\");\n    return;\n  }\n\n  console.log(`Starting test run sync for project ${projectId}`);\n\n  const testRuns = await db.testRuns.findMany({\n    where: {\n      projectId: projectId,\n      // Include deleted items (filtering happens at search time based on admin permissions)\n    },\n    include: {\n      project: true,\n      createdBy: true,\n      state: true,\n      configuration: true,\n      milestone: true,\n      tags: true,\n    },\n  });\n\n  if (testRuns.length === 0) {\n    console.log(\"No test runs to index\");\n    return;\n  }\n\n  const bulkBody = [];\n  for (const testRun of testRuns) {\n    const searchableContent = [\n      testRun.name,\n      testRun.note ? extractTextFromNode(testRun.note) : \"\",\n      testRun.docs ? extractTextFromNode(testRun.docs) : \"\",\n      testRun.tags.map((t: any) => t.name).join(\" \"),\n    ].join(\" \");\n\n    bulkBody.push({\n      index: {\n        _index: ENTITY_INDICES[SearchableEntityType.TEST_RUN],\n        _id: testRun.id.toString(),\n      },\n    });\n\n    bulkBody.push({\n      id: testRun.id,\n      projectId: testRun.projectId,\n      projectName: testRun.project.name,\n      name: testRun.name,\n      note: testRun.note,\n      docs: testRun.docs,\n      configId: testRun.configId,\n      configurationName: testRun.configuration?.name,\n      milestoneId: testRun.milestoneId,\n      milestoneName: testRun.milestone?.name,\n      stateId: testRun.stateId,\n      stateName: testRun.state.name,\n      forecastManual: testRun.forecastManual,\n      forecastAutomated: testRun.forecastAutomated,\n      elapsed: testRun.elapsed,\n      isCompleted: testRun.isCompleted,\n      isDeleted: testRun.isDeleted,\n      completedAt: testRun.completedAt,\n      testRunType: testRun.testRunType,\n      createdAt: testRun.createdAt,\n      createdById: testRun.createdById,\n      createdByName: testRun.createdBy.name,\n      tags: testRun.tags.map((tag: any) => ({ id: tag.id, name: tag.name })),\n      searchableContent,\n    });\n  }\n\n  try {\n    const bulkResponse = await client.bulk({ body: bulkBody, refresh: true });\n\n    if (bulkResponse.errors) {\n      const errors = bulkResponse.items.filter(\n        (item: any) => item.index?.error\n      );\n      console.error(\"Bulk indexing errors:\", errors);\n    } else {\n      console.log(`Successfully indexed ${testRuns.length} test runs`);\n    }\n  } catch (error) {\n    console.error(\"Failed to bulk index test runs:\", error);\n    throw error;\n  }\n}\n\n/**\n * Search for test runs\n */\nexport async function searchTestRuns(params: {\n  query?: string;\n  projectIds?: number[];\n  stateIds?: number[];\n  configurationIds?: number[];\n  milestoneIds?: number[];\n  isCompleted?: boolean;\n  testRunType?: string;\n  customFields?: Array<{\n    fieldId: number;\n    fieldType: string;\n    operator: string;\n    value: any;\n    value2?: any;\n  }>;\n  from?: number;\n  size?: number;\n  sort?: Array<{ field: string; order: \"asc\" | \"desc\" }>;\n}): Promise<{\n  hits: any[];\n  total: number;\n  took: number;\n}> {\n  const client = getElasticsearchClient();\n  if (!client) {\n    return { hits: [], total: 0, took: 0 };\n  }\n\n  const must: any[] = [];\n  const filter: any[] = [];\n\n  // Add query\n  if (params.query) {\n    must.push({\n      multi_match: {\n        query: params.query,\n        fields: [\n          \"name^3\",\n          \"searchableContent\",\n          \"note\",\n          \"docs\",\n          \"customFields.value\",\n        ],\n        type: \"best_fields\",\n        operator: \"or\",\n        fuzziness: \"AUTO\",\n      },\n    });\n  }\n\n  // Add filters\n  if (params.projectIds && params.projectIds.length > 0) {\n    filter.push({ terms: { projectId: params.projectIds } });\n  }\n  if (params.stateIds && params.stateIds.length > 0) {\n    filter.push({ terms: { stateId: params.stateIds } });\n  }\n  if (params.configurationIds && params.configurationIds.length > 0) {\n    filter.push({ terms: { configId: params.configurationIds } });\n  }\n  if (params.milestoneIds && params.milestoneIds.length > 0) {\n    filter.push({ terms: { milestoneId: params.milestoneIds } });\n  }\n  if (typeof params.isCompleted === \"boolean\") {\n    filter.push({ term: { isCompleted: params.isCompleted } });\n  }\n  if (params.testRunType) {\n    filter.push({ term: { testRunType: params.testRunType } });\n  }\n\n  // Add custom field filters\n  if (params.customFields) {\n    // Implementation would be similar to repository case custom field filters\n  }\n\n  const searchBody: any = {\n    index: ENTITY_INDICES[SearchableEntityType.TEST_RUN],\n    from: params.from || 0,\n    size: params.size || 20,\n    query: {\n      bool: {\n        must,\n        filter,\n      },\n    },\n    highlight: {\n      fields: {\n        name: { number_of_fragments: 1 },\n        searchableContent: { number_of_fragments: 3 },\n        note: { number_of_fragments: 2 },\n        docs: { number_of_fragments: 2 },\n      },\n      pre_tags: ['<mark class=\"search-highlight\">'],\n      post_tags: [\"</mark>\"],\n    },\n  };\n\n  // Add sorting\n  if (params.sort && params.sort.length > 0) {\n    searchBody.sort = params.sort.map((s) => ({\n      [s.field]: { order: s.order },\n    }));\n  }\n\n  try {\n    const response = await client.search(searchBody);\n    return {\n      hits: response.hits.hits,\n      total:\n        typeof response.hits.total === \"object\"\n          ? response.hits.total.value\n          : response.hits.total || 0,\n      took: response.took,\n    };\n  } catch (error) {\n    console.error(\"Test run search error:\", error);\n    return { hits: [], total: 0, took: 0 };\n  }\n}\n", "import {\n  getElasticsearchClient,\n  ENTITY_INDICES,\n} from \"./unifiedElasticsearchService\";\nimport { SearchableEntityType } from \"~/types/search\";\nimport type { Sessions, Prisma } from \"@prisma/client\";\nimport { PrismaClient } from \"@prisma/client\";\nimport { extractTextFromNode } from \"~/utils/extractTextFromJson\";\n\nconst prisma = new PrismaClient();\n\n/**\n * Type for session with all required relations for indexing\n */\ntype SessionForIndexing = Sessions & {\n  project: { name: string };\n  createdBy: { name: string };\n  assignedTo?: { name: string } | null;\n  state: { name: string };\n  template: { templateName: string };\n  configuration?: { name: string } | null;\n  milestone?: { name: string } | null;\n  tags: Array<{ id: number; name: string }>;\n  sessionFields?: Array<{\n    fieldId: number;\n    field: {\n      displayName: string;\n      systemName: string;\n      type?: { type: string };\n    };\n    value: any;\n  }>;\n};\n\n/**\n * Index a single session to Elasticsearch\n */\nexport async function indexSession(session: SessionForIndexing): Promise<void> {\n  const client = getElasticsearchClient();\n  if (!client) {\n    throw new Error(\"Elasticsearch client not available\");\n  }\n\n  const searchableContent = [\n    session.name,\n    session.note ? extractTextFromNode(session.note) : \"\",\n    session.mission ? extractTextFromNode(session.mission) : \"\",\n    session.tags.map((t) => t.name).join(\" \"),\n  ].join(\" \");\n\n\n  const document = {\n    id: session.id,\n    projectId: session.projectId,\n    projectName: session.project.name,\n    templateId: session.templateId,\n    templateName: session.template.templateName,\n    name: session.name,\n    note: session.note,\n    mission: session.mission,\n    configId: session.configId,\n    configurationName: session.configuration?.name,\n    milestoneId: session.milestoneId,\n    milestoneName: session.milestone?.name,\n    stateId: session.stateId,\n    stateName: session.state.name,\n    assignedToId: session.assignedToId,\n    assignedToName: session.assignedTo?.name,\n    estimate: session.estimate,\n    forecastManual: session.forecastManual,\n    forecastAutomated: session.forecastAutomated,\n    elapsed: session.elapsed,\n    isCompleted: session.isCompleted,\n    isDeleted: session.isDeleted,\n    completedAt: session.completedAt,\n    createdAt: session.createdAt,\n    createdById: session.createdById,\n    createdByName: session.createdBy.name,\n    tags: session.tags.map((tag) => ({ id: tag.id, name: tag.name })),\n    searchableContent,\n  };\n\n  await client.index({\n    index: ENTITY_INDICES[SearchableEntityType.SESSION],\n    id: session.id.toString(),\n    document,\n    refresh: true,\n  });\n}\n\n/**\n * Delete a session from Elasticsearch\n */\nexport async function deleteSessionFromIndex(sessionId: number): Promise<void> {\n  const client = getElasticsearchClient();\n  if (!client) {\n    console.warn(\"Elasticsearch client not available\");\n    return;\n  }\n\n  try {\n    await client.delete({\n      index: ENTITY_INDICES[SearchableEntityType.SESSION],\n      id: sessionId.toString(),\n      refresh: true,\n    });\n  } catch (error: any) {\n    if (error.meta?.statusCode !== 404) {\n      console.error(\"Failed to delete session from index:\", error);\n    }\n  }\n}\n\n/**\n * Sync a single session to Elasticsearch\n */\nexport async function syncSessionToElasticsearch(sessionId: number): Promise<boolean> {\n  const client = getElasticsearchClient();\n  if (!client) {\n    console.warn(\"Elasticsearch client not available\");\n    return false;\n  }\n\n  try {\n    const session = await prisma.sessions.findUnique({\n      where: { id: sessionId },\n      include: {\n        project: true,\n        createdBy: true,\n        assignedTo: true,\n        state: true,\n        template: true,\n        configuration: true,\n        milestone: true,\n        tags: true,\n      },\n    });\n\n    if (!session) {\n      console.warn(`Session ${sessionId} not found`);\n      return false;\n    }\n\n    // Index session including deleted ones (filtering happens at search time based on admin permissions)\n\n    // Index the session\n    await indexSession(session as SessionForIndexing);\n    return true;\n  } catch (error) {\n    console.error(`Failed to sync session ${sessionId}:`, error);\n    return false;\n  }\n}\n\n/**\n * Bulk index sessions for a project\n */\nexport async function syncProjectSessionsToElasticsearch(\n  projectId: number,\n  db: any\n): Promise<void> {\n  const client = getElasticsearchClient();\n  if (!client) {\n    console.warn(\"Elasticsearch client not available\");\n    return;\n  }\n\n\n  const sessions = await db.sessions.findMany({\n    where: {\n      projectId: projectId,\n      // Include deleted items (filtering happens at search time based on admin permissions)\n    },\n    include: {\n      project: true,\n      createdBy: true,\n      assignedTo: true,\n      state: true,\n      template: true,\n      configuration: true,\n      milestone: true,\n      tags: true,\n    },\n  });\n\n  if (sessions.length === 0) {\n    return;\n  }\n\n  const bulkBody = [];\n  for (const session of sessions) {\n    const searchableContent = [\n      session.name,\n      session.note ? extractTextFromNode(session.note) : \"\",\n      session.mission ? extractTextFromNode(session.mission) : \"\",\n      session.tags.map((t: any) => t.name).join(\" \"),\n    ].join(\" \");\n\n\n    bulkBody.push({\n      index: {\n        _index: ENTITY_INDICES[SearchableEntityType.SESSION],\n        _id: session.id.toString(),\n      },\n    });\n\n    bulkBody.push({\n      id: session.id,\n      projectId: session.projectId,\n      projectName: session.project.name,\n      templateId: session.templateId,\n      templateName: session.template.templateName,\n      name: session.name,\n      note: session.note,\n      mission: session.mission,\n      configId: session.configId,\n      configurationName: session.configuration?.name,\n      milestoneId: session.milestoneId,\n      milestoneName: session.milestone?.name,\n      stateId: session.stateId,\n      stateName: session.state.name,\n      assignedToId: session.assignedToId,\n      assignedToName: session.assignedTo?.name,\n      estimate: session.estimate,\n      forecastManual: session.forecastManual,\n      forecastAutomated: session.forecastAutomated,\n      elapsed: session.elapsed,\n      isCompleted: session.isCompleted,\n      isDeleted: session.isDeleted,\n      completedAt: session.completedAt,\n      createdAt: session.createdAt,\n      createdById: session.createdById,\n      createdByName: session.createdBy.name,\n      tags: session.tags.map((tag: any) => ({ id: tag.id, name: tag.name })),\n      searchableContent,\n    });\n  }\n\n  try {\n    const bulkResponse = await client.bulk({ body: bulkBody, refresh: true });\n\n    if (bulkResponse.errors) {\n      const errors = bulkResponse.items.filter(\n        (item: any) => item.index?.error\n      );\n      console.error(\"Bulk indexing errors:\", errors);\n    } else {\n    }\n  } catch (error) {\n    console.error(\"Failed to bulk index sessions:\", error);\n    throw error;\n  }\n}\n\n/**\n * Search for sessions\n */\nexport async function searchSessions(params: {\n  query?: string;\n  projectIds?: number[];\n  templateIds?: number[];\n  stateIds?: number[];\n  assignedToIds?: string[];\n  configurationIds?: number[];\n  milestoneIds?: number[];\n  isCompleted?: boolean;\n  customFields?: Array<{\n    fieldId: number;\n    fieldType: string;\n    operator: string;\n    value: any;\n    value2?: any;\n  }>;\n  from?: number;\n  size?: number;\n  sort?: Array<{ field: string; order: \"asc\" | \"desc\" }>;\n}): Promise<{\n  hits: any[];\n  total: number;\n  took: number;\n}> {\n  const client = getElasticsearchClient();\n  if (!client) {\n    return { hits: [], total: 0, took: 0 };\n  }\n\n  const must: any[] = [];\n  const filter: any[] = [];\n\n  // Add query\n  if (params.query) {\n    must.push({\n      multi_match: {\n        query: params.query,\n        fields: [\n          \"name^3\",\n          \"searchableContent\",\n          \"note\",\n          \"mission\",\n          \"customFields.value\",\n        ],\n        type: \"best_fields\",\n        operator: \"or\",\n        fuzziness: \"AUTO\",\n      },\n    });\n  }\n\n  // Add filters\n  if (params.projectIds && params.projectIds.length > 0) {\n    filter.push({ terms: { projectId: params.projectIds } });\n  }\n  if (params.templateIds && params.templateIds.length > 0) {\n    filter.push({ terms: { templateId: params.templateIds } });\n  }\n  if (params.stateIds && params.stateIds.length > 0) {\n    filter.push({ terms: { stateId: params.stateIds } });\n  }\n  if (params.assignedToIds && params.assignedToIds.length > 0) {\n    filter.push({ terms: { assignedToId: params.assignedToIds } });\n  }\n  if (params.configurationIds && params.configurationIds.length > 0) {\n    filter.push({ terms: { configId: params.configurationIds } });\n  }\n  if (params.milestoneIds && params.milestoneIds.length > 0) {\n    filter.push({ terms: { milestoneId: params.milestoneIds } });\n  }\n  if (typeof params.isCompleted === \"boolean\") {\n    filter.push({ term: { isCompleted: params.isCompleted } });\n  }\n\n  // Add custom field filters\n  if (params.customFields) {\n    // Implementation would be similar to repository case custom field filters\n  }\n\n  const searchBody: any = {\n    index: ENTITY_INDICES[SearchableEntityType.SESSION],\n    from: params.from || 0,\n    size: params.size || 20,\n    query: {\n      bool: {\n        must,\n        filter,\n      },\n    },\n    highlight: {\n      fields: {\n        name: { number_of_fragments: 1 },\n        searchableContent: { number_of_fragments: 3 },\n        note: { number_of_fragments: 2 },\n        mission: { number_of_fragments: 2 },\n      },\n      pre_tags: ['<mark class=\"search-highlight\">'],\n      post_tags: [\"</mark>\"],\n    },\n  };\n\n  // Add sorting\n  if (params.sort && params.sort.length > 0) {\n    searchBody.sort = params.sort.map((s) => ({\n      [s.field]: { order: s.order },\n    }));\n  }\n\n  try {\n    const response = await client.search(searchBody);\n    return {\n      hits: response.hits.hits,\n      total:\n        typeof response.hits.total === \"object\"\n          ? response.hits.total.value\n          : response.hits.total || 0,\n      took: response.took,\n    };\n  } catch (error) {\n    console.error(\"Session search error:\", error);\n    return { hits: [], total: 0, took: 0 };\n  }\n}\n", "import { PrismaClient } from \"@prisma/client\";\nimport {\n  getElasticsearchClient,\n  ENTITY_INDICES,\n  createEntityIndex,\n} from \"./unifiedElasticsearchService\";\nimport { SearchableEntityType } from \"~/types/search\";\nimport { extractTextFromNode } from \"~/utils/extractTextFromJson\";\n\nconst prisma = new PrismaClient();\n\n/**\n * Document structure for shared steps in Elasticsearch\n */\nexport interface SharedStepDocument {\n  id: number;\n  name: string;\n  projectId: number;\n  projectName: string;\n  projectIconUrl?: string | null;\n  createdAt: Date;\n  createdById: string;\n  createdByName: string;\n  createdByImage?: string | null;\n  isDeleted: boolean;\n  items: Array<{\n    id: number;\n    order: number;\n    step: string;\n    expectedResult: string;\n  }>;\n  searchableContent: string;\n}\n\n/**\n * Build a shared step document for Elasticsearch from Prisma data\n */\nexport async function buildSharedStepDocument(\n  stepGroupId: number\n): Promise<SharedStepDocument | null> {\n  const stepGroup = await prisma.sharedStepGroup.findUnique({\n    where: { id: stepGroupId },\n    include: {\n      project: true,\n      createdBy: true,\n      items: {\n        orderBy: { order: \"asc\" },\n      },\n    },\n  });\n\n  if (!stepGroup) return null;\n\n  // Build searchable content from name and step items\n  const searchableContent = [\n    stepGroup.name,\n    ...stepGroup.items.map((item) => {\n      let stepText = \"\";\n      let expectedResultText = \"\";\n\n      // Handle step field\n      if (typeof item.step === \"string\") {\n        try {\n          const parsed = JSON.parse(item.step);\n          stepText = extractTextFromNode(parsed);\n        } catch {\n          stepText = item.step;\n        }\n      } else if (item.step) {\n        stepText = extractTextFromNode(item.step);\n      }\n\n      // Handle expectedResult field\n      if (typeof item.expectedResult === \"string\") {\n        try {\n          const parsed = JSON.parse(item.expectedResult);\n          expectedResultText = extractTextFromNode(parsed);\n        } catch {\n          expectedResultText = item.expectedResult;\n        }\n      } else if (item.expectedResult) {\n        expectedResultText = extractTextFromNode(item.expectedResult);\n      }\n\n      return `${stepText} ${expectedResultText}`;\n    }),\n  ].join(\" \");\n\n  return {\n    id: stepGroup.id,\n    name: stepGroup.name,\n    projectId: stepGroup.projectId,\n    projectName: stepGroup.project.name,\n    projectIconUrl: stepGroup.project.iconUrl,\n    createdAt: stepGroup.createdAt,\n    createdById: stepGroup.createdById,\n    createdByName: stepGroup.createdBy.name,\n    createdByImage: stepGroup.createdBy.image,\n    isDeleted: stepGroup.isDeleted,\n    items: stepGroup.items.map((item) => ({\n      id: item.id,\n      order: item.order,\n      step:\n        typeof item.step === \"object\"\n          ? JSON.stringify(item.step)\n          : String(item.step),\n      expectedResult:\n        typeof item.expectedResult === \"object\"\n          ? JSON.stringify(item.expectedResult)\n          : String(item.expectedResult),\n    })),\n    searchableContent,\n  };\n}\n\n/**\n * Index a shared step group in Elasticsearch\n */\nexport async function indexSharedStep(\n  stepData: SharedStepDocument\n): Promise<boolean> {\n  const client = getElasticsearchClient();\n  if (!client) return false;\n\n  try {\n    await client.index({\n      index: ENTITY_INDICES[SearchableEntityType.SHARED_STEP],\n      id: stepData.id.toString(),\n      document: stepData,\n    });\n\n    console.log(`Indexed shared step ${stepData.id} in Elasticsearch`);\n    return true;\n  } catch (error) {\n    console.error(`Failed to index shared step ${stepData.id}:`, error);\n    return false;\n  }\n}\n\n/**\n * Delete a shared step from Elasticsearch\n */\nexport async function deleteSharedStep(stepId: number): Promise<boolean> {\n  const client = getElasticsearchClient();\n  if (!client) return false;\n\n  try {\n    await client.delete({\n      index: ENTITY_INDICES[SearchableEntityType.SHARED_STEP],\n      id: stepId.toString(),\n    });\n\n    console.log(`Deleted shared step ${stepId} from Elasticsearch`);\n    return true;\n  } catch (error) {\n    // 404 is expected if document doesn't exist\n    if ((error as any).statusCode === 404) {\n      console.log(\n        `Shared step ${stepId} not found in Elasticsearch (already deleted)`\n      );\n      return true;\n    }\n    console.error(`Failed to delete shared step ${stepId}:`, error);\n    return false;\n  }\n}\n\n/**\n * Sync a shared step to Elasticsearch after create/update\n */\nexport async function syncSharedStepToElasticsearch(\n  stepId: number\n): Promise<boolean> {\n  const doc = await buildSharedStepDocument(stepId);\n  if (!doc) return false;\n\n  // Index shared step including deleted ones (filtering happens at search time based on admin permissions)\n  return await indexSharedStep(doc);\n}\n\n/**\n * Sync all shared steps for a project to Elasticsearch\n */\nexport async function syncProjectSharedStepsToElasticsearch(\n  projectId: number,\n  batchSize: number = 100\n): Promise<boolean> {\n  try {\n    // Ensure index exists\n    await createEntityIndex(SearchableEntityType.SHARED_STEP);\n\n    const totalSteps = await prisma.sharedStepGroup.count({\n      where: {\n        projectId,\n        // Include deleted items (filtering happens at search time based on admin permissions)\n      },\n    });\n\n    console.log(\n      `Syncing ${totalSteps} shared steps for project ${projectId}...`\n    );\n\n    let processed = 0;\n    let hasMore = true;\n\n    while (hasMore) {\n      const steps = await prisma.sharedStepGroup.findMany({\n        where: {\n          projectId,\n          // Include deleted items (filtering happens at search time based on admin permissions)\n        },\n        skip: processed,\n        take: batchSize,\n        orderBy: { id: \"asc\" },\n      });\n\n      if (steps.length === 0) {\n        hasMore = false;\n        break;\n      }\n\n      // Build and index documents for this batch\n      for (const step of steps) {\n        const doc = await buildSharedStepDocument(step.id);\n        if (doc) {\n          await indexSharedStep(doc);\n        }\n      }\n\n      processed += steps.length;\n      console.log(`Indexed ${processed}/${totalSteps} shared steps...`);\n    }\n\n    console.log(\n      `Successfully synced ${processed} shared steps to Elasticsearch`\n    );\n    return true;\n  } catch (error) {\n    console.error(\n      \"Error syncing project shared steps to Elasticsearch:\",\n      error\n    );\n    return false;\n  }\n}\n", "import {\n  getElasticsearchClient,\n  ENTITY_INDICES,\n} from \"./unifiedElasticsearchService\";\nimport { SearchableEntityType } from \"~/types/search\";\nimport type { Issue } from \"@prisma/client\";\nimport { PrismaClient } from \"@prisma/client\";\nimport { extractTextFromNode } from \"~/utils/extractTextFromJson\";\n\nconst prisma = new PrismaClient();\n\n/**\n * Type for issue with all required relations for indexing\n */\ntype IssueForIndexing = Issue & {\n  createdBy: { name: string; image?: string | null };\n  integration?: { name: string } | null;\n  // Direct project relationship (preferred)\n  project?: { id: number; name: string; iconUrl?: string | null } | null;\n  // Fallback: Try to get project from any relationship\n  repositoryCases?: Array<{\n    project: { id: number; name: string; iconUrl?: string | null };\n  }>;\n  sessions?: Array<{\n    project: { id: number; name: string; iconUrl?: string | null };\n  }>;\n  testRuns?: Array<{\n    project: { id: number; name: string; iconUrl?: string | null };\n  }>;\n  sessionResults?: Array<{\n    session: {\n      project: { id: number; name: string; iconUrl?: string | null };\n    };\n  }>;\n  testRunResults?: Array<{\n    testRun: {\n      project: { id: number; name: string; iconUrl?: string | null };\n    };\n  }>;\n  testRunStepResults?: Array<{\n    testRunResult: {\n      testRun: {\n        project: { id: number; name: string; iconUrl?: string | null };\n      };\n    };\n  }>;\n};\n\n/**\n * Helper function to find project info from any issue relationship\n * Checks direct project relationship first, then falls back to relationship tables\n */\nfunction getProjectFromIssue(issue: IssueForIndexing): {\n  id: number;\n  name: string;\n  iconUrl?: string | null;\n} | null {\n  // Check direct project relationship first (most common and efficient)\n  if (issue.project) {\n    return issue.project;\n  }\n\n  // Fallback: Try repository cases\n  if (issue.repositoryCases?.[0]?.project) {\n    return issue.repositoryCases[0].project;\n  }\n\n  // Try sessions\n  if (issue.sessions?.[0]?.project) {\n    return issue.sessions[0].project;\n  }\n\n  // Try test runs\n  if (issue.testRuns?.[0]?.project) {\n    return issue.testRuns[0].project;\n  }\n\n  // Try session results\n  if (issue.sessionResults?.[0]?.session?.project) {\n    return issue.sessionResults[0].session.project;\n  }\n\n  // Try test run results\n  if (issue.testRunResults?.[0]?.testRun?.project) {\n    return issue.testRunResults[0].testRun.project;\n  }\n\n  // Try test run step results\n  if (issue.testRunStepResults?.[0]?.testRunResult?.testRun?.project) {\n    return issue.testRunStepResults[0].testRunResult.testRun.project;\n  }\n\n  return null;\n}\n\n/**\n * Index a single issue to Elasticsearch\n */\nexport async function indexIssue(issue: IssueForIndexing): Promise<void> {\n  const client = getElasticsearchClient();\n  if (!client) {\n    throw new Error(\"Elasticsearch client not available\");\n  }\n\n  // Try to get project info from any linked relationship\n  const projectInfo = getProjectFromIssue(issue);\n\n  // Skip indexing if no project is found (orphaned issue)\n  if (!projectInfo) {\n    console.warn(`Issue ${issue.id} (${issue.name}) has no linked project, skipping indexing`);\n    return;\n  }\n\n  const searchableContent = [\n    issue.name,\n    issue.title,\n    issue.description || \"\",\n    issue.externalId || \"\",\n    issue.note ? extractTextFromNode(issue.note) : \"\",\n    issue.integration?.name || \"\",\n  ].join(\" \");\n\n  const document = {\n    id: issue.id,\n    projectId: projectInfo.id,\n    projectName: projectInfo.name,\n    projectIconUrl: projectInfo.iconUrl,\n    name: issue.name,\n    title: issue.title,\n    description: issue.description,\n    externalId: issue.externalId,\n    note: issue.note,\n    url: (issue.data as any)?.url,\n    issueSystem: issue.integration?.name || \"Unknown\",\n    isDeleted: issue.isDeleted,\n    createdAt: issue.createdAt,\n    createdById: issue.createdById,\n    createdByName: issue.createdBy.name,\n    createdByImage: issue.createdBy.image,\n    searchableContent,\n  };\n\n  await client.index({\n    index: ENTITY_INDICES[SearchableEntityType.ISSUE],\n    id: issue.id.toString(),\n    document,\n    refresh: true,\n  });\n}\n\n/**\n * Delete an issue from Elasticsearch\n */\nexport async function deleteIssueFromIndex(issueId: number): Promise<void> {\n  const client = getElasticsearchClient();\n  if (!client) {\n    console.warn(\"Elasticsearch client not available\");\n    return;\n  }\n\n  try {\n    await client.delete({\n      index: ENTITY_INDICES[SearchableEntityType.ISSUE],\n      id: issueId.toString(),\n      refresh: true,\n    });\n  } catch (error: any) {\n    if (error.meta?.statusCode !== 404) {\n      console.error(\"Failed to delete issue from index:\", error);\n    }\n  }\n}\n\n/**\n * Sync a single issue to Elasticsearch\n */\nexport async function syncIssueToElasticsearch(\n  issueId: number\n): Promise<boolean> {\n  const client = getElasticsearchClient();\n  if (!client) {\n    console.warn(\"Elasticsearch client not available\");\n    return false;\n  }\n\n  try {\n    const issue = await prisma.issue.findUnique({\n      where: { id: issueId },\n      include: {\n        createdBy: true,\n        integration: true,\n        // Include direct project relationship (preferred)\n        project: true,\n        // Fallback: Check all possible relationships to find project\n        repositoryCases: {\n          take: 1,\n          include: {\n            project: true,\n          },\n        },\n        sessions: {\n          take: 1,\n          include: {\n            project: true,\n          },\n        },\n        testRuns: {\n          take: 1,\n          include: {\n            project: true,\n          },\n        },\n        sessionResults: {\n          take: 1,\n          include: {\n            session: {\n              include: {\n                project: true,\n              },\n            },\n          },\n        },\n        testRunResults: {\n          take: 1,\n          include: {\n            testRun: {\n              include: {\n                project: true,\n              },\n            },\n          },\n        },\n        testRunStepResults: {\n          take: 1,\n          include: {\n            testRunResult: {\n              include: {\n                testRun: {\n                  include: {\n                    project: true,\n                  },\n                },\n              },\n            },\n          },\n        },\n      },\n    });\n\n    if (!issue) {\n      console.warn(`Issue ${issueId} not found`);\n      return false;\n    }\n\n    // Index issue including deleted ones (filtering happens at search time based on admin permissions)\n    // Note: indexIssue will skip issues without a valid project link\n    await indexIssue(issue as IssueForIndexing);\n    return true;\n  } catch (error) {\n    console.error(`Failed to sync issue ${issueId}:`, error);\n    return false;\n  }\n}\n\n/**\n * Bulk index issues for a project\n */\nexport async function syncProjectIssuesToElasticsearch(\n  projectId: number,\n  db: any\n): Promise<void> {\n  const client = getElasticsearchClient();\n  if (!client) {\n    console.warn(\"Elasticsearch client not available\");\n    return;\n  }\n\n  console.log(`Starting issue sync for project ${projectId}`);\n\n  // Find issues either by direct projectId or through any relationship\n  const issues = await db.issue.findMany({\n    where: {\n      // Include deleted items (filtering happens at search time based on admin permissions)\n      OR: [\n        // Direct project relationship (preferred)\n        { projectId, project: { isDeleted: false } },\n        // Fallback: Find through relationships\n        { repositoryCases: { some: { projectId, project: { isDeleted: false } } } },\n        { sessions: { some: { projectId, isDeleted: false, project: { isDeleted: false } } } },\n        { testRuns: { some: { projectId, isDeleted: false, project: { isDeleted: false } } } },\n        { sessionResults: { some: { session: { projectId, isDeleted: false, project: { isDeleted: false } } } } },\n        { testRunResults: { some: { testRun: { projectId, isDeleted: false, project: { isDeleted: false } } } } },\n        {\n          testRunStepResults: {\n            some: { testRunResult: { testRun: { projectId, isDeleted: false, project: { isDeleted: false } } } },\n          },\n        },\n      ],\n    },\n    include: {\n      createdBy: true,\n      integration: true,\n      // Include direct project relationship (preferred)\n      project: true,\n      // Fallback relationships\n      repositoryCases: {\n        where: { projectId, project: { isDeleted: false } },\n        take: 1,\n        include: { project: true },\n      },\n      sessions: {\n        where: { projectId, isDeleted: false, project: { isDeleted: false } },\n        take: 1,\n        include: { project: true },\n      },\n      testRuns: {\n        where: { projectId, isDeleted: false, project: { isDeleted: false } },\n        take: 1,\n        include: { project: true },\n      },\n      sessionResults: {\n        where: { session: { projectId, isDeleted: false, project: { isDeleted: false } } },\n        take: 1,\n        include: {\n          session: {\n            include: { project: true },\n          },\n        },\n      },\n      testRunResults: {\n        where: { testRun: { projectId, isDeleted: false, project: { isDeleted: false } } },\n        take: 1,\n        include: {\n          testRun: {\n            include: { project: true },\n          },\n        },\n      },\n      testRunStepResults: {\n        where: { testRunResult: { testRun: { projectId, isDeleted: false, project: { isDeleted: false } } } },\n        take: 1,\n        include: {\n          testRunResult: {\n            include: {\n              testRun: {\n                include: { project: true },\n              },\n            },\n          },\n        },\n      },\n    },\n  });\n\n  if (issues.length === 0) {\n    console.log(\"No issues to index\");\n    return;\n  }\n\n  const bulkBody = [];\n  let skippedCount = 0;\n\n  for (const issue of issues) {\n    // Try to get project info from any linked relationship\n    const projectInfo = getProjectFromIssue(issue as IssueForIndexing);\n\n    // Skip issues without a valid project link\n    if (!projectInfo) {\n      console.warn(`Issue ${issue.id} has no linked project, skipping`);\n      skippedCount++;\n      continue;\n    }\n\n    const searchableContent = [\n      issue.name,\n      issue.title,\n      issue.description || \"\",\n      issue.externalId || \"\",\n      issue.note ? extractTextFromNode(issue.note) : \"\",\n      issue.integration?.name || \"\",\n    ].join(\" \");\n\n    bulkBody.push({\n      index: {\n        _index: ENTITY_INDICES[SearchableEntityType.ISSUE],\n        _id: issue.id.toString(),\n      },\n    });\n\n    bulkBody.push({\n      id: issue.id,\n      projectId: projectInfo.id,\n      projectName: projectInfo.name,\n      projectIconUrl: projectInfo.iconUrl,\n      name: issue.name,\n      title: issue.title,\n      description: issue.description,\n      externalId: issue.externalId,\n      note: issue.note,\n      url: (issue.data as any)?.url,\n      issueSystem: issue.integration?.name || \"Unknown\",\n      isDeleted: issue.isDeleted,\n      createdAt: issue.createdAt,\n      createdById: issue.createdById,\n      createdByName: issue.createdBy.name,\n      createdByImage: issue.createdBy.image,\n      searchableContent,\n    });\n  }\n\n  if (bulkBody.length === 0) {\n    console.log(\n      `No valid issues to index (${skippedCount} orphaned issues skipped)`\n    );\n    return;\n  }\n\n  try {\n    const response = await client.bulk({ body: bulkBody, refresh: true });\n    if (response.errors) {\n      console.error(\"Bulk indexing errors:\", response.errors);\n    }\n    console.log(\n      `Successfully indexed ${bulkBody.length / 2} issues (${skippedCount} orphaned issues skipped)`\n    );\n  } catch (error) {\n    console.error(\"Failed to index issues:\", error);\n  }\n}\n", "import {\n  getElasticsearchClient,\n  ENTITY_INDICES,\n} from \"./unifiedElasticsearchService\";\nimport { SearchableEntityType } from \"~/types/search\";\nimport type { Milestones } from \"@prisma/client\";\nimport { PrismaClient } from \"@prisma/client\";\nimport { extractTextFromNode } from \"~/utils/extractTextFromJson\";\n\nconst prisma = new PrismaClient();\n\n/**\n * Type for milestone with all required relations for indexing\n */\ntype MilestoneForIndexing = Milestones & {\n  project: { name: string; iconUrl?: string | null };\n  creator: { name: string; image?: string | null };\n  milestoneType: { name: string; icon?: { name: string } | null };\n  parent?: { name: string } | null;\n};\n\n/**\n * Index a single milestone to Elasticsearch\n */\nexport async function indexMilestone(milestone: MilestoneForIndexing): Promise<void> {\n  const client = getElasticsearchClient();\n  if (!client) {\n    throw new Error(\"Elasticsearch client not available\");\n  }\n\n  const searchableContent = [\n    milestone.name,\n    milestone.note ? extractTextFromNode(milestone.note) : \"\",\n    milestone.docs ? extractTextFromNode(milestone.docs) : \"\",\n  ].join(\" \");\n\n\n  const document = {\n    id: milestone.id,\n    projectId: milestone.projectId,\n    projectName: milestone.project.name,\n    projectIconUrl: milestone.project.iconUrl,\n    name: milestone.name,\n    note: milestone.note,\n    docs: milestone.docs,\n    milestoneTypeId: milestone.milestoneTypesId,\n    milestoneTypeName: milestone.milestoneType.name,\n    milestoneTypeIcon: milestone.milestoneType.icon?.name,\n    parentId: milestone.parentId,\n    parentName: milestone.parent?.name,\n    isCompleted: milestone.isCompleted,\n    completedAt: milestone.completedAt,\n    isDeleted: milestone.isDeleted,\n    createdAt: milestone.createdAt,\n    createdById: milestone.createdBy,\n    createdByName: milestone.creator.name,\n    createdByImage: milestone.creator.image,\n    searchableContent,\n  };\n\n  await client.index({\n    index: ENTITY_INDICES[SearchableEntityType.MILESTONE],\n    id: milestone.id.toString(),\n    document,\n    refresh: true,\n  });\n}\n\n/**\n * Delete a milestone from Elasticsearch\n */\nexport async function deleteMilestoneFromIndex(milestoneId: number): Promise<void> {\n  const client = getElasticsearchClient();\n  if (!client) {\n    console.warn(\"Elasticsearch client not available\");\n    return;\n  }\n\n  try {\n    await client.delete({\n      index: ENTITY_INDICES[SearchableEntityType.MILESTONE],\n      id: milestoneId.toString(),\n      refresh: true,\n    });\n  } catch (error: any) {\n    if (error.meta?.statusCode !== 404) {\n      console.error(\"Failed to delete milestone from index:\", error);\n    }\n  }\n}\n\n/**\n * Sync a single milestone to Elasticsearch\n */\nexport async function syncMilestoneToElasticsearch(milestoneId: number): Promise<boolean> {\n  const client = getElasticsearchClient();\n  if (!client) {\n    console.warn(\"Elasticsearch client not available\");\n    return false;\n  }\n\n  try {\n    const milestone = await prisma.milestones.findUnique({\n      where: { id: milestoneId },\n      include: {\n        project: true,\n        creator: true,\n        milestoneType: {\n          include: {\n            icon: true,\n          },\n        },\n        parent: true,\n      },\n    });\n\n    if (!milestone) {\n      console.warn(`Milestone ${milestoneId} not found`);\n      return false;\n    }\n\n    // Index milestone including deleted ones (filtering happens at search time based on admin permissions)\n\n    // Index the milestone\n    await indexMilestone(milestone as MilestoneForIndexing);\n    return true;\n  } catch (error) {\n    console.error(`Failed to sync milestone ${milestoneId}:`, error);\n    return false;\n  }\n}\n\n/**\n * Bulk index milestones for a project\n */\nexport async function syncProjectMilestonesToElasticsearch(\n  projectId: number,\n  db: any\n): Promise<void> {\n  const client = getElasticsearchClient();\n  if (!client) {\n    console.warn(\"Elasticsearch client not available\");\n    return;\n  }\n\n  console.log(`Starting milestone sync for project ${projectId}`);\n\n  const milestones = await db.milestones.findMany({\n    where: {\n      projectId: projectId,\n      // Include deleted items (filtering happens at search time based on admin permissions)\n    },\n    include: {\n      project: true,\n      creator: true,\n      milestoneType: {\n        include: {\n          icon: true,\n        },\n      },\n      parent: true,\n    },\n  });\n\n  if (milestones.length === 0) {\n    console.log(\"No milestones to index\");\n    return;\n  }\n\n  const bulkBody = [];\n  for (const milestone of milestones) {\n    const searchableContent = [\n      milestone.name,\n      milestone.note ? extractTextFromNode(milestone.note) : \"\",\n      milestone.docs ? extractTextFromNode(milestone.docs) : \"\",\n    ].join(\" \");\n\n\n    bulkBody.push({\n      index: {\n        _index: ENTITY_INDICES[SearchableEntityType.MILESTONE],\n        _id: milestone.id.toString(),\n      },\n    });\n\n    bulkBody.push({\n      id: milestone.id,\n      projectId: milestone.projectId,\n      projectName: milestone.project.name,\n      projectIconUrl: milestone.project.iconUrl,\n      name: milestone.name,\n      note: milestone.note,\n      docs: milestone.docs,\n      milestoneTypeId: milestone.milestoneTypesId,\n      milestoneTypeName: milestone.milestoneType.name,\n      milestoneTypeIcon: milestone.milestoneType.icon?.name,\n      parentId: milestone.parentId,\n      parentName: milestone.parent?.name,\n        isCompleted: milestone.isCompleted,\n      completedAt: milestone.completedAt,\n      isDeleted: milestone.isDeleted,\n      createdAt: milestone.createdAt,\n        createdById: milestone.createdBy,\n      createdByName: milestone.createdBy.name,\n      createdByImage: milestone.createdBy.image,\n        searchableContent,\n    });\n  }\n\n  try {\n    const response = await client.bulk({ body: bulkBody, refresh: true });\n    if (response.errors) {\n      console.error(\"Bulk indexing errors:\", response.errors);\n    }\n    console.log(`Successfully indexed ${milestones.length} milestones`);\n  } catch (error) {\n    console.error(\"Failed to index milestones:\", error);\n  }\n}\n\n/**\n * Sync all milestones that have a specific parent\n */\nexport async function syncChildMilestonesToElasticsearch(parentId: number): Promise<void> {\n  const client = getElasticsearchClient();\n  if (!client) {\n    console.warn(\"Elasticsearch client not available\");\n    return;\n  }\n\n  try {\n    const childMilestones = await prisma.milestones.findMany({\n      where: {\n        parentId: parentId,\n        // Include deleted items (filtering happens at search time based on admin permissions)\n      },\n    });\n\n    for (const child of childMilestones) {\n      await syncMilestoneToElasticsearch(child.id);\n    }\n  } catch (error) {\n    console.error(`Failed to sync child milestones of parent ${parentId}:`, error);\n  }\n}", "import {\n  getElasticsearchClient,\n  ENTITY_INDICES,\n} from \"./unifiedElasticsearchService\";\nimport { SearchableEntityType } from \"~/types/search\";\nimport type { Projects } from \"@prisma/client\";\nimport { PrismaClient } from \"@prisma/client\";\nimport { extractTextFromNode } from \"~/utils/extractTextFromJson\";\n\nconst prisma = new PrismaClient();\n\n/**\n * Type for project with all required relations for indexing\n */\ntype ProjectForIndexing = Projects & {\n  creator: { name: string; image?: string | null };\n};\n\n/**\n * Index a single project to Elasticsearch\n */\nexport async function indexProject(project: ProjectForIndexing): Promise<void> {\n  const client = getElasticsearchClient();\n  if (!client) {\n    throw new Error(\"Elasticsearch client not available\");\n  }\n\n  const searchableContent = [\n    project.name,\n    project.note ? extractTextFromNode(project.note) : \"\",\n    project.docs ? extractTextFromNode(project.docs) : \"\",\n  ].join(\" \");\n\n  const document = {\n    id: project.id,\n    name: project.name,\n    iconUrl: project.iconUrl,\n    note: project.note,\n    docs: project.docs,\n    isDeleted: project.isDeleted,\n    createdAt: project.createdAt,\n    createdById: project.createdBy,\n    createdByName: project.creator.name,\n    createdByImage: project.creator.image,\n    searchableContent,\n  };\n\n  await client.index({\n    index: ENTITY_INDICES[SearchableEntityType.PROJECT],\n    id: project.id.toString(),\n    document,\n    refresh: true,\n  });\n}\n\n/**\n * Delete a project from Elasticsearch\n */\nexport async function deleteProjectFromIndex(projectId: number): Promise<void> {\n  const client = getElasticsearchClient();\n  if (!client) {\n    console.warn(\"Elasticsearch client not available\");\n    return;\n  }\n\n  try {\n    await client.delete({\n      index: ENTITY_INDICES[SearchableEntityType.PROJECT],\n      id: projectId.toString(),\n      refresh: true,\n    });\n  } catch (error: any) {\n    if (error.meta?.statusCode !== 404) {\n      console.error(\"Failed to delete project from index:\", error);\n    }\n  }\n}\n\n/**\n * Sync a single project to Elasticsearch\n */\nexport async function syncProjectToElasticsearch(projectId: number): Promise<boolean> {\n  const client = getElasticsearchClient();\n  if (!client) {\n    console.warn(\"Elasticsearch client not available\");\n    return false;\n  }\n\n  try {\n    const project = await prisma.projects.findUnique({\n      where: { id: projectId },\n      include: {\n        creator: true,\n      },\n    });\n\n    if (!project) {\n      console.warn(`Project ${projectId} not found`);\n      return false;\n    }\n\n    // Index project including deleted ones (filtering happens at search time based on admin permissions)\n\n    // Index the project\n    await indexProject(project);\n    return true;\n  } catch (error) {\n    console.error(`Failed to sync project ${projectId}:`, error);\n    return false;\n  }\n}\n\n/**\n * Sync all projects to Elasticsearch\n */\nexport async function syncAllProjectsToElasticsearch(): Promise<void> {\n  const client = getElasticsearchClient();\n  if (!client) {\n    console.warn(\"Elasticsearch client not available\");\n    return;\n  }\n\n  console.log(\"Starting project sync\");\n\n  const projects = await prisma.projects.findMany({\n    where: {\n      // Include deleted items (filtering happens at search time based on admin permissions)\n    },\n    include: {\n      creator: true,\n    },\n  });\n\n  if (projects.length === 0) {\n    console.log(\"No projects to index\");\n    return;\n  }\n\n  const bulkBody = [];\n  for (const project of projects) {\n    const searchableContent = [\n      project.name,\n      project.note ? extractTextFromNode(project.note) : \"\",\n      project.docs ? extractTextFromNode(project.docs) : \"\",\n    ].join(\" \");\n\n    bulkBody.push({\n      index: {\n        _index: ENTITY_INDICES[SearchableEntityType.PROJECT],\n        _id: project.id.toString(),\n      },\n    });\n\n    bulkBody.push({\n      id: project.id,\n      name: project.name,\n      iconUrl: project.iconUrl,\n      note: project.note,\n      docs: project.docs,\n      isDeleted: project.isDeleted,\n      createdAt: project.createdAt,\n      createdById: project.createdBy,\n      createdByName: project.creator.name,\n      createdByImage: project.creator.image,\n      searchableContent,\n    });\n  }\n\n  try {\n    const response = await client.bulk({ body: bulkBody, refresh: true });\n    if (response.errors) {\n      console.error(\"Bulk indexing errors:\", response.errors);\n    }\n    console.log(`Successfully indexed ${projects.length} projects`);\n  } catch (error) {\n    console.error(\"Failed to index projects:\", error);\n  }\n}", "\"use server\";\n\nimport { prisma } from \"../lib/prisma\";\n\ntype UpdateRepositoryCaseForecastOptions = {\n  skipTestRunUpdate?: boolean;\n  collectAffectedTestRuns?: boolean;\n};\n\ntype UpdateRepositoryCaseForecastResult = {\n  updatedCaseIds: number[];\n  affectedTestRunIds: number[];\n};\n\ntype UpdateTestRunForecastOptions = {\n  alreadyRefreshedCaseIds?: Set<number>;\n};\n\n/**\n * Calculates the group-averaged forecast for a repository case and all cases linked by SAME_TEST_DIFFERENT_SOURCE.\n * Updates forecastManual and forecastAutomated for all cases in the group.\n * @param repositoryCaseId The ID of the RepositoryCase to update.\n * @returns The unique RepositoryCase IDs whose forecasts were refreshed and affected TestRun IDs.\n */\nexport async function updateRepositoryCaseForecast(\n  repositoryCaseId: number,\n  options: UpdateRepositoryCaseForecastOptions = {}\n): Promise<UpdateRepositoryCaseForecastResult> {\n  if (process.env.DEBUG_FORECAST) {\n    console.log(\n      `Calculating group forecast for RepositoryCase ID: ${repositoryCaseId}`\n    );\n  }\n\n  try {\n    // 1. Find all cases in the SAME_TEST_DIFFERENT_SOURCE link group (including itself)\n    const caseAndLinks = await prisma.repositoryCases.findUnique({\n      where: { id: repositoryCaseId },\n      select: {\n        id: true,\n        source: true,\n        linksFrom: {\n          where: { type: \"SAME_TEST_DIFFERENT_SOURCE\", isDeleted: false },\n          select: { caseBId: true },\n        },\n        linksTo: {\n          where: { type: \"SAME_TEST_DIFFERENT_SOURCE\", isDeleted: false },\n          select: { caseAId: true },\n        },\n      },\n    });\n    if (!caseAndLinks) return { updatedCaseIds: [], affectedTestRunIds: [] };\n    const linkedIds = [\n      caseAndLinks.id,\n      ...caseAndLinks.linksFrom.map((l) => l.caseBId),\n      ...caseAndLinks.linksTo.map((l) => l.caseAId),\n    ];\n    const uniqueCaseIds = Array.from(new Set(linkedIds));\n    if (process.env.DEBUG_FORECAST) console.log(\"[Forecast] Group case IDs:\", uniqueCaseIds);\n\n    // 2. Fetch all cases in the group with their source\n    const allCases = await prisma.repositoryCases.findMany({\n      where: { id: { in: uniqueCaseIds } },\n      select: { id: true, source: true },\n    });\n    if (process.env.DEBUG_FORECAST) console.log(\"[Forecast] allCases:\", allCases);\n\n    // 3. Gather all manual and JUNIT result durations\n    // Manual: TestRunResults (isDeleted: false, elapsed > 0)\n    const manualCaseIds = allCases\n      .filter((c) => c.source === \"MANUAL\")\n      .map((c) => c.id);\n    if (process.env.DEBUG_FORECAST) console.log(\"[Forecast] manualCaseIds:\", manualCaseIds);\n    let manualResults: { elapsed: number | null }[] = [];\n    if (manualCaseIds.length) {\n      // 1. Find all TestRunCase IDs for these repositoryCaseIds\n      const testRunCases = await prisma.testRunCases.findMany({\n        where: { repositoryCaseId: { in: manualCaseIds } },\n        select: { id: true },\n      });\n      const testRunCaseIds = testRunCases.map((trc) => trc.id);\n\n      // 2. Find all TestRunResults for those TestRunCase IDs\n      manualResults = testRunCaseIds.length\n        ? await prisma.testRunResults.findMany({\n            where: {\n              testRunCaseId: { in: testRunCaseIds },\n              isDeleted: false,\n              elapsed: { gt: 0 },\n            },\n            select: { elapsed: true },\n          })\n        : [];\n    }\n    if (process.env.DEBUG_FORECAST) console.log(\"[Forecast] manualResults:\", manualResults);\n    const manualDurations = manualResults\n      .map((r) => r.elapsed)\n      .filter((v) => v != null);\n    if (process.env.DEBUG_FORECAST) console.log(\"[Forecast] manualDurations:\", manualDurations);\n\n    // JUNIT: JUnitTestResult (statusId not null, time > 0)\n    const junitCaseIds = allCases\n      .filter((c) => c.source === \"JUNIT\")\n      .map((c) => c.id);\n    if (process.env.DEBUG_FORECAST) console.log(\"[Forecast] junitCaseIds:\", junitCaseIds);\n    const junitResults = junitCaseIds.length\n      ? await prisma.jUnitTestResult.findMany({\n          where: {\n            repositoryCaseId: { in: junitCaseIds },\n            time: { gt: 0 },\n          },\n          select: { time: true },\n        })\n      : [];\n    if (process.env.DEBUG_FORECAST) console.log(\"[Forecast] junitResults:\", junitResults);\n    const junitDurations = junitResults\n      .map((r) => r.time)\n      .filter((v) => v != null);\n    if (process.env.DEBUG_FORECAST) console.log(\"[Forecast] junitDurations:\", junitDurations);\n\n    // 4. Compute averages\n    const avgManual =\n      manualDurations.length > 0\n        ? Math.round(\n            manualDurations.reduce((a, b) => a + b, 0) / manualDurations.length\n          )\n        : null;\n    const avgJunit =\n      junitDurations.length > 0\n        ? parseFloat(\n            (\n              junitDurations.reduce((a, b) => a + b, 0) / junitDurations.length\n            ).toFixed(3)\n          )\n        : null;\n    if (process.env.DEBUG_FORECAST) console.log(\"[Forecast] avgManual:\", avgManual, \"avgJunit:\", avgJunit);\n\n    // 5. Update all cases in the group (using updateMany can reset fields to defaults, so we use individual updates)\n    for (const caseId of uniqueCaseIds) {\n      await prisma.repositoryCases.update({\n        where: { id: caseId },\n        data: {\n          forecastManual: avgManual,\n          forecastAutomated: avgJunit,\n        },\n      });\n    }\n    if (process.env.DEBUG_FORECAST) {\n      console.log(\n        `Updated forecastManual=${avgManual}, forecastAutomated=${avgJunit} for cases: [${uniqueCaseIds.join(\", \")}]`\n      );\n    }\n\n    // --- Update TestRun forecasts for all TestRuns affected by these case updates ---\n    const affectedTestRunCases = await prisma.testRunCases.findMany({\n      where: {\n        repositoryCaseId: { in: uniqueCaseIds },\n      },\n      select: {\n        testRunId: true,\n      },\n    });\n\n    const uniqueAffectedTestRunIds = Array.from(\n      new Set(affectedTestRunCases.map((trc) => trc.testRunId))\n    );\n\n    // If not skipping, update TestRuns now; otherwise just collect their IDs\n    if (!options.skipTestRunUpdate && uniqueAffectedTestRunIds.length > 0) {\n      for (const testRunId of uniqueAffectedTestRunIds) {\n        await updateTestRunForecast(testRunId, {\n          alreadyRefreshedCaseIds: new Set(uniqueCaseIds),\n        });\n      }\n    }\n    // --- End TestRun forecast update ---\n\n    return {\n      updatedCaseIds: uniqueCaseIds,\n      affectedTestRunIds: options.collectAffectedTestRuns ? uniqueAffectedTestRunIds : [],\n    };\n  } catch (error) {\n    console.error(\n      `Error updating group forecast for RepositoryCase ID ${repositoryCaseId}:`,\n      error\n    );\n    throw error;\n  }\n}\n\n/**\n * Calculates and updates the forecast for a specific TestRun.\n * @param testRunId The ID of the TestRun to update.\n */\nexport async function updateTestRunForecast(\n  testRunId: number,\n  options: UpdateTestRunForecastOptions = {}\n): Promise<void> {\n  if (process.env.DEBUG_FORECAST) console.log(`Updating forecast for TestRun ID: ${testRunId}`);\n  try {\n    // 1. Fetch all TestRunCases for this TestRun, including their status system name\n    let testRunCasesWithDetails = await prisma.testRunCases.findMany({\n      where: { testRunId: testRunId },\n      select: {\n        repositoryCaseId: true,\n        status: {\n          select: {\n            systemName: true,\n          },\n        },\n      },\n    });\n\n    // Ensure repository case forecasts are current before recalculating the run forecast\n    if (testRunCasesWithDetails.length > 0) {\n      const processedCaseIds = new Set<number>(\n        options.alreadyRefreshedCaseIds\n          ? Array.from(options.alreadyRefreshedCaseIds)\n          : []\n      );\n\n      const repositoryCaseIdsInRun = Array.from(\n        new Set(testRunCasesWithDetails.map((trc) => trc.repositoryCaseId))\n      );\n\n      let refreshedAnyCase = false;\n\n      for (const repositoryCaseId of repositoryCaseIdsInRun) {\n        if (processedCaseIds.has(repositoryCaseId)) {\n          continue;\n        }\n\n        const result = await updateRepositoryCaseForecast(\n          repositoryCaseId,\n          { skipTestRunUpdate: true }\n        );\n\n        if (result.updatedCaseIds.length > 0) {\n          refreshedAnyCase = true;\n          for (const refreshedId of result.updatedCaseIds) {\n            processedCaseIds.add(refreshedId);\n          }\n        }\n      }\n\n      if (refreshedAnyCase) {\n        // Refetch to capture any status changes that may have occurred during case refresh\n        testRunCasesWithDetails = await prisma.testRunCases.findMany({\n          where: { testRunId: testRunId },\n          select: {\n            repositoryCaseId: true,\n            status: {\n              select: {\n                systemName: true,\n              },\n            },\n          },\n        });\n      }\n    }\n\n    // 2. Filter cases to include only those with no result or an \"untested\" status\n    const repositoryCaseIdsToForecast = testRunCasesWithDetails\n      .filter(\n        (trc) => trc.status === null || trc.status?.systemName === \"UNTESTED\"\n      )\n      .map((trc) => trc.repositoryCaseId);\n\n    if (!repositoryCaseIdsToForecast.length) {\n      // No applicable cases in this test run, so clear its forecasts\n      await prisma.testRuns.update({\n        where: { id: testRunId },\n        data: {\n          forecastManual: null,\n          forecastAutomated: null,\n        },\n      });\n      if (process.env.DEBUG_FORECAST) {\n        console.log(\n          `Cleared forecasts for TestRun ID: ${testRunId} as no pending/untested cases were found`\n        );\n      }\n      return;\n    }\n\n    // 3. Fetch the RepositoryCases for these filtered IDs\n    const repositoryCases = await prisma.repositoryCases.findMany({\n      where: { id: { in: repositoryCaseIdsToForecast } },\n      select: { forecastManual: true, forecastAutomated: true },\n    });\n\n    // 4. Calculate the sum of forecasts\n    let totalForecastManual = 0;\n    let totalForecastAutomated = 0;\n    let hasManual = false;\n    let hasAutomated = false;\n\n    for (const rc of repositoryCases) {\n      if (rc.forecastManual !== null) {\n        totalForecastManual += rc.forecastManual;\n        hasManual = true;\n      }\n      if (rc.forecastAutomated !== null) {\n        totalForecastAutomated += rc.forecastAutomated;\n        hasAutomated = true;\n      }\n    }\n\n    // 5. Update the TestRun record\n    await prisma.testRuns.update({\n      where: { id: testRunId },\n      data: {\n        forecastManual: hasManual ? totalForecastManual : null,\n        forecastAutomated: hasAutomated\n          ? parseFloat(totalForecastAutomated.toFixed(3))\n          : null,\n      },\n    });\n\n    if (process.env.DEBUG_FORECAST) {\n      console.log(\n        `Updated TestRun ID ${testRunId} with forecastManual=${totalForecastManual}, forecastAutomated=${totalForecastAutomated}`\n      );\n    }\n  } catch (error) {\n    console.error(\n      `Error updating forecast for TestRun ID ${testRunId}:`,\n      error\n    );\n    throw error;\n  }\n}\n\n/**\n * Fetches all RepositoryCase IDs that are not deleted or archived.\n * @returns An array of active RepositoryCase IDs.\n */\nexport async function getActiveRepositoryCaseIds(): Promise<number[]> {\n  if (process.env.DEBUG_FORECAST) console.log(\"Fetching active repository case IDs...\");\n  try {\n    const cases = await prisma.repositoryCases.findMany({\n      where: {\n        isDeleted: false,\n        isArchived: false,\n      },\n      select: {\n        id: true,\n      },\n    });\n    const ids = cases.map((c) => c.id);\n    if (process.env.DEBUG_FORECAST) console.log(`Found ${ids.length} active repository cases.`);\n    return ids;\n  } catch (error) {\n    console.error(\"Error fetching active repository case IDs:\", error);\n    throw error; // Propagate error\n  }\n}\n\n/**\n * Fetches unique case group representatives to avoid recalculating the same linked groups.\n * For each group of cases linked by SAME_TEST_DIFFERENT_SOURCE, returns only one representative case ID.\n * Processes cases in batches to avoid hitting database bind variable limits.\n * @returns An array of representative RepositoryCase IDs, one per unique group.\n */\nexport async function getUniqueCaseGroupIds(): Promise<number[]> {\n  if (process.env.DEBUG_FORECAST) console.log(\"Fetching unique case group representatives...\");\n  try {\n    const BATCH_SIZE = 1000;\n    const processedCaseIds = new Set<number>();\n    const uniqueRepresentatives: number[] = [];\n\n    // First, get all active case IDs\n    const allCaseIds = await prisma.repositoryCases.findMany({\n      where: {\n        isDeleted: false,\n        isArchived: false,\n      },\n      select: {\n        id: true,\n      },\n    });\n\n    const totalCases = allCaseIds.length;\n    if (process.env.DEBUG_FORECAST) console.log(`Processing ${totalCases} active cases in batches of ${BATCH_SIZE}...`);\n\n    // Process in batches to avoid bind variable limit\n    for (let i = 0; i < allCaseIds.length; i += BATCH_SIZE) {\n      const batchIds = allCaseIds.slice(i, i + BATCH_SIZE).map((c) => c.id);\n\n      const casesWithLinks = await prisma.repositoryCases.findMany({\n        where: {\n          id: { in: batchIds },\n        },\n        select: {\n          id: true,\n          linksFrom: {\n            where: { type: \"SAME_TEST_DIFFERENT_SOURCE\", isDeleted: false },\n            select: { caseBId: true },\n          },\n          linksTo: {\n            where: { type: \"SAME_TEST_DIFFERENT_SOURCE\", isDeleted: false },\n            select: { caseAId: true },\n          },\n        },\n      });\n\n      for (const caseData of casesWithLinks) {\n        // Skip if we've already processed this case as part of another group\n        if (processedCaseIds.has(caseData.id)) {\n          continue;\n        }\n\n        // This case becomes the representative for its group\n        uniqueRepresentatives.push(caseData.id);\n\n        // Mark all cases in this group as processed\n        const linkedIds = [\n          caseData.id,\n          ...caseData.linksFrom.map((l) => l.caseBId),\n          ...caseData.linksTo.map((l) => l.caseAId),\n        ];\n\n        for (const linkedId of linkedIds) {\n          processedCaseIds.add(linkedId);\n        }\n      }\n\n      if (process.env.DEBUG_FORECAST) {\n        console.log(`Processed batch ${Math.floor(i / BATCH_SIZE) + 1}/${Math.ceil(totalCases / BATCH_SIZE)}: ${uniqueRepresentatives.length} unique groups so far`);\n      }\n    }\n\n    if (process.env.DEBUG_FORECAST) {\n      console.log(\n        `Found ${uniqueRepresentatives.length} unique case groups (from ${totalCases} total active cases)`\n      );\n    }\n    return uniqueRepresentatives;\n  } catch (error) {\n    console.error(\"Error fetching unique case group IDs:\", error);\n    throw error;\n  }\n}\n\n// Optional: Disconnect Prisma client on exit (important for graceful shutdown)\n// This might be better handled in the worker's shutdown process\n// process.on('exit', async () => {\n//   await prisma.$disconnect();\n// });\n", "import { Worker, Job } from \"bullmq\";\nimport valkeyConnection from \"../lib/valkey\";\nimport { NOTIFICATION_QUEUE_NAME, emailQueue } from \"../lib/queues\";\nimport { PrismaClient } from \"@prisma/client\";\nimport { pathToFileURL } from \"node:url\";\n\nconst prisma = new PrismaClient();\n\n// Define job data structures\ninterface CreateNotificationJobData {\n  userId: string;\n  type: string;\n  title: string;\n  message: string;\n  relatedEntityId?: string;\n  relatedEntityType?: string;\n  data?: any;\n}\n\ninterface ProcessUserNotificationsJobData {\n  userId: string;\n}\n\n// Define job names\nexport const JOB_CREATE_NOTIFICATION = \"create-notification\";\nexport const JOB_PROCESS_USER_NOTIFICATIONS = \"process-user-notifications\";\nexport const JOB_SEND_DAILY_DIGEST = \"send-daily-digest\";\n\nconst processor = async (job: Job) => {\n  console.log(`Processing notification job ${job.id} of type ${job.name}`);\n\n  switch (job.name) {\n    case JOB_CREATE_NOTIFICATION:\n      const createData = job.data as CreateNotificationJobData;\n\n      try {\n        // Check user preferences first\n        const userPreferences = await prisma.userPreferences.findUnique({\n          where: { userId: createData.userId },\n        });\n\n        // Get global notification settings from AppConfig\n        const globalSettings = await prisma.appConfig.findUnique({\n          where: { key: \"notificationSettings\" },\n        });\n\n        // Determine notification mode\n        let notificationMode =\n          userPreferences?.notificationMode || \"USE_GLOBAL\";\n        if (notificationMode === \"USE_GLOBAL\") {\n          const settingsValue = globalSettings?.value as {\n            defaultMode?: string;\n          } | null;\n          notificationMode = (settingsValue?.defaultMode || \"IN_APP\") as any;\n        }\n\n        // Skip notification creation if user has notifications set to NONE\n        if (notificationMode === \"NONE\") {\n          console.log(\n            `Skipping notification for user ${createData.userId} - notifications disabled`\n          );\n          return;\n        }\n\n        // Create the in-app notification (for all modes except NONE)\n        const notification = await prisma.notification.create({\n          data: {\n            userId: createData.userId,\n            type: createData.type as any,\n            title: createData.title,\n            message: createData.message,\n            relatedEntityId: createData.relatedEntityId,\n            relatedEntityType: createData.relatedEntityType,\n            data: createData.data,\n          },\n        });\n\n        // Queue email if needed based on notification mode\n        if (notificationMode === \"IN_APP_EMAIL_IMMEDIATE\") {\n          await emailQueue?.add(\"send-notification-email\", {\n            notificationId: notification.id,\n            userId: createData.userId,\n            immediate: true,\n          });\n        }\n\n        console.log(\n          `Created notification ${notification.id} for user ${createData.userId} with mode ${notificationMode}`\n        );\n      } catch (error) {\n        console.error(`Failed to create notification:`, error);\n        throw error;\n      }\n      break;\n\n    case JOB_PROCESS_USER_NOTIFICATIONS:\n      const processData = job.data as ProcessUserNotificationsJobData;\n\n      try {\n        // Get unread notifications for the user\n        const notifications = await prisma.notification.findMany({\n          where: {\n            userId: processData.userId,\n            isRead: false,\n            isDeleted: false,\n          },\n          orderBy: { createdAt: \"desc\" },\n        });\n\n        console.log(\n          `Processing ${notifications.length} notifications for user ${processData.userId}`\n        );\n      } catch (error) {\n        console.error(`Failed to process user notifications:`, error);\n        throw error;\n      }\n      break;\n\n    case JOB_SEND_DAILY_DIGEST:\n      try {\n        // Get global settings from AppConfig\n        const globalSettings = await prisma.appConfig.findUnique({\n          where: { key: \"notificationSettings\" },\n        });\n        const settingsValue = globalSettings?.value as {\n          defaultMode?: string;\n        } | null;\n        const globalDefaultMode = settingsValue?.defaultMode || \"IN_APP\";\n\n        // Get all users with IN_APP_EMAIL_DAILY preference or USE_GLOBAL where global is daily\n        const users = await prisma.userPreferences.findMany({\n          where: {\n            OR: [\n              { notificationMode: \"IN_APP_EMAIL_DAILY\" },\n              {\n                notificationMode: \"USE_GLOBAL\",\n                ...(globalDefaultMode === \"IN_APP_EMAIL_DAILY\"\n                  ? {}\n                  : { id: \"none\" }), // Only include if global is daily\n              },\n            ],\n          },\n          include: {\n            user: true,\n          },\n        });\n\n        for (const userPref of users) {\n          // Get unread notifications from the last 24 hours\n          const yesterday = new Date();\n          yesterday.setDate(yesterday.getDate() - 1);\n\n          const notifications = await prisma.notification.findMany({\n            where: {\n              userId: userPref.userId,\n              isRead: false,\n              isDeleted: false,\n              createdAt: { gte: yesterday },\n            },\n            orderBy: { createdAt: \"desc\" },\n          });\n\n          if (notifications.length > 0) {\n            await emailQueue?.add(\"send-digest-email\", {\n              userId: userPref.userId,\n              notifications: notifications.map((n) => ({\n                id: n.id,\n                title: n.title,\n                message: n.message,\n                createdAt: n.createdAt,\n              })),\n            });\n          }\n        }\n\n        console.log(`Processed daily digest for ${users.length} users`);\n      } catch (error) {\n        console.error(`Failed to send daily digest:`, error);\n        throw error;\n      }\n      break;\n\n    default:\n      throw new Error(`Unknown job type: ${job.name}`);\n  }\n};\n\nlet worker: Worker | null = null;\n\n// Function to start the worker\nconst startWorker = async () => {\n  if (valkeyConnection) {\n    worker = new Worker(NOTIFICATION_QUEUE_NAME, processor, {\n      connection: valkeyConnection,\n      concurrency: 5,\n    });\n\n    worker.on(\"completed\", (job) => {\n      console.log(`Job ${job.id} completed successfully.`);\n    });\n\n    worker.on(\"failed\", (job, err) => {\n      console.error(`Job ${job?.id} failed:`, err);\n    });\n\n    worker.on(\"error\", (err) => {\n      console.error(\"Worker error:\", err);\n    });\n\n    console.log(\n      `Notification worker started for queue \"${NOTIFICATION_QUEUE_NAME}\".`\n    );\n  } else {\n    console.warn(\n      \"Valkey connection not available. Notification worker not started.\"\n    );\n  }\n\n  // Allow graceful shutdown\n  process.on(\"SIGINT\", async () => {\n    console.log(\"Shutting down notification worker...\");\n    if (worker) {\n      await worker.close();\n    }\n    await prisma.$disconnect();\n    process.exit(0);\n  });\n};\n\n// Run the worker if this file is executed directly (works with both ESM and CommonJS)\nif (\n  (typeof import.meta !== \"undefined\" &&\n    import.meta.url === pathToFileURL(process.argv[1]).href) ||\n  (typeof import.meta === \"undefined\" ||\n    (import.meta as any).url === undefined)\n) {\n  console.log(\"Notification worker running...\");\n  startWorker().catch((err) => {\n    console.error(\"Failed to start notification worker:\", err);\n    process.exit(1);\n  });\n}\n\nexport default worker;\nexport { processor };\n", "import { forecastQueue, notificationQueue } from \"./lib/queues\";\nimport { FORECAST_QUEUE_NAME, NOTIFICATION_QUEUE_NAME } from \"./lib/queues\";\nimport { JOB_UPDATE_ALL_CASES } from \"./workers/forecastWorker\";\nimport { JOB_SEND_DAILY_DIGEST } from \"./workers/notificationWorker\";\n\n// Define the cron schedule (e.g., every day at 3:00 AM server time)\n// Uses standard cron syntax: min hour day(month) month day(week)\nconst CRON_SCHEDULE_DAILY_3AM = \"0 3 * * *\";\nconst CRON_SCHEDULE_DAILY_8AM = \"0 8 * * *\"; // For daily digest emails\n\nasync function scheduleJobs() {\n  console.log(\"Attempting to schedule jobs...\");\n\n  if (!forecastQueue || !notificationQueue) {\n    console.error(\"Required queues are not initialized. Cannot schedule jobs.\");\n    process.exit(1); // Exit if queues aren't available\n  }\n\n  try {\n    // Clean up any old versions of the repeatable job first\n    const repeatableJobs = await forecastQueue.getRepeatableJobs();\n    let removedCount = 0;\n    for (const job of repeatableJobs) {\n      // Check job name specifically - avoids removing unrelated repeatable jobs\n      if (job.name === JOB_UPDATE_ALL_CASES) {\n        console.log(\n          `Removing existing repeatable job \"${job.name}\" with key: ${job.key}`\n        );\n        await forecastQueue.removeRepeatableByKey(job.key);\n        removedCount++;\n      }\n    }\n    if (removedCount > 0) {\n      console.log(`Removed ${removedCount} old repeatable forecast jobs.`);\n    }\n\n    // Add the repeatable job to update all cases\n    await forecastQueue.add(\n      JOB_UPDATE_ALL_CASES, // Job name from worker\n      {}, // No specific data needed\n      {\n        repeat: {\n          // BullMQ v3+ uses pattern instead of cron\n          // For older versions use: cron: CRON_SCHEDULE_DAILY_3AM\n          pattern: CRON_SCHEDULE_DAILY_3AM,\n          // tz: 'UTC', // Example: Explicitly set timezone if needed\n        },\n        jobId: JOB_UPDATE_ALL_CASES, // Use the job name as a predictable ID\n      }\n    );\n\n    console.log(\n      `Successfully scheduled repeatable job \"${JOB_UPDATE_ALL_CASES}\" with pattern \"${CRON_SCHEDULE_DAILY_3AM}\" on queue \"${FORECAST_QUEUE_NAME}\".`\n    );\n\n    // Schedule daily digest notifications\n    const notificationRepeatableJobs =\n      await notificationQueue.getRepeatableJobs();\n    let removedNotificationCount = 0;\n    for (const job of notificationRepeatableJobs) {\n      if (job.name === JOB_SEND_DAILY_DIGEST) {\n        console.log(\n          `Removing existing repeatable job \"${job.name}\" with key: ${job.key}`\n        );\n        await notificationQueue.removeRepeatableByKey(job.key);\n        removedNotificationCount++;\n      }\n    }\n    if (removedNotificationCount > 0) {\n      console.log(\n        `Removed ${removedNotificationCount} old repeatable notification jobs.`\n      );\n    }\n\n    // Add the repeatable job for daily digest\n    await notificationQueue.add(\n      JOB_SEND_DAILY_DIGEST,\n      {},\n      {\n        repeat: {\n          pattern: CRON_SCHEDULE_DAILY_8AM,\n        },\n        jobId: JOB_SEND_DAILY_DIGEST,\n      }\n    );\n\n    console.log(\n      `Successfully scheduled repeatable job \"${JOB_SEND_DAILY_DIGEST}\" with pattern \"${CRON_SCHEDULE_DAILY_8AM}\" on queue \"${NOTIFICATION_QUEUE_NAME}\".`\n    );\n  } catch (error) {\n    console.error(\"Error scheduling jobs:\", error);\n    process.exit(1); // Exit if scheduling fails\n  }\n}\n\n// Run the scheduling function\nscheduleJobs()\n  .then(() => {\n    console.log(\"Scheduling script finished successfully.\");\n    // Close the connection used by the queue ONLY if this script is standalone\n    // If part of app init, the main app should manage connection lifecycle\n    // forecastQueue?.client.disconnect();\n    process.exit(0); // Exit successfully\n  })\n  .catch((err) => {\n    console.error(\"Scheduling script failed unexpectedly:\", err);\n    process.exit(1); // Exit with error\n  });\n\n// Keep the script running if it's part of a larger initialization process\n// or exit if it's standalone.\n// setTimeout(() => {}, 10000); // Example keep-alive\n"],
  "mappings": ";;;;;;;;;;;;;;;;;;;;;;;;;AAAA,oBAAsB;;;ACAtB,qBAAoB;AAGpB,IAAM,iBAAiB,QAAQ,IAAI,2BAA2B;AAG9D,IAAM,YAAY,QAAQ,IAAI;AAE9B,IAAI,CAAC,aAAa,CAAC,gBAAgB;AAGjC,UAAQ;AAAA,IACN;AAAA,EACF;AAEF;AAGA,IAAM,oBAAoB;AAAA,EACxB,sBAAsB;AAAA;AAAA,EACtB,kBAAkB;AAAA;AACpB;AAEA,IAAI,mBAAmC;AAEvC,IAAI,aAAa,CAAC,gBAAgB;AAGhC,QAAM,gBAAgB,UAAU,QAAQ,gBAAgB,UAAU;AAGlE,qBAAmB,IAAI,eAAAA,QAAQ,eAAe,iBAAiB;AAE/D,mBAAiB,GAAG,WAAW,MAAM;AACnC,YAAQ,IAAI,mCAAmC;AAAA,EACjD,CAAC;AAED,mBAAiB,GAAG,SAAS,CAAC,QAAQ;AACpC,YAAQ,MAAM,4BAA4B,GAAG;AAAA,EAC/C,CAAC;AACH,OAAO;AACL,UAAQ,KAAK,6DAA6D;AAC5E;AAEA,IAAO,iBAAQ;;;AC3CR,IAAM,sBAAsB;AAC5B,IAAM,0BAA0B;AAChC,IAAM,mBAAmB;AACzB,IAAM,kBAAkB;AACxB,IAAM,2BAA2B;AACjC,IAAM,mCAAmC;;;AFehD,IAAI,gBAA8B;AAClC,IAAI,oBAAkC;AACtC,IAAI,aAA2B;AAC/B,IAAI,YAA0B;AAC9B,IAAI,oBAAkC;AACtC,IAAI,4BAA0C;AAG9C,IAAI,gBAAkB;AAEpB,kBAAgB,IAAI,oBAAM,qBAAqB;AAAA,IAC7C,YAAY;AAAA,IACZ,mBAAmB;AAAA;AAAA,MAEjB,UAAU;AAAA;AAAA,MACV,SAAS;AAAA,QACP,MAAM;AAAA;AAAA,QACN,OAAO;AAAA;AAAA,MACT;AAAA,MACA,kBAAkB;AAAA,QAChB,KAAK,OAAO,KAAK;AAAA;AAAA,QACjB,OAAO;AAAA;AAAA,MACT;AAAA,MACA,cAAc;AAAA,QACZ,KAAK,OAAO,KAAK;AAAA;AAAA,MACnB;AAAA,IACF;AAAA,EACF,CAAC;AAED,UAAQ,IAAI,UAAU,mBAAmB,gBAAgB;AAGzD,gBAAc,GAAG,SAAS,CAAC,UAAU;AACnC,YAAQ,MAAM,SAAS,mBAAmB,WAAW,KAAK;AAAA,EAC5D,CAAC;AACH,OAAO;AACL,UAAQ;AAAA,IACN,2CAA2C,mBAAmB;AAAA,EAChE;AACF;AAGA,IAAI,gBAAkB;AACpB,sBAAoB,IAAI,oBAAM,yBAAyB;AAAA,IACrD,YAAY;AAAA,IACZ,mBAAmB;AAAA,MACjB,UAAU;AAAA,MACV,SAAS;AAAA,QACP,MAAM;AAAA,QACN,OAAO;AAAA,MACT;AAAA,MACA,kBAAkB;AAAA,QAChB,KAAK,OAAO,KAAK;AAAA;AAAA,QACjB,OAAO;AAAA,MACT;AAAA,MACA,cAAc;AAAA,QACZ,KAAK,OAAO,KAAK;AAAA;AAAA,MACnB;AAAA,IACF;AAAA,EACF,CAAC;AAED,UAAQ,IAAI,UAAU,uBAAuB,gBAAgB;AAE7D,oBAAkB,GAAG,SAAS,CAAC,UAAU;AACvC,YAAQ,MAAM,SAAS,uBAAuB,WAAW,KAAK;AAAA,EAChE,CAAC;AACH,OAAO;AACL,UAAQ;AAAA,IACN,2CAA2C,uBAAuB;AAAA,EACpE;AACF;AAGA,IAAI,gBAAkB;AACpB,eAAa,IAAI,oBAAM,kBAAkB;AAAA,IACvC,YAAY;AAAA,IACZ,mBAAmB;AAAA,MACjB,UAAU;AAAA,MACV,SAAS;AAAA,QACP,MAAM;AAAA,QACN,OAAO;AAAA,MACT;AAAA,MACA,kBAAkB;AAAA,QAChB,KAAK,OAAO,KAAK;AAAA;AAAA,QACjB,OAAO;AAAA,MACT;AAAA,MACA,cAAc;AAAA,QACZ,KAAK,OAAO,KAAK;AAAA;AAAA,MACnB;AAAA,IACF;AAAA,EACF,CAAC;AAED,UAAQ,IAAI,UAAU,gBAAgB,gBAAgB;AAEtD,aAAW,GAAG,SAAS,CAAC,UAAU;AAChC,YAAQ,MAAM,SAAS,gBAAgB,WAAW,KAAK;AAAA,EACzD,CAAC;AACH,OAAO;AACL,UAAQ;AAAA,IACN,2CAA2C,gBAAgB;AAAA,EAC7D;AACF;AAGA,IAAI,gBAAkB;AACpB,cAAY,IAAI,oBAAM,iBAAiB;AAAA,IACrC,YAAY;AAAA,IACZ,mBAAmB;AAAA,MACjB,UAAU;AAAA,MACV,SAAS;AAAA,QACP,MAAM;AAAA,QACN,OAAO;AAAA,MACT;AAAA,MACA,kBAAkB;AAAA,QAChB,KAAK,OAAO,KAAK;AAAA;AAAA,QACjB,OAAO;AAAA,MACT;AAAA,MACA,cAAc;AAAA,QACZ,KAAK,OAAO,KAAK;AAAA;AAAA,MACnB;AAAA,IACF;AAAA,EACF,CAAC;AAED,UAAQ,IAAI,UAAU,eAAe,gBAAgB;AAErD,YAAU,GAAG,SAAS,CAAC,UAAU;AAC/B,YAAQ,MAAM,SAAS,eAAe,WAAW,KAAK;AAAA,EACxD,CAAC;AACH,OAAO;AACL,UAAQ;AAAA,IACN,2CAA2C,eAAe;AAAA,EAC5D;AACF;AAGA,IAAI,gBAAkB;AACpB,sBAAoB,IAAI,oBAAM,0BAA0B;AAAA,IACtD,YAAY;AAAA,IACZ,mBAAmB;AAAA,MACjB,UAAU;AAAA,MACV,kBAAkB;AAAA,QAChB,KAAK,OAAO,KAAK;AAAA,QACjB,OAAO;AAAA,MACT;AAAA,MACA,cAAc;AAAA,QACZ,KAAK,OAAO,KAAK;AAAA,MACnB;AAAA,IACF;AAAA,EACF,CAAC;AAED,UAAQ,IAAI,UAAU,wBAAwB,gBAAgB;AAE9D,oBAAkB,GAAG,SAAS,CAAC,UAAU;AACvC,YAAQ,MAAM,SAAS,wBAAwB,WAAW,KAAK;AAAA,EACjE,CAAC;AACH,OAAO;AACL,UAAQ;AAAA,IACN,2CAA2C,wBAAwB;AAAA,EACrE;AACF;AAGA,IAAI,gBAAkB;AACpB,8BAA4B,IAAI,oBAAM,kCAAkC;AAAA,IACtE,YAAY;AAAA,IACZ,mBAAmB;AAAA,MACjB,UAAU;AAAA;AAAA,MACV,kBAAkB;AAAA,QAChB,KAAK,OAAO,KAAK;AAAA;AAAA,QACjB,OAAO;AAAA,MACT;AAAA,MACA,cAAc;AAAA,QACZ,KAAK,OAAO,KAAK;AAAA;AAAA,MACnB;AAAA,IACF;AAAA,EACF,CAAC;AAED,UAAQ,IAAI,UAAU,gCAAgC,gBAAgB;AAEtE,4BAA0B,GAAG,SAAS,CAAC,UAAU;AAC/C,YAAQ,MAAM,SAAS,gCAAgC,WAAW,KAAK;AAAA,EACzE,CAAC;AACH,OAAO;AACL,UAAQ;AAAA,IACN,2CAA2C,gCAAgC;AAAA,EAC7E;AACF;;;AG/MA,IAAAC,iBAA4B;;;ACC5B,IAAAC,iBAA6B;AAC7B,qBAAwB;;;ACFxB,oBAA6B;;;ACA7B,2BAAuB;;;ACAvB,wBAA0B;AAC1B,gBAAkB;AAEX,IAAM,UAAM,6BAAU;AAAA;AAAA;AAAA;AAAA;AAAA,EAK3B,QAAQ;AAAA,IACN,cAAc,YACX,OAAO,EACP;AAAA,MACC,CAAC,QAAQ,CAAC,IAAI,SAAS,qBAAqB;AAAA,MAC5C;AAAA,IACF;AAAA,IACF,UAAU,YACP,KAAK,CAAC,eAAe,QAAQ,YAAY,CAAC,EAC1C,SAAS,aAAa;AAAA,IACzB,iBACE,QAAQ,IAAI,aAAa,eACrB,YAAE,OAAO,IACT,YAAE,OAAO,EAAE,SAAS;AAAA,IAC1B,cAAc,YAAE;AAAA;AAAA;AAAA,MAGd,CAAC,QAAQ,QAAQ,IAAI,cAAc;AAAA;AAAA,MAEnC,QAAQ,IAAI,SAAS,YAAE,OAAO,IAAI,YAAE,IAAI;AAAA,IAC1C;AAAA,IACA,oBAAoB,YAAE,IAAI,EAAE,SAAS;AAAA,EACvC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,QAAQ;AAAA;AAAA,EAER;AAAA;AAAA;AAAA;AAAA;AAAA,EAMA,YAAY;AAAA,IACV,cAAc,QAAQ,IAAI;AAAA,IAC1B,UAAU,QAAQ,IAAI;AAAA,IACtB,iBAAiB,QAAQ,IAAI;AAAA,IAC7B,cAAc,QAAQ,IAAI;AAAA,IAC1B,oBAAoB,QAAQ,IAAI;AAAA,EAClC;AAAA;AAAA;AAAA;AAAA;AAAA,EAKA,gBAAgB,CAAC,CAAC,QAAQ,IAAI;AAAA;AAAA;AAAA;AAAA;AAAA,EAK9B,wBAAwB;AAC1B,CAAC;;;AD1DD,IAAI,WAA0B;AAKvB,SAAS,yBAAwC;AACtD,MAAI,CAAC,IAAI,oBAAoB;AAC3B,YAAQ;AAAA,MACN;AAAA,IACF;AACA,WAAO;AAAA,EACT;AAEA,MAAI,CAAC,UAAU;AACb,QAAI;AACF,iBAAW,IAAI,4BAAO;AAAA,QACpB,MAAM,IAAI;AAAA;AAAA,QAEV,YAAY;AAAA,QACZ,gBAAgB;AAAA,QAChB,cAAc;AAAA;AAAA,MAChB,CAAC;AAAA,IAEH,SAAS,OAAO;AACd,cAAQ,MAAM,8CAA8C,KAAK;AACjE,aAAO;AAAA,IACT;AAAA,EACF;AAEA,SAAO;AACT;AAqBO,IAAM,wBAAwB;;;AE9CrC,eAAsB,oBACpB,UACkB;AAClB,QAAM,SAAS,uBAAuB;AACtC,MAAI,CAAC,OAAQ,QAAO;AAEpB,MAAI;AAEF,UAAM,oBAAoB;AAAA,MACxB,SAAS;AAAA,MACT,SAAS;AAAA,MACT,SAAS,MAAM,IAAI,CAAC,MAAM,EAAE,IAAI,EAAE,KAAK,GAAG;AAAA,MAC1C,SAAS,OAAO,IAAI,CAAC,MAAM;AACzB,cAAM,cAAc,GAAG,EAAE,IAAI,IAAI,EAAE,cAAc;AAEjD,eAAO,EAAE,gBAAgB,EAAE,sBACvB,GAAG,WAAW,IAAI,EAAE,mBAAmB,KACvC;AAAA,MACN,CAAC,EAAE,KAAK,GAAG;AAAA,MACX,SAAS,cAAc,IAAI,CAAC,OAAO,GAAG,KAAK,EAAE,KAAK,GAAG;AAAA,IACvD,EACG,OAAO,OAAO,EACd,KAAK,GAAG;AAEX,UAAM,OAAO,MAAM;AAAA,MACjB,OAAO;AAAA,MACP,IAAI,SAAS,GAAG,SAAS;AAAA,MACzB,UAAU;AAAA,QACR,GAAG;AAAA,QACH;AAAA,MACF;AAAA,IACF,CAAC;AAED,YAAQ,IAAI,2BAA2B,SAAS,EAAE,mBAAmB;AACrE,WAAO;AAAA,EACT,SAAS,OAAO;AACd,YAAQ,MAAM,mCAAmC,SAAS,EAAE,KAAK,KAAK;AACtE,WAAO;AAAA,EACT;AACF;AAsEA,eAAsB,qBAAqB,QAAkC;AAC3E,QAAM,SAAS,uBAAuB;AACtC,MAAI,CAAC,OAAQ,QAAO;AAEpB,MAAI;AACF,UAAM,OAAO,OAAO;AAAA,MAClB,OAAO;AAAA,MACP,IAAI,OAAO,SAAS;AAAA,IACtB,CAAC;AAED,YAAQ,IAAI,2BAA2B,MAAM,qBAAqB;AAClE,WAAO;AAAA,EACT,SAAS,OAAO;AAEd,QAAK,MAAc,eAAe,KAAK;AACrC,cAAQ;AAAA,QACN,mBAAmB,MAAM;AAAA,MAC3B;AACA,aAAO;AAAA,IACT;AACA,YAAQ,MAAM,oCAAoC,MAAM,KAAK,KAAK;AAClE,WAAO;AAAA,EACT;AACF;;;ACzIO,IAAM,sBAAsB,CAAC,SAAsB;AACxD,MAAI,CAAC,KAAM,QAAO;AAGlB,MAAI,OAAO,SAAS,SAAU,QAAO;AAGrC,MAAI,KAAK,QAAQ,OAAO,KAAK,SAAS,SAAU,QAAO,KAAK;AAG5D,MAAI,KAAK,WAAW,MAAM,QAAQ,KAAK,OAAO,GAAG;AAC/C,WAAO,KAAK,QAAQ,IAAI,mBAAmB,EAAE,KAAK,EAAE;AAAA,EACtD;AAGA,SAAO;AACT;;;ACZO,IAAM,iBAAiB;AAAA,EAC5B,wCAAqC,GAAG;AAAA,EACxC,gCAAiC,GAAG;AAAA,EACpC,0BAA8B,GAAG;AAAA,EACjC,wBAA6B,GAAG;AAAA,EAChC,wBAA6B,GAAG;AAAA,EAChC,oBAA2B,GAAG;AAAA,EAC9B,4BAA+B,GAAG;AACpC;AAGA,IAAM,cAAc;AAAA,EAClB,YAAY;AAAA,IACV,IAAI,EAAE,MAAM,UAAmB;AAAA,IAC/B,WAAW,EAAE,MAAM,UAAmB;AAAA,IACtC,aAAa,EAAE,MAAM,UAAmB;AAAA,IACxC,gBAAgB,EAAE,MAAM,UAAmB;AAAA,IAC3C,WAAW,EAAE,MAAM,OAAgB;AAAA,IACnC,WAAW,EAAE,MAAM,OAAgB;AAAA,IACnC,aAAa,EAAE,MAAM,UAAmB;AAAA,IACxC,eAAe,EAAE,MAAM,UAAmB;AAAA,IAC1C,gBAAgB,EAAE,MAAM,UAAmB;AAAA,IAC3C,mBAAmB;AAAA,MACjB,MAAM;AAAA,MACN,UAAU;AAAA,MACV,QAAQ;AAAA,QACN,SAAS;AAAA,UACP,MAAM;AAAA,UACN,cAAc;AAAA,QAChB;AAAA,MACF;AAAA,IACF;AAAA,IACA,cAAc;AAAA,MACZ,MAAM;AAAA,MACN,YAAY;AAAA,QACV,SAAS,EAAE,MAAM,UAAmB;AAAA,QACpC,WAAW,EAAE,MAAM,UAAmB;AAAA,QACtC,WAAW,EAAE,MAAM,UAAmB;AAAA,QACtC,OAAO,EAAE,MAAM,OAAgB;AAAA,QAC/B,cAAc,EAAE,MAAM,UAAmB;AAAA,QACzC,cAAc,EAAE,MAAM,SAAkB;AAAA,QACxC,cAAc,EAAE,MAAM,UAAmB;AAAA,QACzC,WAAW,EAAE,MAAM,OAAgB;AAAA,QACnC,YAAY,EAAE,MAAM,UAAmB;AAAA,QACvC,aAAa;AAAA,UACX,MAAM;AAAA,UACN,YAAY;AAAA,YACV,IAAI,EAAE,MAAM,UAAmB;AAAA,YAC/B,MAAM,EAAE,MAAM,UAAmB;AAAA,YACjC,MAAM;AAAA,cACJ,MAAM;AAAA,cACN,YAAY;AAAA,gBACV,MAAM,EAAE,MAAM,UAAmB;AAAA,cACnC;AAAA,YACF;AAAA,YACA,WAAW;AAAA,cACT,MAAM;AAAA,cACN,YAAY;AAAA,gBACV,OAAO,EAAE,MAAM,UAAmB;AAAA,cACpC;AAAA,YACF;AAAA,UACF;AAAA,QACF;AAAA,QACA,cAAc;AAAA,UACZ,MAAM;AAAA,UACN,YAAY;AAAA,YACV,IAAI,EAAE,MAAM,UAAmB;AAAA,YAC/B,MAAM,EAAE,MAAM,UAAmB;AAAA,YACjC,MAAM;AAAA,cACJ,MAAM;AAAA,cACN,YAAY;AAAA,gBACV,MAAM,EAAE,MAAM,UAAmB;AAAA,cACnC;AAAA,YACF;AAAA,YACA,WAAW;AAAA,cACT,MAAM;AAAA,cACN,YAAY;AAAA,gBACV,OAAO,EAAE,MAAM,UAAmB;AAAA,cACpC;AAAA,YACF;AAAA,UACF;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAAA,EACF;AACF;AAGO,IAAM,kBAAkB;AAAA,EAC7B,wCAAqC,GAAG;AAAA,IACtC,YAAY;AAAA,MACV,GAAG,YAAY;AAAA,MACf,cAAc,EAAE,MAAM,UAAmB;AAAA,MACzC,UAAU,EAAE,MAAM,UAAmB;AAAA,MACrC,YAAY,EAAE,MAAM,UAAmB;AAAA,MACvC,YAAY,EAAE,MAAM,UAAmB;AAAA,MACvC,cAAc,EAAE,MAAM,UAAmB;AAAA,MACzC,MAAM;AAAA,QACJ,MAAM;AAAA,QACN,UAAU;AAAA,QACV,QAAQ;AAAA,UACN,SAAS;AAAA,YACP,MAAM;AAAA,YACN,cAAc;AAAA,UAChB;AAAA,QACF;AAAA,MACF;AAAA,MACA,WAAW,EAAE,MAAM,UAAmB;AAAA,MACtC,QAAQ,EAAE,MAAM,UAAmB;AAAA,MACnC,SAAS,EAAE,MAAM,UAAmB;AAAA,MACpC,WAAW,EAAE,MAAM,UAAmB;AAAA,MACtC,WAAW,EAAE,MAAM,UAAmB;AAAA,MACtC,YAAY,EAAE,MAAM,UAAmB;AAAA,MACvC,UAAU,EAAE,MAAM,UAAmB;AAAA,MACrC,gBAAgB,EAAE,MAAM,UAAmB;AAAA,MAC3C,mBAAmB,EAAE,MAAM,QAAiB;AAAA,MAC5C,WAAW,EAAE,MAAM,UAAmB;AAAA,MACtC,YAAY,EAAE,MAAM,UAAmB;AAAA,MACvC,WAAW,EAAE,MAAM,UAAmB;AAAA,MACtC,MAAM;AAAA,QACJ,MAAM;AAAA,QACN,YAAY;AAAA,UACV,IAAI,EAAE,MAAM,UAAmB;AAAA,UAC/B,MAAM,EAAE,MAAM,UAAmB;AAAA,QACnC;AAAA,MACF;AAAA,MACA,OAAO;AAAA,QACL,MAAM;AAAA,QACN,YAAY;AAAA,UACV,IAAI,EAAE,MAAM,UAAmB;AAAA,UAC/B,OAAO,EAAE,MAAM,UAAmB;AAAA,UAClC,MAAM,EAAE,MAAM,OAAgB;AAAA,UAC9B,gBAAgB,EAAE,MAAM,OAAgB;AAAA,UACxC,cAAc,EAAE,MAAM,UAAmB;AAAA,UACzC,mBAAmB,EAAE,MAAM,UAAmB;AAAA,UAC9C,qBAAqB,EAAE,MAAM,OAAgB;AAAA,QAC/C;AAAA,MACF;AAAA,IACF;AAAA,EACF;AAAA,EACA,gCAAiC,GAAG;AAAA,IAClC,YAAY;AAAA,MACV,GAAG,YAAY;AAAA,MACf,MAAM;AAAA,QACJ,MAAM;AAAA,QACN,UAAU;AAAA,QACV,QAAQ;AAAA,UACN,SAAS;AAAA,YACP,MAAM;AAAA,YACN,cAAc;AAAA,UAChB;AAAA,QACF;AAAA,MACF;AAAA,MACA,WAAW,EAAE,MAAM,UAAmB;AAAA,MACtC,OAAO;AAAA,QACL,MAAM;AAAA,QACN,YAAY;AAAA,UACV,IAAI,EAAE,MAAM,UAAmB;AAAA,UAC/B,OAAO,EAAE,MAAM,UAAmB;AAAA,UAClC,MAAM,EAAE,MAAM,OAAgB;AAAA,UAC9B,gBAAgB,EAAE,MAAM,OAAgB;AAAA,QAC1C;AAAA,MACF;AAAA,IACF;AAAA,EACF;AAAA,EACA,0BAA8B,GAAG;AAAA,IAC/B,YAAY;AAAA,MACV,GAAG,YAAY;AAAA,MACf,MAAM;AAAA,QACJ,MAAM;AAAA,QACN,UAAU;AAAA,QACV,QAAQ;AAAA,UACN,SAAS;AAAA,YACP,MAAM;AAAA,YACN,cAAc;AAAA,UAChB;AAAA,QACF;AAAA,MACF;AAAA,MACA,MAAM,EAAE,MAAM,OAAgB;AAAA,MAC9B,MAAM,EAAE,MAAM,OAAgB;AAAA,MAC9B,UAAU,EAAE,MAAM,UAAmB;AAAA,MACrC,mBAAmB,EAAE,MAAM,UAAmB;AAAA,MAC9C,aAAa,EAAE,MAAM,UAAmB;AAAA,MACxC,eAAe,EAAE,MAAM,UAAmB;AAAA,MAC1C,SAAS,EAAE,MAAM,UAAmB;AAAA,MACpC,WAAW,EAAE,MAAM,UAAmB;AAAA,MACtC,WAAW,EAAE,MAAM,UAAmB;AAAA,MACtC,YAAY,EAAE,MAAM,UAAmB;AAAA,MACvC,gBAAgB,EAAE,MAAM,UAAmB;AAAA,MAC3C,mBAAmB,EAAE,MAAM,QAAiB;AAAA,MAC5C,SAAS,EAAE,MAAM,UAAmB;AAAA,MACpC,aAAa,EAAE,MAAM,UAAmB;AAAA,MACxC,WAAW,EAAE,MAAM,UAAmB;AAAA,MACtC,aAAa,EAAE,MAAM,OAAgB;AAAA,MACrC,aAAa,EAAE,MAAM,UAAmB;AAAA,MACxC,MAAM;AAAA,QACJ,MAAM;AAAA,QACN,YAAY;AAAA,UACV,IAAI,EAAE,MAAM,UAAmB;AAAA,UAC/B,MAAM,EAAE,MAAM,UAAmB;AAAA,QACnC;AAAA,MACF;AAAA,IACF;AAAA,EACF;AAAA,EACA,wBAA6B,GAAG;AAAA,IAC9B,YAAY;AAAA,MACV,GAAG,YAAY;AAAA,MACf,YAAY,EAAE,MAAM,UAAmB;AAAA,MACvC,cAAc,EAAE,MAAM,UAAmB;AAAA,MACzC,MAAM;AAAA,QACJ,MAAM;AAAA,QACN,UAAU;AAAA,QACV,QAAQ;AAAA,UACN,SAAS;AAAA,YACP,MAAM;AAAA,YACN,cAAc;AAAA,UAChB;AAAA,QACF;AAAA,MACF;AAAA,MACA,MAAM,EAAE,MAAM,OAAgB;AAAA,MAC9B,SAAS,EAAE,MAAM,OAAgB;AAAA,MACjC,UAAU,EAAE,MAAM,UAAmB;AAAA,MACrC,mBAAmB,EAAE,MAAM,UAAmB;AAAA,MAC9C,aAAa,EAAE,MAAM,UAAmB;AAAA,MACxC,eAAe,EAAE,MAAM,UAAmB;AAAA,MAC1C,SAAS,EAAE,MAAM,UAAmB;AAAA,MACpC,WAAW,EAAE,MAAM,UAAmB;AAAA,MACtC,WAAW,EAAE,MAAM,UAAmB;AAAA,MACtC,YAAY,EAAE,MAAM,UAAmB;AAAA,MACvC,cAAc,EAAE,MAAM,UAAmB;AAAA,MACzC,gBAAgB,EAAE,MAAM,UAAmB;AAAA,MAC3C,iBAAiB,EAAE,MAAM,UAAmB;AAAA,MAC5C,UAAU,EAAE,MAAM,UAAmB;AAAA,MACrC,gBAAgB,EAAE,MAAM,UAAmB;AAAA,MAC3C,mBAAmB,EAAE,MAAM,QAAiB;AAAA,MAC5C,SAAS,EAAE,MAAM,UAAmB;AAAA,MACpC,aAAa,EAAE,MAAM,UAAmB;AAAA,MACxC,WAAW,EAAE,MAAM,UAAmB;AAAA,MACtC,aAAa,EAAE,MAAM,OAAgB;AAAA,MACrC,MAAM;AAAA,QACJ,MAAM;AAAA,QACN,YAAY;AAAA,UACV,IAAI,EAAE,MAAM,UAAmB;AAAA,UAC/B,MAAM,EAAE,MAAM,UAAmB;AAAA,QACnC;AAAA,MACF;AAAA,IACF;AAAA,EACF;AAAA,EACA,wBAA6B,GAAG;AAAA,IAC9B,YAAY;AAAA,MACV,IAAI,EAAE,MAAM,UAAmB;AAAA,MAC/B,MAAM;AAAA,QACJ,MAAM;AAAA,QACN,UAAU;AAAA,QACV,QAAQ;AAAA,UACN,SAAS;AAAA,YACP,MAAM;AAAA,YACN,cAAc;AAAA,UAChB;AAAA,QACF;AAAA,MACF;AAAA,MACA,SAAS,EAAE,MAAM,UAAmB;AAAA,MACpC,MAAM,EAAE,MAAM,OAAgB;AAAA,MAC9B,MAAM,EAAE,MAAM,OAAgB;AAAA,MAC9B,WAAW,EAAE,MAAM,UAAmB;AAAA,MACtC,WAAW,EAAE,MAAM,OAAgB;AAAA,MACnC,aAAa,EAAE,MAAM,UAAmB;AAAA,MACxC,eAAe,EAAE,MAAM,UAAmB;AAAA,MAC1C,gBAAgB,EAAE,MAAM,UAAmB;AAAA,MAC3C,mBAAmB,EAAE,MAAM,OAAgB;AAAA,IAC7C;AAAA,EACF;AAAA,EACA,oBAA2B,GAAG;AAAA,IAC5B,YAAY;AAAA,MACV,GAAG,YAAY;AAAA,MACf,MAAM;AAAA,QACJ,MAAM;AAAA,QACN,UAAU;AAAA,QACV,QAAQ;AAAA,UACN,SAAS;AAAA,YACP,MAAM;AAAA,YACN,cAAc;AAAA,UAChB;AAAA,QACF;AAAA,MACF;AAAA,MACA,OAAO;AAAA,QACL,MAAM;AAAA,QACN,UAAU;AAAA,QACV,QAAQ;AAAA,UACN,SAAS;AAAA,YACP,MAAM;AAAA,YACN,cAAc;AAAA,UAChB;AAAA,QACF;AAAA,MACF;AAAA,MACA,aAAa,EAAE,MAAM,OAAgB;AAAA,MACrC,YAAY,EAAE,MAAM,UAAmB;AAAA,MACvC,MAAM,EAAE,MAAM,OAAgB;AAAA,MAC9B,KAAK,EAAE,MAAM,UAAmB;AAAA,MAChC,aAAa,EAAE,MAAM,OAAgB;AAAA,MACrC,WAAW,EAAE,MAAM,UAAmB;AAAA,IACxC;AAAA,EACF;AAAA,EACA,4BAA+B,GAAG;AAAA,IAChC,YAAY;AAAA,MACV,GAAG,YAAY;AAAA,MACf,MAAM;AAAA,QACJ,MAAM;AAAA,QACN,UAAU;AAAA,QACV,QAAQ;AAAA,UACN,SAAS;AAAA,YACP,MAAM;AAAA,YACN,cAAc;AAAA,UAChB;AAAA,QACF;AAAA,MACF;AAAA,MACA,MAAM,EAAE,MAAM,OAAgB;AAAA,MAC9B,MAAM,EAAE,MAAM,OAAgB;AAAA,MAC9B,iBAAiB,EAAE,MAAM,UAAmB;AAAA,MAC5C,mBAAmB,EAAE,MAAM,UAAmB;AAAA,MAC9C,mBAAmB,EAAE,MAAM,UAAmB;AAAA,MAC9C,UAAU,EAAE,MAAM,UAAmB;AAAA,MACrC,YAAY,EAAE,MAAM,UAAmB;AAAA,MACvC,SAAS,EAAE,MAAM,OAAgB;AAAA,MACjC,aAAa,EAAE,MAAM,UAAmB;AAAA,MACxC,aAAa,EAAE,MAAM,OAAgB;AAAA,MACrC,WAAW,EAAE,MAAM,UAAmB;AAAA,IACxC;AAAA,EACF;AACF;AAsFO,SAAS,0BACd,WACA,OAC8B;AAC9B,QAAM,OAAqC,CAAC;AAE5C,UAAQ,WAAW;AAAA,IACjB,KAAK;AACH,WAAK,eAAe,QAAQ,KAAK;AACjC,WAAK,QAAQ,OAAO,KAAK;AACzB;AAAA,IAEF,KAAK;AACH,UAAI,OAAO;AACT,cAAM,OAAO,IAAI,KAAK,KAAK;AAC3B,YAAI,CAAC,MAAM,KAAK,QAAQ,CAAC,GAAG;AAC1B,eAAK,YAAY,KAAK,YAAY;AAClC,eAAK,QAAQ,KAAK,YAAY;AAAA,QAChC;AAAA,MACF;AACA;AAAA,IAEF,KAAK;AACH,WAAK,eAAe,OAAO,KAAK;AAChC,WAAK,QAAQ,OAAO,KAAK;AACzB;AAAA,IAEF,KAAK;AACH,UAAI,MAAM,QAAQ,KAAK,GAAG;AACxB,aAAK,aAAa,MAAM,IAAI,CAAC,MAAM,OAAO,CAAC,CAAC;AAC5C,aAAK,QAAQ,MAAM,KAAK,GAAG;AAAA,MAC7B,WAAW,OAAO;AAEhB,YAAI;AACF,gBAAM,SAAS,KAAK,MAAM,KAAK;AAC/B,cAAI,MAAM,QAAQ,MAAM,GAAG;AACzB,iBAAK,aAAa,OAAO,IAAI,CAAC,MAAM,OAAO,CAAC,CAAC;AAC7C,iBAAK,QAAQ,OAAO,KAAK,GAAG;AAAA,UAC9B;AAAA,QACF,QAAQ;AACN,eAAK,QAAQ,OAAO,KAAK;AAAA,QAC3B;AAAA,MACF;AACA;AAAA,IAEF,KAAK;AACH,WAAK,eAAe,OAAO,KAAK;AAChC,WAAK,QAAQ,OAAO,KAAK;AACzB;AAAA,IAEF,KAAK;AAAA,IACL,KAAK;AACH,WAAK,eAAe,OAAO,KAAK;AAChC,WAAK,QAAQ,OAAO,KAAK;AACzB;AAAA,IAEF,KAAK;AAEH,UAAI,OAAO;AACT,YAAI;AACF,gBAAM,UAAU,OAAO,UAAU,WAAW,KAAK,MAAM,KAAK,IAAI;AAChE,gBAAM,cAAc,sBAAsB,OAAO;AACjD,eAAK,QAAQ;AAAA,QACf,QAAQ;AACN,eAAK,QAAQ,OAAO,KAAK;AAAA,QAC3B;AAAA,MACF;AACA;AAAA,IAEF,KAAK;AAEH,UAAI,OAAO;AACT,aAAK,QAAQ,OAAO,KAAK;AAAA,MAC3B;AACA;AAAA,IAEF;AACE,WAAK,QAAQ,OAAO,KAAK;AAAA,EAC7B;AAEA,SAAO;AACT;AAKA,SAAS,sBAAsB,SAAsB;AACnD,MAAI,CAAC,WAAW,CAAC,QAAQ,QAAS,QAAO;AAEzC,MAAI,OAAO;AAEX,WAAS,gBAAgB,MAAW;AAClC,QAAI,KAAK,MAAM;AACb,cAAQ,KAAK,OAAO;AAAA,IACtB;AACA,QAAI,KAAK,SAAS;AAChB,WAAK,QAAQ,QAAQ,eAAe;AAAA,IACtC;AAAA,EACF;AAEA,UAAQ,QAAQ,QAAQ,eAAe;AACvC,SAAO,KAAK,KAAK;AACnB;AAKO,SAAS,0BACd,aAiBuB;AACvB,SAAO,YAAY,IAAI,CAAC,QAAQ;AAC9B,UAAM,YAAY,IAAI,MAAM,MAAM,QAAQ,IAAI,MAAM;AACpD,UAAM,cAAc,0BAA0B,WAAW,IAAI,KAAK;AAElE,UAAM,MAA2B;AAAA,MAC/B,SAAS,IAAI;AAAA,MACb,WAAW,IAAI,MAAM;AAAA,MACrB;AAAA,MACA,GAAG;AAAA,IACL;AAGA,QACE,IAAI,SACJ,IAAI,MAAM,iBACT,cAAc,YAAY,cAAc,aACzC;AACA,YAAM,iBAAiB,IAAI,MAAM,aAAa;AAAA,QAC5C,CAAC,OAAO,GAAG,YAAY,OAAO,IAAI;AAAA,MACpC;AACA,UAAI,gBAAgB;AAClB,YAAI,cAAc;AAAA,UAChB,IAAI,eAAe,YAAY;AAAA,UAC/B,MAAM,eAAe,YAAY;AAAA,UACjC,MAAM,eAAe,YAAY;AAAA,UACjC,WAAW,eAAe,YAAY;AAAA,QACxC;AAAA,MACF;AAAA,IACF;AAGA,QAAI,IAAI,MAAM,gBAAgB,cAAc,gBAAgB;AAC1D,UAAI,eAAe,IAAI,MAAM,aAAa,IAAI,CAAC,QAAQ;AAAA,QACrD,IAAI,GAAG,YAAY;AAAA,QACnB,MAAM,GAAG,YAAY;AAAA,QACrB,MAAM,GAAG,YAAY;AAAA,QACrB,WAAW,GAAG,YAAY;AAAA,MAC5B,EAAE;AAAA,IACJ;AAEA,WAAO;AAAA,EACT,CAAC;AACH;;;ALlkBA,IAAM,SAAS,IAAI,2BAAa;AAKhC,SAAS,gBAAgB,UAAuB;AAC9C,MAAI,CAAC,SAAU,QAAO;AAEtB,MAAI;AAEF,QAAI,OAAO,aAAa,UAAU;AAChC,YAAM,SAAS,KAAK,MAAM,QAAQ;AAClC,aAAO,oBAAoB,MAAM;AAAA,IACnC;AAEA,WAAO,oBAAoB,QAAQ;AAAA,EACrC,SAAS,OAAO;AAEd,WAAO,OAAO,aAAa,WAAW,WAAW;AAAA,EACnD;AACF;AAKA,eAAsB,4BACpB,QACwC;AACxC,QAAM,WAAW,MAAM,OAAO,gBAAgB,WAAW;AAAA,IACvD,OAAO,EAAE,IAAI,OAAO;AAAA,IACpB,SAAS;AAAA,MACP,SAAS;AAAA,MACT,QAAQ;AAAA,MACR,UAAU;AAAA,MACV,OAAO;AAAA,QACL,SAAS;AAAA,UACP,MAAM;AAAA,UACN,OAAO;AAAA,QACT;AAAA,MACF;AAAA,MACA,SAAS;AAAA,MACT,MAAM;AAAA,MACN,OAAO;AAAA,QACL,SAAS,EAAE,OAAO,MAAM;AAAA,QACxB,SAAS;AAAA,UACP,iBAAiB;AAAA,YACf,SAAS;AAAA,cACP,OAAO;AAAA,gBACL,SAAS,EAAE,OAAO,MAAM;AAAA,cAC1B;AAAA,YACF;AAAA,UACF;AAAA,QACF;AAAA,MACF;AAAA,MACA,iBAAiB;AAAA,QACf,SAAS;AAAA,UACP,OAAO;AAAA,YACL,SAAS;AAAA,cACP,MAAM;AAAA,cACN,cAAc;AAAA,gBACZ,SAAS;AAAA,kBACP,aAAa;AAAA,oBACX,SAAS;AAAA,sBACP,MAAM;AAAA,sBACN,WAAW;AAAA,oBACb;AAAA,kBACF;AAAA,gBACF;AAAA,cACF;AAAA,YACF;AAAA,UACF;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAAA,EACF,CAAC;AAED,MAAI,CAAC,SAAU,QAAO;AAGtB,QAAM,aAAa,MAAM,gBAAgB,SAAS,QAAQ;AAE1D,SAAO;AAAA,IACL,IAAI,SAAS;AAAA,IACb,WAAW,SAAS;AAAA,IACpB,aAAa,SAAS,QAAQ;AAAA,IAC9B,gBAAgB,SAAS,QAAQ;AAAA,IACjC,cAAc,SAAS;AAAA,IACvB,UAAU,SAAS;AAAA,IACnB;AAAA,IACA,YAAY,SAAS;AAAA,IACrB,cAAc,SAAS,SAAS;AAAA,IAChC,MAAM,SAAS;AAAA,IACf,WAAW,SAAS;AAAA,IACpB,QAAQ,SAAS;AAAA,IACjB,SAAS,SAAS;AAAA,IAClB,WAAW,SAAS,MAAM;AAAA,IAC1B,WAAW,SAAS,MAAM,KAAK;AAAA,IAC/B,YAAY,SAAS,MAAM,MAAM;AAAA,IACjC,UAAU,SAAS;AAAA,IACnB,gBAAgB,SAAS;AAAA,IACzB,mBAAmB,SAAS;AAAA,IAC5B,WAAW,SAAS;AAAA,IACpB,YAAY,SAAS;AAAA,IACrB,WAAW,SAAS;AAAA,IACpB,WAAW,SAAS;AAAA,IACpB,WAAW,SAAS;AAAA,IACpB,aAAa,SAAS,QAAQ;AAAA,IAC9B,cAAc,SAAS,QAAQ;AAAA,IAC/B,MAAM,SAAS,KAAK,IAAI,CAAC,SAAS;AAAA,MAChC,IAAI,IAAI;AAAA,MACR,MAAM,IAAI;AAAA,IACZ,EAAE;AAAA,IACF,cAAc;AAAA,MACZ,SAAS,gBAAgB,IAAI,CAAC,SAAS;AAAA,QACrC,SAAS,IAAI;AAAA,QACb,OAAO;AAAA,UACL,aAAa,IAAI,MAAM;AAAA,UACvB,YAAY,IAAI,MAAM;AAAA,UACtB,MAAM,IAAI,MAAM,OAAO,EAAE,MAAM,IAAI,MAAM,KAAK,KAAK,IAAI;AAAA,UACvD,cAAc,IAAI,MAAM,cAAc,IAAI,CAAC,QAAQ;AAAA,YACjD,aAAa;AAAA,cACX,IAAI,GAAG,YAAY;AAAA,cACnB,MAAM,GAAG,YAAY;AAAA,cACrB,MAAM,GAAG,YAAY,OACjB,EAAE,MAAM,GAAG,YAAY,KAAK,KAAK,IACjC;AAAA,cACJ,WAAW,GAAG,YAAY,YACtB,EAAE,OAAO,GAAG,YAAY,UAAU,MAAM,IACxC;AAAA,YACN;AAAA,UACF,EAAE;AAAA,QACJ;AAAA,QACA,OAAO,IAAI;AAAA,MACb,EAAE;AAAA,IACJ,EACG;AAAA,MACC,CAAC,OAAO,GAAG,UAAU,QAAQ,GAAG,UAAU,UAAa,GAAG,UAAU;AAAA,IACtE,EACC,IAAI,CAAC,QAAQ;AAAA,MACZ,SAAS,GAAG;AAAA,MACZ,WAAW,GAAG;AAAA,MACd,WAAW,GAAG;AAAA,MACd,OAAO,GAAG,SAAS;AAAA;AAAA,IACrB,EAAE;AAAA,IACJ,OAAO,SAAS,MAAM,QAAQ,CAAC,SAAgB;AAE7C,UAAI,KAAK,qBAAqB,KAAK,iBAAiB;AAClD,eAAO,KAAK,gBAAgB,MAAM,IAAI,CAAC,MAAM,WAAW;AAAA,UACtD,IAAI,KAAK,KAAK,MAAO;AAAA;AAAA,UACrB,OAAO,KAAK;AAAA,UACZ,MAAM,gBAAgB,KAAK,IAAI;AAAA,UAC/B,gBAAgB,gBAAgB,KAAK,cAAc;AAAA,UACnD,cAAc;AAAA,UACd,mBAAmB,KAAK;AAAA,UACxB,qBAAqB,KAAK,iBAAiB;AAAA,QAC7C,EAAE;AAAA,MACJ;AAEA,aAAO;AAAA,QACL;AAAA,UACE,IAAI,KAAK;AAAA,UACT,OAAO,KAAK;AAAA,UACZ,MAAM,gBAAgB,KAAK,IAAI;AAAA,UAC/B,gBAAgB,gBAAgB,KAAK,cAAc;AAAA,UACnD,cAAc;AAAA,UACd,mBAAmB;AAAA,UACnB,qBAAqB;AAAA,QACvB;AAAA,MACF;AAAA,IACF,CAAC;AAAA,EACH;AACF;AAKA,eAAe,gBAAgB,UAAmC;AAChE,QAAM,SAAS,MAAM,OAAO,kBAAkB,WAAW;AAAA,IACvD,OAAO,EAAE,IAAI,SAAS;AAAA,IACtB,SAAS,EAAE,QAAQ,KAAK;AAAA,EAC1B,CAAC;AAED,MAAI,CAAC,OAAQ,QAAO;AAEpB,QAAM,OAAO,CAAC,OAAO,IAAI;AACzB,MAAI,UAAe;AAEnB,SAAO,QAAQ,QAAQ;AACrB,SAAK,QAAQ,QAAQ,OAAO,IAAI;AAChC,UAAM,aAAa,MAAM,OAAO,kBAAkB,WAAW;AAAA,MAC3D,OAAO,EAAE,IAAI,QAAQ,OAAO,GAAG;AAAA,MAC/B,SAAS,EAAE,QAAQ,KAAK;AAAA,IAC1B,CAAC;AACD,QAAI,CAAC,WAAY;AACjB,cAAU;AAAA,EACZ;AAEA,SAAO,MAAM,KAAK,KAAK,GAAG;AAC5B;AAKA,eAAsB,kCACpB,QACkB;AAClB,QAAM,MAAM,MAAM,4BAA4B,MAAM;AACpD,MAAI,CAAC,KAAK;AAER,UAAM,qBAAqB,MAAM;AACjC,WAAO;AAAA,EACT;AAIA,MAAI,IAAI,YAAY;AAClB,UAAM,qBAAqB,MAAM;AACjC,WAAO;AAAA,EACT;AAEA,SAAO,MAAM,oBAAoB,GAAG;AACtC;;;AMpOA,IAAAC,iBAA6B;AAG7B,IAAMC,UAAS,IAAI,4BAAa;AAiBhC,eAAsB,aAAa,SAA4C;AAC7E,QAAM,SAAS,uBAAuB;AACtC,MAAI,CAAC,QAAQ;AACX,UAAM,IAAI,MAAM,oCAAoC;AAAA,EACtD;AAEA,QAAM,oBAAoB;AAAA,IACxB,QAAQ;AAAA,IACR,QAAQ,OAAO,oBAAoB,QAAQ,IAAI,IAAI;AAAA,IACnD,QAAQ,OAAO,oBAAoB,QAAQ,IAAI,IAAI;AAAA,IACnD,QAAQ,KAAK,IAAI,CAAC,MAAM,EAAE,IAAI,EAAE,KAAK,GAAG;AAAA,EAC1C,EAAE,KAAK,GAAG;AAEV,QAAM,WAAW;AAAA,IACf,IAAI,QAAQ;AAAA,IACZ,WAAW,QAAQ;AAAA,IACnB,aAAa,QAAQ,QAAQ;AAAA,IAC7B,MAAM,QAAQ;AAAA,IACd,MAAM,QAAQ;AAAA,IACd,MAAM,QAAQ;AAAA,IACd,UAAU,QAAQ;AAAA,IAClB,mBAAmB,QAAQ,eAAe;AAAA,IAC1C,aAAa,QAAQ;AAAA,IACrB,eAAe,QAAQ,WAAW;AAAA,IAClC,SAAS,QAAQ;AAAA,IACjB,WAAW,QAAQ,MAAM;AAAA,IACzB,gBAAgB,QAAQ;AAAA,IACxB,mBAAmB,QAAQ;AAAA,IAC3B,SAAS,QAAQ;AAAA,IACjB,aAAa,QAAQ;AAAA,IACrB,WAAW,QAAQ;AAAA,IACnB,aAAa,QAAQ;AAAA,IACrB,aAAa,QAAQ;AAAA,IACrB,WAAW,QAAQ;AAAA,IACnB,aAAa,QAAQ;AAAA,IACrB,eAAe,QAAQ,UAAU;AAAA,IACjC,MAAM,QAAQ,KAAK,IAAI,CAAC,SAAS,EAAE,IAAI,IAAI,IAAI,MAAM,IAAI,KAAK,EAAE;AAAA,IAChE;AAAA,EACF;AAEA,QAAM,OAAO,MAAM;AAAA,IACjB,OAAO,wCAA4C;AAAA,IACnD,IAAI,QAAQ,GAAG,SAAS;AAAA,IACxB;AAAA,IACA,SAAS;AAAA,EACX,CAAC;AACH;AA4BA,eAAsB,2BAA2B,WAAqC;AACpF,QAAM,SAAS,uBAAuB;AACtC,MAAI,CAAC,QAAQ;AACX,YAAQ,KAAK,oCAAoC;AACjD,WAAO;AAAA,EACT;AAEA,MAAI;AACF,UAAM,UAAU,MAAMC,QAAO,SAAS,WAAW;AAAA,MAC/C,OAAO,EAAE,IAAI,UAAU;AAAA,MACvB,SAAS;AAAA,QACP,SAAS;AAAA,QACT,WAAW;AAAA,QACX,OAAO;AAAA,QACP,eAAe;AAAA,QACf,WAAW;AAAA,QACX,MAAM;AAAA,MACR;AAAA,IACF,CAAC;AAED,QAAI,CAAC,SAAS;AACZ,cAAQ,KAAK,YAAY,SAAS,YAAY;AAC9C,aAAO;AAAA,IACT;AAKA,UAAM,aAAa,OAA6B;AAChD,WAAO;AAAA,EACT,SAAS,OAAO;AACd,YAAQ,MAAM,2BAA2B,SAAS,KAAK,KAAK;AAC5D,WAAO;AAAA,EACT;AACF;;;AChIA,IAAAC,iBAA6B;AAG7B,IAAMC,UAAS,IAAI,4BAAa;AA4BhC,eAAsB,aAAa,SAA4C;AAC7E,QAAM,SAAS,uBAAuB;AACtC,MAAI,CAAC,QAAQ;AACX,UAAM,IAAI,MAAM,oCAAoC;AAAA,EACtD;AAEA,QAAM,oBAAoB;AAAA,IACxB,QAAQ;AAAA,IACR,QAAQ,OAAO,oBAAoB,QAAQ,IAAI,IAAI;AAAA,IACnD,QAAQ,UAAU,oBAAoB,QAAQ,OAAO,IAAI;AAAA,IACzD,QAAQ,KAAK,IAAI,CAAC,MAAM,EAAE,IAAI,EAAE,KAAK,GAAG;AAAA,EAC1C,EAAE,KAAK,GAAG;AAGV,QAAM,WAAW;AAAA,IACf,IAAI,QAAQ;AAAA,IACZ,WAAW,QAAQ;AAAA,IACnB,aAAa,QAAQ,QAAQ;AAAA,IAC7B,YAAY,QAAQ;AAAA,IACpB,cAAc,QAAQ,SAAS;AAAA,IAC/B,MAAM,QAAQ;AAAA,IACd,MAAM,QAAQ;AAAA,IACd,SAAS,QAAQ;AAAA,IACjB,UAAU,QAAQ;AAAA,IAClB,mBAAmB,QAAQ,eAAe;AAAA,IAC1C,aAAa,QAAQ;AAAA,IACrB,eAAe,QAAQ,WAAW;AAAA,IAClC,SAAS,QAAQ;AAAA,IACjB,WAAW,QAAQ,MAAM;AAAA,IACzB,cAAc,QAAQ;AAAA,IACtB,gBAAgB,QAAQ,YAAY;AAAA,IACpC,UAAU,QAAQ;AAAA,IAClB,gBAAgB,QAAQ;AAAA,IACxB,mBAAmB,QAAQ;AAAA,IAC3B,SAAS,QAAQ;AAAA,IACjB,aAAa,QAAQ;AAAA,IACrB,WAAW,QAAQ;AAAA,IACnB,aAAa,QAAQ;AAAA,IACrB,WAAW,QAAQ;AAAA,IACnB,aAAa,QAAQ;AAAA,IACrB,eAAe,QAAQ,UAAU;AAAA,IACjC,MAAM,QAAQ,KAAK,IAAI,CAAC,SAAS,EAAE,IAAI,IAAI,IAAI,MAAM,IAAI,KAAK,EAAE;AAAA,IAChE;AAAA,EACF;AAEA,QAAM,OAAO,MAAM;AAAA,IACjB,OAAO,sCAA2C;AAAA,IAClD,IAAI,QAAQ,GAAG,SAAS;AAAA,IACxB;AAAA,IACA,SAAS;AAAA,EACX,CAAC;AACH;AA4BA,eAAsB,2BAA2B,WAAqC;AACpF,QAAM,SAAS,uBAAuB;AACtC,MAAI,CAAC,QAAQ;AACX,YAAQ,KAAK,oCAAoC;AACjD,WAAO;AAAA,EACT;AAEA,MAAI;AACF,UAAM,UAAU,MAAMC,QAAO,SAAS,WAAW;AAAA,MAC/C,OAAO,EAAE,IAAI,UAAU;AAAA,MACvB,SAAS;AAAA,QACP,SAAS;AAAA,QACT,WAAW;AAAA,QACX,YAAY;AAAA,QACZ,OAAO;AAAA,QACP,UAAU;AAAA,QACV,eAAe;AAAA,QACf,WAAW;AAAA,QACX,MAAM;AAAA,MACR;AAAA,IACF,CAAC;AAED,QAAI,CAAC,SAAS;AACZ,cAAQ,KAAK,WAAW,SAAS,YAAY;AAC7C,aAAO;AAAA,IACT;AAKA,UAAM,aAAa,OAA6B;AAChD,WAAO;AAAA,EACT,SAAS,OAAO;AACd,YAAQ,MAAM,0BAA0B,SAAS,KAAK,KAAK;AAC3D,WAAO;AAAA,EACT;AACF;;;ACxJA,IAAAC,iBAA6B;AAS7B,IAAMC,UAAS,IAAI,4BAAa;AA4BhC,eAAsB,wBACpB,aACoC;AACpC,QAAM,YAAY,MAAMA,QAAO,gBAAgB,WAAW;AAAA,IACxD,OAAO,EAAE,IAAI,YAAY;AAAA,IACzB,SAAS;AAAA,MACP,SAAS;AAAA,MACT,WAAW;AAAA,MACX,OAAO;AAAA,QACL,SAAS,EAAE,OAAO,MAAM;AAAA,MAC1B;AAAA,IACF;AAAA,EACF,CAAC;AAED,MAAI,CAAC,UAAW,QAAO;AAGvB,QAAM,oBAAoB;AAAA,IACxB,UAAU;AAAA,IACV,GAAG,UAAU,MAAM,IAAI,CAAC,SAAS;AAC/B,UAAI,WAAW;AACf,UAAI,qBAAqB;AAGzB,UAAI,OAAO,KAAK,SAAS,UAAU;AACjC,YAAI;AACF,gBAAM,SAAS,KAAK,MAAM,KAAK,IAAI;AACnC,qBAAW,oBAAoB,MAAM;AAAA,QACvC,QAAQ;AACN,qBAAW,KAAK;AAAA,QAClB;AAAA,MACF,WAAW,KAAK,MAAM;AACpB,mBAAW,oBAAoB,KAAK,IAAI;AAAA,MAC1C;AAGA,UAAI,OAAO,KAAK,mBAAmB,UAAU;AAC3C,YAAI;AACF,gBAAM,SAAS,KAAK,MAAM,KAAK,cAAc;AAC7C,+BAAqB,oBAAoB,MAAM;AAAA,QACjD,QAAQ;AACN,+BAAqB,KAAK;AAAA,QAC5B;AAAA,MACF,WAAW,KAAK,gBAAgB;AAC9B,6BAAqB,oBAAoB,KAAK,cAAc;AAAA,MAC9D;AAEA,aAAO,GAAG,QAAQ,IAAI,kBAAkB;AAAA,IAC1C,CAAC;AAAA,EACH,EAAE,KAAK,GAAG;AAEV,SAAO;AAAA,IACL,IAAI,UAAU;AAAA,IACd,MAAM,UAAU;AAAA,IAChB,WAAW,UAAU;AAAA,IACrB,aAAa,UAAU,QAAQ;AAAA,IAC/B,gBAAgB,UAAU,QAAQ;AAAA,IAClC,WAAW,UAAU;AAAA,IACrB,aAAa,UAAU;AAAA,IACvB,eAAe,UAAU,UAAU;AAAA,IACnC,gBAAgB,UAAU,UAAU;AAAA,IACpC,WAAW,UAAU;AAAA,IACrB,OAAO,UAAU,MAAM,IAAI,CAAC,UAAU;AAAA,MACpC,IAAI,KAAK;AAAA,MACT,OAAO,KAAK;AAAA,MACZ,MACE,OAAO,KAAK,SAAS,WACjB,KAAK,UAAU,KAAK,IAAI,IACxB,OAAO,KAAK,IAAI;AAAA,MACtB,gBACE,OAAO,KAAK,mBAAmB,WAC3B,KAAK,UAAU,KAAK,cAAc,IAClC,OAAO,KAAK,cAAc;AAAA,IAClC,EAAE;AAAA,IACF;AAAA,EACF;AACF;AAKA,eAAsB,gBACpB,UACkB;AAClB,QAAM,SAAS,uBAAuB;AACtC,MAAI,CAAC,OAAQ,QAAO;AAEpB,MAAI;AACF,UAAM,OAAO,MAAM;AAAA,MACjB,OAAO,8CAA+C;AAAA,MACtD,IAAI,SAAS,GAAG,SAAS;AAAA,MACzB,UAAU;AAAA,IACZ,CAAC;AAED,YAAQ,IAAI,uBAAuB,SAAS,EAAE,mBAAmB;AACjE,WAAO;AAAA,EACT,SAAS,OAAO;AACd,YAAQ,MAAM,+BAA+B,SAAS,EAAE,KAAK,KAAK;AAClE,WAAO;AAAA,EACT;AACF;AAiCA,eAAsB,8BACpB,QACkB;AAClB,QAAM,MAAM,MAAM,wBAAwB,MAAM;AAChD,MAAI,CAAC,IAAK,QAAO;AAGjB,SAAO,MAAM,gBAAgB,GAAG;AAClC;;;AC5KA,IAAAC,iBAA6B;AAG7B,IAAMC,UAAS,IAAI,4BAAa;AA2ChC,SAAS,oBAAoB,OAIpB;AAEP,MAAI,MAAM,SAAS;AACjB,WAAO,MAAM;AAAA,EACf;AAGA,MAAI,MAAM,kBAAkB,CAAC,GAAG,SAAS;AACvC,WAAO,MAAM,gBAAgB,CAAC,EAAE;AAAA,EAClC;AAGA,MAAI,MAAM,WAAW,CAAC,GAAG,SAAS;AAChC,WAAO,MAAM,SAAS,CAAC,EAAE;AAAA,EAC3B;AAGA,MAAI,MAAM,WAAW,CAAC,GAAG,SAAS;AAChC,WAAO,MAAM,SAAS,CAAC,EAAE;AAAA,EAC3B;AAGA,MAAI,MAAM,iBAAiB,CAAC,GAAG,SAAS,SAAS;AAC/C,WAAO,MAAM,eAAe,CAAC,EAAE,QAAQ;AAAA,EACzC;AAGA,MAAI,MAAM,iBAAiB,CAAC,GAAG,SAAS,SAAS;AAC/C,WAAO,MAAM,eAAe,CAAC,EAAE,QAAQ;AAAA,EACzC;AAGA,MAAI,MAAM,qBAAqB,CAAC,GAAG,eAAe,SAAS,SAAS;AAClE,WAAO,MAAM,mBAAmB,CAAC,EAAE,cAAc,QAAQ;AAAA,EAC3D;AAEA,SAAO;AACT;AAKA,eAAsB,WAAW,OAAwC;AACvE,QAAM,SAAS,uBAAuB;AACtC,MAAI,CAAC,QAAQ;AACX,UAAM,IAAI,MAAM,oCAAoC;AAAA,EACtD;AAGA,QAAM,cAAc,oBAAoB,KAAK;AAG7C,MAAI,CAAC,aAAa;AAChB,YAAQ,KAAK,SAAS,MAAM,EAAE,KAAK,MAAM,IAAI,4CAA4C;AACzF;AAAA,EACF;AAEA,QAAM,oBAAoB;AAAA,IACxB,MAAM;AAAA,IACN,MAAM;AAAA,IACN,MAAM,eAAe;AAAA,IACrB,MAAM,cAAc;AAAA,IACpB,MAAM,OAAO,oBAAoB,MAAM,IAAI,IAAI;AAAA,IAC/C,MAAM,aAAa,QAAQ;AAAA,EAC7B,EAAE,KAAK,GAAG;AAEV,QAAM,WAAW;AAAA,IACf,IAAI,MAAM;AAAA,IACV,WAAW,YAAY;AAAA,IACvB,aAAa,YAAY;AAAA,IACzB,gBAAgB,YAAY;AAAA,IAC5B,MAAM,MAAM;AAAA,IACZ,OAAO,MAAM;AAAA,IACb,aAAa,MAAM;AAAA,IACnB,YAAY,MAAM;AAAA,IAClB,MAAM,MAAM;AAAA,IACZ,KAAM,MAAM,MAAc;AAAA,IAC1B,aAAa,MAAM,aAAa,QAAQ;AAAA,IACxC,WAAW,MAAM;AAAA,IACjB,WAAW,MAAM;AAAA,IACjB,aAAa,MAAM;AAAA,IACnB,eAAe,MAAM,UAAU;AAAA,IAC/B,gBAAgB,MAAM,UAAU;AAAA,IAChC;AAAA,EACF;AAEA,QAAM,OAAO,MAAM;AAAA,IACjB,OAAO,kCAAyC;AAAA,IAChD,IAAI,MAAM,GAAG,SAAS;AAAA,IACtB;AAAA,IACA,SAAS;AAAA,EACX,CAAC;AACH;AA4BA,eAAsB,yBACpB,SACkB;AAClB,QAAM,SAAS,uBAAuB;AACtC,MAAI,CAAC,QAAQ;AACX,YAAQ,KAAK,oCAAoC;AACjD,WAAO;AAAA,EACT;AAEA,MAAI;AACF,UAAM,QAAQ,MAAMC,QAAO,MAAM,WAAW;AAAA,MAC1C,OAAO,EAAE,IAAI,QAAQ;AAAA,MACrB,SAAS;AAAA,QACP,WAAW;AAAA,QACX,aAAa;AAAA;AAAA,QAEb,SAAS;AAAA;AAAA,QAET,iBAAiB;AAAA,UACf,MAAM;AAAA,UACN,SAAS;AAAA,YACP,SAAS;AAAA,UACX;AAAA,QACF;AAAA,QACA,UAAU;AAAA,UACR,MAAM;AAAA,UACN,SAAS;AAAA,YACP,SAAS;AAAA,UACX;AAAA,QACF;AAAA,QACA,UAAU;AAAA,UACR,MAAM;AAAA,UACN,SAAS;AAAA,YACP,SAAS;AAAA,UACX;AAAA,QACF;AAAA,QACA,gBAAgB;AAAA,UACd,MAAM;AAAA,UACN,SAAS;AAAA,YACP,SAAS;AAAA,cACP,SAAS;AAAA,gBACP,SAAS;AAAA,cACX;AAAA,YACF;AAAA,UACF;AAAA,QACF;AAAA,QACA,gBAAgB;AAAA,UACd,MAAM;AAAA,UACN,SAAS;AAAA,YACP,SAAS;AAAA,cACP,SAAS;AAAA,gBACP,SAAS;AAAA,cACX;AAAA,YACF;AAAA,UACF;AAAA,QACF;AAAA,QACA,oBAAoB;AAAA,UAClB,MAAM;AAAA,UACN,SAAS;AAAA,YACP,eAAe;AAAA,cACb,SAAS;AAAA,gBACP,SAAS;AAAA,kBACP,SAAS;AAAA,oBACP,SAAS;AAAA,kBACX;AAAA,gBACF;AAAA,cACF;AAAA,YACF;AAAA,UACF;AAAA,QACF;AAAA,MACF;AAAA,IACF,CAAC;AAED,QAAI,CAAC,OAAO;AACV,cAAQ,KAAK,SAAS,OAAO,YAAY;AACzC,aAAO;AAAA,IACT;AAIA,UAAM,WAAW,KAAyB;AAC1C,WAAO;AAAA,EACT,SAAS,OAAO;AACd,YAAQ,MAAM,wBAAwB,OAAO,KAAK,KAAK;AACvD,WAAO;AAAA,EACT;AACF;;;AChQA,IAAAC,iBAA6B;AAG7B,IAAMC,UAAS,IAAI,4BAAa;AAehC,eAAsB,eAAe,WAAgD;AACnF,QAAM,SAAS,uBAAuB;AACtC,MAAI,CAAC,QAAQ;AACX,UAAM,IAAI,MAAM,oCAAoC;AAAA,EACtD;AAEA,QAAM,oBAAoB;AAAA,IACxB,UAAU;AAAA,IACV,UAAU,OAAO,oBAAoB,UAAU,IAAI,IAAI;AAAA,IACvD,UAAU,OAAO,oBAAoB,UAAU,IAAI,IAAI;AAAA,EACzD,EAAE,KAAK,GAAG;AAGV,QAAM,WAAW;AAAA,IACf,IAAI,UAAU;AAAA,IACd,WAAW,UAAU;AAAA,IACrB,aAAa,UAAU,QAAQ;AAAA,IAC/B,gBAAgB,UAAU,QAAQ;AAAA,IAClC,MAAM,UAAU;AAAA,IAChB,MAAM,UAAU;AAAA,IAChB,MAAM,UAAU;AAAA,IAChB,iBAAiB,UAAU;AAAA,IAC3B,mBAAmB,UAAU,cAAc;AAAA,IAC3C,mBAAmB,UAAU,cAAc,MAAM;AAAA,IACjD,UAAU,UAAU;AAAA,IACpB,YAAY,UAAU,QAAQ;AAAA,IAC9B,aAAa,UAAU;AAAA,IACvB,aAAa,UAAU;AAAA,IACvB,WAAW,UAAU;AAAA,IACrB,WAAW,UAAU;AAAA,IACrB,aAAa,UAAU;AAAA,IACvB,eAAe,UAAU,QAAQ;AAAA,IACjC,gBAAgB,UAAU,QAAQ;AAAA,IAClC;AAAA,EACF;AAEA,QAAM,OAAO,MAAM;AAAA,IACjB,OAAO,0CAA6C;AAAA,IACpD,IAAI,UAAU,GAAG,SAAS;AAAA,IAC1B;AAAA,IACA,SAAS;AAAA,EACX,CAAC;AACH;AA4BA,eAAsB,6BAA6B,aAAuC;AACxF,QAAM,SAAS,uBAAuB;AACtC,MAAI,CAAC,QAAQ;AACX,YAAQ,KAAK,oCAAoC;AACjD,WAAO;AAAA,EACT;AAEA,MAAI;AACF,UAAM,YAAY,MAAMC,QAAO,WAAW,WAAW;AAAA,MACnD,OAAO,EAAE,IAAI,YAAY;AAAA,MACzB,SAAS;AAAA,QACP,SAAS;AAAA,QACT,SAAS;AAAA,QACT,eAAe;AAAA,UACb,SAAS;AAAA,YACP,MAAM;AAAA,UACR;AAAA,QACF;AAAA,QACA,QAAQ;AAAA,MACV;AAAA,IACF,CAAC;AAED,QAAI,CAAC,WAAW;AACd,cAAQ,KAAK,aAAa,WAAW,YAAY;AACjD,aAAO;AAAA,IACT;AAKA,UAAM,eAAe,SAAiC;AACtD,WAAO;AAAA,EACT,SAAS,OAAO;AACd,YAAQ,MAAM,4BAA4B,WAAW,KAAK,KAAK;AAC/D,WAAO;AAAA,EACT;AACF;;;AC5HA,IAAAC,iBAA6B;AAG7B,IAAMC,UAAS,IAAI,4BAAa;AAYhC,eAAsB,aAAa,SAA4C;AAC7E,QAAM,SAAS,uBAAuB;AACtC,MAAI,CAAC,QAAQ;AACX,UAAM,IAAI,MAAM,oCAAoC;AAAA,EACtD;AAEA,QAAM,oBAAoB;AAAA,IACxB,QAAQ;AAAA,IACR,QAAQ,OAAO,oBAAoB,QAAQ,IAAI,IAAI;AAAA,IACnD,QAAQ,OAAO,oBAAoB,QAAQ,IAAI,IAAI;AAAA,EACrD,EAAE,KAAK,GAAG;AAEV,QAAM,WAAW;AAAA,IACf,IAAI,QAAQ;AAAA,IACZ,MAAM,QAAQ;AAAA,IACd,SAAS,QAAQ;AAAA,IACjB,MAAM,QAAQ;AAAA,IACd,MAAM,QAAQ;AAAA,IACd,WAAW,QAAQ;AAAA,IACnB,WAAW,QAAQ;AAAA,IACnB,aAAa,QAAQ;AAAA,IACrB,eAAe,QAAQ,QAAQ;AAAA,IAC/B,gBAAgB,QAAQ,QAAQ;AAAA,IAChC;AAAA,EACF;AAEA,QAAM,OAAO,MAAM;AAAA,IACjB,OAAO,sCAA2C;AAAA,IAClD,IAAI,QAAQ,GAAG,SAAS;AAAA,IACxB;AAAA,IACA,SAAS;AAAA,EACX,CAAC;AACH;AA4BA,eAAsB,2BAA2B,WAAqC;AACpF,QAAM,SAAS,uBAAuB;AACtC,MAAI,CAAC,QAAQ;AACX,YAAQ,KAAK,oCAAoC;AACjD,WAAO;AAAA,EACT;AAEA,MAAI;AACF,UAAM,UAAU,MAAMC,QAAO,SAAS,WAAW;AAAA,MAC/C,OAAO,EAAE,IAAI,UAAU;AAAA,MACvB,SAAS;AAAA,QACP,SAAS;AAAA,MACX;AAAA,IACF,CAAC;AAED,QAAI,CAAC,SAAS;AACZ,cAAQ,KAAK,WAAW,SAAS,YAAY;AAC7C,aAAO;AAAA,IACT;AAKA,UAAM,aAAa,OAAO;AAC1B,WAAO;AAAA,EACT,SAAS,OAAO;AACd,YAAQ,MAAM,0BAA0B,SAAS,KAAK,KAAK;AAC3D,WAAO;AAAA,EACT;AACF;;;AZ5FA,IAAI;AACJ,IAAI;AAGJ,SAAS,mBAAmB,aAAqC;AAC/D,QAAM,aAAa,IAAI,4BAAa,EAAE,YAAY,CAAC;AAGnD,QAAM,SAAS,WAAW,SAAS;AAAA,IACjC,OAAO;AAAA,MACL,iBAAiB;AAAA,QACf,MAAM,OAAO,EAAE,MAAM,MAAM,GAAQ;AACjC,gBAAM,SAAS,MAAM,MAAM,IAAI;AAE/B,cAAI,QAAQ,IAAI;AACd,8CAAkC,OAAO,EAAE,EAAE,MAAM,CAAC,UAAe;AACjE,sBAAQ,MAAM,kCAAkC,OAAO,EAAE,sBAAsB,KAAK;AAAA,YACtF,CAAC;AAAA,UACH;AACA,iBAAO;AAAA,QACT;AAAA,QACA,MAAM,OAAO,EAAE,MAAM,MAAM,GAAQ;AACjC,gBAAM,SAAS,MAAM,MAAM,IAAI;AAE/B,cAAI,QAAQ,IAAI;AACd,8CAAkC,OAAO,EAAE,EAAE,MAAM,CAAC,UAAe;AACjE,sBAAQ,MAAM,kCAAkC,OAAO,EAAE,sBAAsB,KAAK;AAAA,YACtF,CAAC;AAAA,UACH;AACA,iBAAO;AAAA,QACT;AAAA,QACA,MAAM,OAAO,EAAE,MAAM,MAAM,GAAQ;AACjC,gBAAM,SAAS,MAAM,MAAM,IAAI;AAE/B,cAAI,QAAQ,IAAI;AACd,8CAAkC,OAAO,EAAE,EAAE,MAAM,CAAC,UAAe;AACjE,sBAAQ,MAAM,kCAAkC,OAAO,EAAE,sBAAsB,KAAK;AAAA,YACtF,CAAC;AAAA,UACH;AACA,iBAAO;AAAA,QACT;AAAA,QACA,MAAM,OAAO,EAAE,MAAM,MAAM,GAAQ;AACjC,gBAAM,SAAS,MAAM,MAAM,IAAI;AAE/B,cAAI,QAAQ,IAAI;AACd,8CAAkC,OAAO,EAAE,EAAE,MAAM,CAAC,UAAe;AACjE,sBAAQ,MAAM,kCAAkC,OAAO,EAAE,mCAAmC,KAAK;AAAA,YACnG,CAAC;AAAA,UACH;AACA,iBAAO;AAAA,QACT;AAAA,MACF;AAAA,MACA,UAAU;AAAA,QACR,MAAM,OAAO,EAAE,MAAM,MAAM,GAAQ;AACjC,gBAAM,SAAS,MAAM,MAAM,IAAI;AAC/B,cAAI,QAAQ,IAAI;AACd,uCAA2B,OAAO,EAAE,EAAE,MAAM,CAAC,UAAe;AAC1D,sBAAQ,MAAM,2BAA2B,OAAO,EAAE,sBAAsB,KAAK;AAAA,YAC/E,CAAC;AAAA,UACH;AACA,iBAAO;AAAA,QACT;AAAA,QACA,MAAM,OAAO,EAAE,MAAM,MAAM,GAAQ;AACjC,gBAAM,SAAS,MAAM,MAAM,IAAI;AAC/B,cAAI,QAAQ,IAAI;AACd,uCAA2B,OAAO,EAAE,EAAE,MAAM,CAAC,UAAe;AAC1D,sBAAQ,MAAM,2BAA2B,OAAO,EAAE,sBAAsB,KAAK;AAAA,YAC/E,CAAC;AAAA,UACH;AACA,iBAAO;AAAA,QACT;AAAA,MACF;AAAA,MACA,UAAU;AAAA,QACR,MAAM,OAAO,EAAE,MAAM,MAAM,GAAQ;AACjC,gBAAM,SAAS,MAAM,MAAM,IAAI;AAC/B,cAAI,QAAQ,IAAI;AACd,uCAA2B,OAAO,EAAE,EAAE,MAAM,CAAC,UAAe;AAC1D,sBAAQ,MAAM,0BAA0B,OAAO,EAAE,sBAAsB,KAAK;AAAA,YAC9E,CAAC;AAAA,UACH;AACA,iBAAO;AAAA,QACT;AAAA,QACA,MAAM,OAAO,EAAE,MAAM,MAAM,GAAQ;AACjC,gBAAM,SAAS,MAAM,MAAM,IAAI;AAC/B,cAAI,QAAQ,IAAI;AACd,uCAA2B,OAAO,EAAE,EAAE,MAAM,CAAC,UAAe;AAC1D,sBAAQ,MAAM,0BAA0B,OAAO,EAAE,sBAAsB,KAAK;AAAA,YAC9E,CAAC;AAAA,UACH;AACA,iBAAO;AAAA,QACT;AAAA,QACA,MAAM,OAAO,EAAE,MAAM,MAAM,GAAQ;AACjC,gBAAM,SAAS,MAAM,MAAM,IAAI;AAC/B,cAAI,QAAQ,IAAI;AACd,uCAA2B,OAAO,EAAE,EAAE,MAAM,CAAC,UAAe;AAC1D,sBAAQ,MAAM,0BAA0B,OAAO,EAAE,sBAAsB,KAAK;AAAA,YAC9E,CAAC;AAAA,UACH;AACA,iBAAO;AAAA,QACT;AAAA,QACA,MAAM,OAAO,EAAE,MAAM,MAAM,GAAQ;AACjC,gBAAM,SAAS,MAAM,MAAM,IAAI;AAC/B,cAAI,QAAQ,IAAI;AACd,uCAA2B,OAAO,EAAE,EAAE,MAAM,CAAC,UAAe;AAC1D,sBAAQ,MAAM,0BAA0B,OAAO,EAAE,sBAAsB,KAAK;AAAA,YAC9E,CAAC;AAAA,UACH;AACA,iBAAO;AAAA,QACT;AAAA,MACF;AAAA,MACA,kBAAkB;AAAA,QAChB,MAAM,OAAO,EAAE,MAAM,MAAM,GAAQ;AACjC,gBAAM,SAAS,MAAM,MAAM,IAAI;AAC/B,cAAI,QAAQ,IAAI;AACd,0CAA8B,OAAO,EAAE,EAAE,MAAM,CAAC,UAAe;AAC7D,sBAAQ,MAAM,8BAA8B,OAAO,EAAE,sBAAsB,KAAK;AAAA,YAClF,CAAC;AAAA,UACH;AACA,iBAAO;AAAA,QACT;AAAA,QACA,MAAM,OAAO,EAAE,MAAM,MAAM,GAAQ;AACjC,gBAAM,SAAS,MAAM,MAAM,IAAI;AAC/B,cAAI,QAAQ,IAAI;AACd,0CAA8B,OAAO,EAAE,EAAE,MAAM,CAAC,UAAe;AAC7D,sBAAQ,MAAM,8BAA8B,OAAO,EAAE,sBAAsB,KAAK;AAAA,YAClF,CAAC;AAAA,UACH;AACA,iBAAO;AAAA,QACT;AAAA,MACF;AAAA,MACA,QAAQ;AAAA,QACN,MAAM,OAAO,EAAE,MAAM,MAAM,GAAQ;AACjC,gBAAM,SAAS,MAAM,MAAM,IAAI;AAC/B,cAAI,QAAQ,IAAI;AACd,qCAAyB,OAAO,EAAE,EAAE,MAAM,CAAC,UAAe;AACxD,sBAAQ,MAAM,wBAAwB,OAAO,EAAE,sBAAsB,KAAK;AAAA,YAC5E,CAAC;AAAA,UACH;AACA,iBAAO;AAAA,QACT;AAAA,QACA,MAAM,OAAO,EAAE,MAAM,MAAM,GAAQ;AACjC,gBAAM,SAAS,MAAM,MAAM,IAAI;AAC/B,cAAI,QAAQ,IAAI;AACd,qCAAyB,OAAO,EAAE,EAAE,MAAM,CAAC,UAAe;AACxD,sBAAQ,MAAM,wBAAwB,OAAO,EAAE,sBAAsB,KAAK;AAAA,YAC5E,CAAC;AAAA,UACH;AACA,iBAAO;AAAA,QACT;AAAA,MACF;AAAA,MACA,YAAY;AAAA,QACV,MAAM,OAAO,EAAE,MAAM,MAAM,GAAQ;AACjC,gBAAM,SAAS,MAAM,MAAM,IAAI;AAC/B,cAAI,QAAQ,IAAI;AACd,yCAA6B,OAAO,EAAE,EAAE,MAAM,CAAC,UAAe;AAC5D,sBAAQ,MAAM,4BAA4B,OAAO,EAAE,sBAAsB,KAAK;AAAA,YAChF,CAAC;AAAA,UACH;AACA,iBAAO;AAAA,QACT;AAAA,QACA,MAAM,OAAO,EAAE,MAAM,MAAM,GAAQ;AACjC,gBAAM,SAAS,MAAM,MAAM,IAAI;AAC/B,cAAI,QAAQ,IAAI;AACd,yCAA6B,OAAO,EAAE,EAAE,MAAM,CAAC,UAAe;AAC5D,sBAAQ,MAAM,4BAA4B,OAAO,EAAE,sBAAsB,KAAK;AAAA,YAChF,CAAC;AAAA,UACH;AACA,iBAAO;AAAA,QACT;AAAA,MACF;AAAA,MACA,UAAU;AAAA,QACR,MAAM,OAAO,EAAE,MAAM,MAAM,GAAQ;AACjC,gBAAM,SAAS,MAAM,MAAM,IAAI;AAC/B,cAAI,QAAQ,IAAI;AACd,uCAA2B,OAAO,EAAE,EAAE,MAAM,CAAC,UAAe;AAC1D,sBAAQ,MAAM,0BAA0B,OAAO,EAAE,sBAAsB,KAAK;AAAA,YAC9E,CAAC;AAAA,UACH;AACA,iBAAO;AAAA,QACT;AAAA,QACA,MAAM,OAAO,EAAE,MAAM,MAAM,GAAQ;AACjC,gBAAM,SAAS,MAAM,MAAM,IAAI;AAC/B,cAAI,QAAQ,IAAI;AACd,uCAA2B,OAAO,EAAE,EAAE,MAAM,CAAC,UAAe;AAC1D,sBAAQ,MAAM,0BAA0B,OAAO,EAAE,sBAAsB,KAAK;AAAA,YAC9E,CAAC;AAAA,UACH;AACA,iBAAO;AAAA,QACT;AAAA,MACF;AAAA,IACF;AAAA,EACF,CAAC;AAED,SAAO;AACT;AAIA,IAAI,QAAQ,IAAI,aAAa,cAAc;AACzC,iBAAe,mBAAmB,QAAQ;AAC1C,iBAAW,wBAAQ,YAAY;AACjC,OAAO;AAEL,MAAI,CAAC,OAAO,QAAQ;AAClB,WAAO,SAAS,mBAAmB,WAAW;AAC9C,WAAO,SAAK,wBAAQ,OAAO,MAAM;AAAA,EACnC;AACA,iBAAe,OAAO;AACtB,aAAW,OAAO;AACpB;AAEO,IAAMC,UAAS;;;Aa7MtB,eAAsB,6BACpB,kBACA,UAA+C,CAAC,GACH;AAC7C,MAAI,QAAQ,IAAI,gBAAgB;AAC9B,YAAQ;AAAA,MACN,qDAAqD,gBAAgB;AAAA,IACvE;AAAA,EACF;AAEA,MAAI;AAEF,UAAM,eAAe,MAAMC,QAAO,gBAAgB,WAAW;AAAA,MAC3D,OAAO,EAAE,IAAI,iBAAiB;AAAA,MAC9B,QAAQ;AAAA,QACN,IAAI;AAAA,QACJ,QAAQ;AAAA,QACR,WAAW;AAAA,UACT,OAAO,EAAE,MAAM,8BAA8B,WAAW,MAAM;AAAA,UAC9D,QAAQ,EAAE,SAAS,KAAK;AAAA,QAC1B;AAAA,QACA,SAAS;AAAA,UACP,OAAO,EAAE,MAAM,8BAA8B,WAAW,MAAM;AAAA,UAC9D,QAAQ,EAAE,SAAS,KAAK;AAAA,QAC1B;AAAA,MACF;AAAA,IACF,CAAC;AACD,QAAI,CAAC,aAAc,QAAO,EAAE,gBAAgB,CAAC,GAAG,oBAAoB,CAAC,EAAE;AACvE,UAAM,YAAY;AAAA,MAChB,aAAa;AAAA,MACb,GAAG,aAAa,UAAU,IAAI,CAAC,MAAM,EAAE,OAAO;AAAA,MAC9C,GAAG,aAAa,QAAQ,IAAI,CAAC,MAAM,EAAE,OAAO;AAAA,IAC9C;AACA,UAAM,gBAAgB,MAAM,KAAK,IAAI,IAAI,SAAS,CAAC;AACnD,QAAI,QAAQ,IAAI,eAAgB,SAAQ,IAAI,8BAA8B,aAAa;AAGvF,UAAM,WAAW,MAAMA,QAAO,gBAAgB,SAAS;AAAA,MACrD,OAAO,EAAE,IAAI,EAAE,IAAI,cAAc,EAAE;AAAA,MACnC,QAAQ,EAAE,IAAI,MAAM,QAAQ,KAAK;AAAA,IACnC,CAAC;AACD,QAAI,QAAQ,IAAI,eAAgB,SAAQ,IAAI,wBAAwB,QAAQ;AAI5E,UAAM,gBAAgB,SACnB,OAAO,CAAC,MAAM,EAAE,WAAW,QAAQ,EACnC,IAAI,CAAC,MAAM,EAAE,EAAE;AAClB,QAAI,QAAQ,IAAI,eAAgB,SAAQ,IAAI,6BAA6B,aAAa;AACtF,QAAI,gBAA8C,CAAC;AACnD,QAAI,cAAc,QAAQ;AAExB,YAAM,eAAe,MAAMA,QAAO,aAAa,SAAS;AAAA,QACtD,OAAO,EAAE,kBAAkB,EAAE,IAAI,cAAc,EAAE;AAAA,QACjD,QAAQ,EAAE,IAAI,KAAK;AAAA,MACrB,CAAC;AACD,YAAM,iBAAiB,aAAa,IAAI,CAAC,QAAQ,IAAI,EAAE;AAGvD,sBAAgB,eAAe,SAC3B,MAAMA,QAAO,eAAe,SAAS;AAAA,QACnC,OAAO;AAAA,UACL,eAAe,EAAE,IAAI,eAAe;AAAA,UACpC,WAAW;AAAA,UACX,SAAS,EAAE,IAAI,EAAE;AAAA,QACnB;AAAA,QACA,QAAQ,EAAE,SAAS,KAAK;AAAA,MAC1B,CAAC,IACD,CAAC;AAAA,IACP;AACA,QAAI,QAAQ,IAAI,eAAgB,SAAQ,IAAI,6BAA6B,aAAa;AACtF,UAAM,kBAAkB,cACrB,IAAI,CAAC,MAAM,EAAE,OAAO,EACpB,OAAO,CAAC,MAAM,KAAK,IAAI;AAC1B,QAAI,QAAQ,IAAI,eAAgB,SAAQ,IAAI,+BAA+B,eAAe;AAG1F,UAAM,eAAe,SAClB,OAAO,CAAC,MAAM,EAAE,WAAW,OAAO,EAClC,IAAI,CAAC,MAAM,EAAE,EAAE;AAClB,QAAI,QAAQ,IAAI,eAAgB,SAAQ,IAAI,4BAA4B,YAAY;AACpF,UAAM,eAAe,aAAa,SAC9B,MAAMA,QAAO,gBAAgB,SAAS;AAAA,MACpC,OAAO;AAAA,QACL,kBAAkB,EAAE,IAAI,aAAa;AAAA,QACrC,MAAM,EAAE,IAAI,EAAE;AAAA,MAChB;AAAA,MACA,QAAQ,EAAE,MAAM,KAAK;AAAA,IACvB,CAAC,IACD,CAAC;AACL,QAAI,QAAQ,IAAI,eAAgB,SAAQ,IAAI,4BAA4B,YAAY;AACpF,UAAM,iBAAiB,aACpB,IAAI,CAAC,MAAM,EAAE,IAAI,EACjB,OAAO,CAAC,MAAM,KAAK,IAAI;AAC1B,QAAI,QAAQ,IAAI,eAAgB,SAAQ,IAAI,8BAA8B,cAAc;AAGxF,UAAM,YACJ,gBAAgB,SAAS,IACrB,KAAK;AAAA,MACH,gBAAgB,OAAO,CAAC,GAAG,MAAM,IAAI,GAAG,CAAC,IAAI,gBAAgB;AAAA,IAC/D,IACA;AACN,UAAM,WACJ,eAAe,SAAS,IACpB;AAAA,OAEI,eAAe,OAAO,CAAC,GAAG,MAAM,IAAI,GAAG,CAAC,IAAI,eAAe,QAC3D,QAAQ,CAAC;AAAA,IACb,IACA;AACN,QAAI,QAAQ,IAAI,eAAgB,SAAQ,IAAI,yBAAyB,WAAW,aAAa,QAAQ;AAGrG,eAAW,UAAU,eAAe;AAClC,YAAMA,QAAO,gBAAgB,OAAO;AAAA,QAClC,OAAO,EAAE,IAAI,OAAO;AAAA,QACpB,MAAM;AAAA,UACJ,gBAAgB;AAAA,UAChB,mBAAmB;AAAA,QACrB;AAAA,MACF,CAAC;AAAA,IACH;AACA,QAAI,QAAQ,IAAI,gBAAgB;AAC9B,cAAQ;AAAA,QACN,0BAA0B,SAAS,uBAAuB,QAAQ,gBAAgB,cAAc,KAAK,IAAI,CAAC;AAAA,MAC5G;AAAA,IACF;AAGA,UAAM,uBAAuB,MAAMA,QAAO,aAAa,SAAS;AAAA,MAC9D,OAAO;AAAA,QACL,kBAAkB,EAAE,IAAI,cAAc;AAAA,MACxC;AAAA,MACA,QAAQ;AAAA,QACN,WAAW;AAAA,MACb;AAAA,IACF,CAAC;AAED,UAAM,2BAA2B,MAAM;AAAA,MACrC,IAAI,IAAI,qBAAqB,IAAI,CAAC,QAAQ,IAAI,SAAS,CAAC;AAAA,IAC1D;AAGA,QAAI,CAAC,QAAQ,qBAAqB,yBAAyB,SAAS,GAAG;AACrE,iBAAW,aAAa,0BAA0B;AAChD,cAAM,sBAAsB,WAAW;AAAA,UACrC,yBAAyB,IAAI,IAAI,aAAa;AAAA,QAChD,CAAC;AAAA,MACH;AAAA,IACF;AAGA,WAAO;AAAA,MACL,gBAAgB;AAAA,MAChB,oBAAoB,QAAQ,0BAA0B,2BAA2B,CAAC;AAAA,IACpF;AAAA,EACF,SAAS,OAAO;AACd,YAAQ;AAAA,MACN,uDAAuD,gBAAgB;AAAA,MACvE;AAAA,IACF;AACA,UAAM;AAAA,EACR;AACF;AAMA,eAAsB,sBACpB,WACA,UAAwC,CAAC,GAC1B;AACf,MAAI,QAAQ,IAAI,eAAgB,SAAQ,IAAI,qCAAqC,SAAS,EAAE;AAC5F,MAAI;AAEF,QAAI,0BAA0B,MAAMA,QAAO,aAAa,SAAS;AAAA,MAC/D,OAAO,EAAE,UAAqB;AAAA,MAC9B,QAAQ;AAAA,QACN,kBAAkB;AAAA,QAClB,QAAQ;AAAA,UACN,QAAQ;AAAA,YACN,YAAY;AAAA,UACd;AAAA,QACF;AAAA,MACF;AAAA,IACF,CAAC;AAGD,QAAI,wBAAwB,SAAS,GAAG;AACtC,YAAM,mBAAmB,IAAI;AAAA,QAC3B,QAAQ,0BACJ,MAAM,KAAK,QAAQ,uBAAuB,IAC1C,CAAC;AAAA,MACP;AAEA,YAAM,yBAAyB,MAAM;AAAA,QACnC,IAAI,IAAI,wBAAwB,IAAI,CAAC,QAAQ,IAAI,gBAAgB,CAAC;AAAA,MACpE;AAEA,UAAI,mBAAmB;AAEvB,iBAAW,oBAAoB,wBAAwB;AACrD,YAAI,iBAAiB,IAAI,gBAAgB,GAAG;AAC1C;AAAA,QACF;AAEA,cAAM,SAAS,MAAM;AAAA,UACnB;AAAA,UACA,EAAE,mBAAmB,KAAK;AAAA,QAC5B;AAEA,YAAI,OAAO,eAAe,SAAS,GAAG;AACpC,6BAAmB;AACnB,qBAAW,eAAe,OAAO,gBAAgB;AAC/C,6BAAiB,IAAI,WAAW;AAAA,UAClC;AAAA,QACF;AAAA,MACF;AAEA,UAAI,kBAAkB;AAEpB,kCAA0B,MAAMA,QAAO,aAAa,SAAS;AAAA,UAC3D,OAAO,EAAE,UAAqB;AAAA,UAC9B,QAAQ;AAAA,YACN,kBAAkB;AAAA,YAClB,QAAQ;AAAA,cACN,QAAQ;AAAA,gBACN,YAAY;AAAA,cACd;AAAA,YACF;AAAA,UACF;AAAA,QACF,CAAC;AAAA,MACH;AAAA,IACF;AAGA,UAAM,8BAA8B,wBACjC;AAAA,MACC,CAAC,QAAQ,IAAI,WAAW,QAAQ,IAAI,QAAQ,eAAe;AAAA,IAC7D,EACC,IAAI,CAAC,QAAQ,IAAI,gBAAgB;AAEpC,QAAI,CAAC,4BAA4B,QAAQ;AAEvC,YAAMA,QAAO,SAAS,OAAO;AAAA,QAC3B,OAAO,EAAE,IAAI,UAAU;AAAA,QACvB,MAAM;AAAA,UACJ,gBAAgB;AAAA,UAChB,mBAAmB;AAAA,QACrB;AAAA,MACF,CAAC;AACD,UAAI,QAAQ,IAAI,gBAAgB;AAC9B,gBAAQ;AAAA,UACN,qCAAqC,SAAS;AAAA,QAChD;AAAA,MACF;AACA;AAAA,IACF;AAGA,UAAM,kBAAkB,MAAMA,QAAO,gBAAgB,SAAS;AAAA,MAC5D,OAAO,EAAE,IAAI,EAAE,IAAI,4BAA4B,EAAE;AAAA,MACjD,QAAQ,EAAE,gBAAgB,MAAM,mBAAmB,KAAK;AAAA,IAC1D,CAAC;AAGD,QAAI,sBAAsB;AAC1B,QAAI,yBAAyB;AAC7B,QAAI,YAAY;AAChB,QAAI,eAAe;AAEnB,eAAW,MAAM,iBAAiB;AAChC,UAAI,GAAG,mBAAmB,MAAM;AAC9B,+BAAuB,GAAG;AAC1B,oBAAY;AAAA,MACd;AACA,UAAI,GAAG,sBAAsB,MAAM;AACjC,kCAA0B,GAAG;AAC7B,uBAAe;AAAA,MACjB;AAAA,IACF;AAGA,UAAMA,QAAO,SAAS,OAAO;AAAA,MAC3B,OAAO,EAAE,IAAI,UAAU;AAAA,MACvB,MAAM;AAAA,QACJ,gBAAgB,YAAY,sBAAsB;AAAA,QAClD,mBAAmB,eACf,WAAW,uBAAuB,QAAQ,CAAC,CAAC,IAC5C;AAAA,MACN;AAAA,IACF,CAAC;AAED,QAAI,QAAQ,IAAI,gBAAgB;AAC9B,cAAQ;AAAA,QACN,sBAAsB,SAAS,wBAAwB,mBAAmB,uBAAuB,sBAAsB;AAAA,MACzH;AAAA,IACF;AAAA,EACF,SAAS,OAAO;AACd,YAAQ;AAAA,MACN,0CAA0C,SAAS;AAAA,MACnD;AAAA,IACF;AACA,UAAM;AAAA,EACR;AACF;AAiCA,eAAsB,wBAA2C;AAC/D,MAAI,QAAQ,IAAI,eAAgB,SAAQ,IAAI,+CAA+C;AAC3F,MAAI;AACF,UAAM,aAAa;AACnB,UAAM,mBAAmB,oBAAI,IAAY;AACzC,UAAM,wBAAkC,CAAC;AAGzC,UAAM,aAAa,MAAMC,QAAO,gBAAgB,SAAS;AAAA,MACvD,OAAO;AAAA,QACL,WAAW;AAAA,QACX,YAAY;AAAA,MACd;AAAA,MACA,QAAQ;AAAA,QACN,IAAI;AAAA,MACN;AAAA,IACF,CAAC;AAED,UAAM,aAAa,WAAW;AAC9B,QAAI,QAAQ,IAAI,eAAgB,SAAQ,IAAI,cAAc,UAAU,+BAA+B,UAAU,KAAK;AAGlH,aAAS,IAAI,GAAG,IAAI,WAAW,QAAQ,KAAK,YAAY;AACtD,YAAM,WAAW,WAAW,MAAM,GAAG,IAAI,UAAU,EAAE,IAAI,CAAC,MAAM,EAAE,EAAE;AAEpE,YAAM,iBAAiB,MAAMA,QAAO,gBAAgB,SAAS;AAAA,QAC3D,OAAO;AAAA,UACL,IAAI,EAAE,IAAI,SAAS;AAAA,QACrB;AAAA,QACA,QAAQ;AAAA,UACN,IAAI;AAAA,UACJ,WAAW;AAAA,YACT,OAAO,EAAE,MAAM,8BAA8B,WAAW,MAAM;AAAA,YAC9D,QAAQ,EAAE,SAAS,KAAK;AAAA,UAC1B;AAAA,UACA,SAAS;AAAA,YACP,OAAO,EAAE,MAAM,8BAA8B,WAAW,MAAM;AAAA,YAC9D,QAAQ,EAAE,SAAS,KAAK;AAAA,UAC1B;AAAA,QACF;AAAA,MACF,CAAC;AAED,iBAAW,YAAY,gBAAgB;AAErC,YAAI,iBAAiB,IAAI,SAAS,EAAE,GAAG;AACrC;AAAA,QACF;AAGA,8BAAsB,KAAK,SAAS,EAAE;AAGtC,cAAM,YAAY;AAAA,UAChB,SAAS;AAAA,UACT,GAAG,SAAS,UAAU,IAAI,CAAC,MAAM,EAAE,OAAO;AAAA,UAC1C,GAAG,SAAS,QAAQ,IAAI,CAAC,MAAM,EAAE,OAAO;AAAA,QAC1C;AAEA,mBAAW,YAAY,WAAW;AAChC,2BAAiB,IAAI,QAAQ;AAAA,QAC/B;AAAA,MACF;AAEA,UAAI,QAAQ,IAAI,gBAAgB;AAC9B,gBAAQ,IAAI,mBAAmB,KAAK,MAAM,IAAI,UAAU,IAAI,CAAC,IAAI,KAAK,KAAK,aAAa,UAAU,CAAC,KAAK,sBAAsB,MAAM,uBAAuB;AAAA,MAC7J;AAAA,IACF;AAEA,QAAI,QAAQ,IAAI,gBAAgB;AAC9B,cAAQ;AAAA,QACN,SAAS,sBAAsB,MAAM,6BAA6B,UAAU;AAAA,MAC9E;AAAA,IACF;AACA,WAAO;AAAA,EACT,SAAS,OAAO;AACd,YAAQ,MAAM,yCAAyC,KAAK;AAC5D,UAAM;AAAA,EACR;AACF;;;AdlbA,sBAA8B;AAR9B;AAiBO,IAAM,yBAAyB;AAC/B,IAAM,uBAAuB;AAEpC,IAAM,YAAY,OAAO,QAAa;AACpC,UAAQ,IAAI,kBAAkB,IAAI,EAAE,YAAY,IAAI,IAAI,EAAE;AAC1D,MAAI,eAAe;AACnB,MAAI,YAAY;AAEhB,UAAQ,IAAI,MAAM;AAAA,IAChB,KAAK;AACH,YAAM,aAAa,IAAI;AACvB,UAAI,CAAC,cAAc,OAAO,WAAW,qBAAqB,UAAU;AAClE,cAAM,IAAI;AAAA,UACR,wBAAwB,IAAI,EAAE;AAAA,QAChC;AAAA,MACF;AACA,UAAI;AACF,cAAM,6BAA6B,WAAW,gBAAgB;AAC9D,uBAAe;AACf,gBAAQ;AAAA,UACN,OAAO,IAAI,EAAE,yCAAyC,WAAW,gBAAgB;AAAA,QACnF;AAAA,MACF,SAAS,OAAO;AACd,oBAAY;AACZ,gBAAQ;AAAA,UACN,OAAO,IAAI,EAAE,oBAAoB,WAAW,gBAAgB;AAAA,UAC5D;AAAA,QACF;AACA,cAAM;AAAA,MACR;AACA;AAAA,IAEF,KAAK;AACH,cAAQ,IAAI,OAAO,IAAI,EAAE,yCAAyC;AAElE,qBAAe;AACf,kBAAY;AAEZ,YAAM,UAAU,MAAM,sBAAsB;AAG5C,YAAM,qBAAqB,oBAAI,IAAY;AAG3C,iBAAW,UAAU,SAAS;AAC5B,YAAI;AACF,gBAAM,SAAS,MAAM,6BAA6B,QAAQ;AAAA,YACxD,mBAAmB;AAAA,YACnB,yBAAyB;AAAA,UAC3B,CAAC;AAGD,qBAAW,aAAa,OAAO,oBAAoB;AACjD,+BAAmB,IAAI,SAAS;AAAA,UAClC;AAEA;AAAA,QACF,SAAS,OAAO;AACd,kBAAQ;AAAA,YACN,OAAO,IAAI,EAAE,wCAAwC,MAAM;AAAA,YAC3D;AAAA,UACF;AACA;AAAA,QAEF;AAAA,MACF;AAEA,cAAQ;AAAA,QACN,OAAO,IAAI,EAAE,eAAe,QAAQ,MAAM,iCAAiC,YAAY,aAAa,SAAS;AAAA,MAC/G;AAGA,cAAQ;AAAA,QACN,OAAO,IAAI,EAAE,eAAe,mBAAmB,IAAI;AAAA,MACrD;AAEA,YAAM,iBAAiB,MAAMC,QAAO,SAAS,SAAS;AAAA,QACpD,OAAO;AAAA,UACL,IAAI,EAAE,IAAI,MAAM,KAAK,kBAAkB,EAAE;AAAA,UACzC,aAAa;AAAA,QACf;AAAA,QACA,QAAQ,EAAE,IAAI,KAAK;AAAA,MACrB,CAAC;AAED,YAAM,mBAAmB,eAAe,IAAI,CAAC,OAAO,GAAG,EAAE;AACzD,YAAM,wBACJ,mBAAmB,OAAO,iBAAiB;AAE7C,cAAQ;AAAA,QACN,OAAO,IAAI,EAAE,cAAc,iBAAiB,MAAM,8BAA8B,qBAAqB;AAAA,MACvG;AACA,UAAI,sBAAsB;AAC1B,UAAI,mBAAmB;AAEvB,iBAAW,aAAa,kBAAkB;AACxC,YAAI;AACF,gBAAM,sBAAsB,SAAS;AACrC;AAAA,QACF,SAAS,OAAO;AACd,kBAAQ;AAAA,YACN,OAAO,IAAI,EAAE,4CAA4C,SAAS;AAAA,YAClE;AAAA,UACF;AACA;AAAA,QACF;AAAA,MACF;AAEA,cAAQ;AAAA,QACN,OAAO,IAAI,EAAE,uBAAuB,mBAAmB,uBAAuB,gBAAgB,aAAa,qBAAqB;AAAA,MAClI;AAEA,UAAI,YAAY,KAAK,mBAAmB,GAAG;AAEzC,gBAAQ;AAAA,UACN,OAAO,IAAI,EAAE,kBAAkB,SAAS,sBAAsB,gBAAgB;AAAA,QAChF;AAAA,MAEF;AACA;AAAA,IAEF;AACE,YAAM,IAAI,MAAM,qBAAqB,IAAI,IAAI,EAAE;AAAA,EACnD;AAEA,SAAO,EAAE,QAAQ,aAAa,cAAc,UAAU;AACxD;AAEA,eAAe,cAAc;AAE3B,MAAI,gBAAkB;AACpB,UAAMC,UAAS,IAAI,sBAAO,qBAAqB,WAAW;AAAA,MACxD,YAAY;AAAA,MACZ,aAAa;AAAA,MACb,SAAS;AAAA,QACP,KAAK;AAAA,QACL,UAAU;AAAA,MACZ;AAAA,IACF,CAAC;AAED,IAAAA,QAAO,GAAG,aAAa,CAAC,KAAK,WAAW;AACtC,cAAQ;AAAA,QACN,eAAe,IAAI,EAAE,KAAK,IAAI,IAAI;AAAA,QAClC;AAAA,MACF;AAAA,IACF,CAAC;AAED,IAAAA,QAAO,GAAG,UAAU,CAAC,KAAK,QAAQ;AAChC,cAAQ;AAAA,QACN,eAAe,KAAK,EAAE,KAAK,KAAK,IAAI;AAAA,QACpC;AAAA,MACF;AAAA,IACF,CAAC;AAED,IAAAA,QAAO,GAAG,SAAS,CAAC,QAAQ;AAC1B,cAAQ,MAAM,gCAAgC,GAAG;AAAA,IACnD,CAAC;AAED,YAAQ,IAAI,mDAAmD;AAG/D,UAAM,WAAW,YAAY;AAC3B,cAAQ,IAAI,kCAAkC;AAC9C,YAAMA,QAAO,MAAM;AACnB,cAAQ,IAAI,uCAAuC;AACnD,cAAQ,KAAK,CAAC;AAAA,IAChB;AAEA,YAAQ,GAAG,WAAW,QAAQ;AAC9B,YAAQ,GAAG,UAAU,QAAQ;AAAA,EAC/B,OAAO;AACL,YAAQ;AAAA,MACN;AAAA,IACF;AACA,YAAQ,KAAK,CAAC;AAAA,EAChB;AACF;AAKA,IACG,OAAO,gBAAgB,eACtB,YAAY,YAAQ,+BAAc,QAAQ,KAAK,CAAC,CAAC,EAAE,QACrD,OAAO,gBAAgB,eACtB,YAAoB,QAAQ,QAC7B;AACA,cAAY,EAAE,MAAM,CAAC,QAAQ;AAC3B,YAAQ,MAAM,2BAA2B,GAAG;AAC5C,YAAQ,KAAK,CAAC;AAAA,EAChB,CAAC;AACH;;;Ae/MA,IAAAC,iBAA4B;AAG5B,IAAAC,iBAA6B;AAC7B,IAAAC,mBAA8B;AAJ9B,IAAAC,eAAA;AAMA,IAAMC,UAAS,IAAI,4BAAa;AAkBzB,IAAM,0BAA0B;AAChC,IAAM,iCAAiC;AACvC,IAAM,wBAAwB;AAErC,IAAMC,aAAY,OAAO,QAAa;AACpC,UAAQ,IAAI,+BAA+B,IAAI,EAAE,YAAY,IAAI,IAAI,EAAE;AAEvE,UAAQ,IAAI,MAAM;AAAA,IAChB,KAAK;AACH,YAAM,aAAa,IAAI;AAEvB,UAAI;AAEF,cAAM,kBAAkB,MAAMD,QAAO,gBAAgB,WAAW;AAAA,UAC9D,OAAO,EAAE,QAAQ,WAAW,OAAO;AAAA,QACrC,CAAC;AAGD,cAAM,iBAAiB,MAAMA,QAAO,UAAU,WAAW;AAAA,UACvD,OAAO,EAAE,KAAK,uBAAuB;AAAA,QACvC,CAAC;AAGD,YAAI,mBACF,iBAAiB,oBAAoB;AACvC,YAAI,qBAAqB,cAAc;AACrC,gBAAM,gBAAgB,gBAAgB;AAGtC,6BAAoB,eAAe,eAAe;AAAA,QACpD;AAGA,YAAI,qBAAqB,QAAQ;AAC/B,kBAAQ;AAAA,YACN,kCAAkC,WAAW,MAAM;AAAA,UACrD;AACA;AAAA,QACF;AAGA,cAAM,eAAe,MAAMA,QAAO,aAAa,OAAO;AAAA,UACpD,MAAM;AAAA,YACJ,QAAQ,WAAW;AAAA,YACnB,MAAM,WAAW;AAAA,YACjB,OAAO,WAAW;AAAA,YAClB,SAAS,WAAW;AAAA,YACpB,iBAAiB,WAAW;AAAA,YAC5B,mBAAmB,WAAW;AAAA,YAC9B,MAAM,WAAW;AAAA,UACnB;AAAA,QACF,CAAC;AAGD,YAAI,qBAAqB,0BAA0B;AACjD,gBAAM,YAAY,IAAI,2BAA2B;AAAA,YAC/C,gBAAgB,aAAa;AAAA,YAC7B,QAAQ,WAAW;AAAA,YACnB,WAAW;AAAA,UACb,CAAC;AAAA,QACH;AAEA,gBAAQ;AAAA,UACN,wBAAwB,aAAa,EAAE,aAAa,WAAW,MAAM,cAAc,gBAAgB;AAAA,QACrG;AAAA,MACF,SAAS,OAAO;AACd,gBAAQ,MAAM,kCAAkC,KAAK;AACrD,cAAM;AAAA,MACR;AACA;AAAA,IAEF,KAAK;AACH,YAAM,cAAc,IAAI;AAExB,UAAI;AAEF,cAAM,gBAAgB,MAAMA,QAAO,aAAa,SAAS;AAAA,UACvD,OAAO;AAAA,YACL,QAAQ,YAAY;AAAA,YACpB,QAAQ;AAAA,YACR,WAAW;AAAA,UACb;AAAA,UACA,SAAS,EAAE,WAAW,OAAO;AAAA,QAC/B,CAAC;AAED,gBAAQ;AAAA,UACN,cAAc,cAAc,MAAM,2BAA2B,YAAY,MAAM;AAAA,QACjF;AAAA,MACF,SAAS,OAAO;AACd,gBAAQ,MAAM,yCAAyC,KAAK;AAC5D,cAAM;AAAA,MACR;AACA;AAAA,IAEF,KAAK;AACH,UAAI;AAEF,cAAM,iBAAiB,MAAMA,QAAO,UAAU,WAAW;AAAA,UACvD,OAAO,EAAE,KAAK,uBAAuB;AAAA,QACvC,CAAC;AACD,cAAM,gBAAgB,gBAAgB;AAGtC,cAAM,oBAAoB,eAAe,eAAe;AAGxD,cAAM,QAAQ,MAAMA,QAAO,gBAAgB,SAAS;AAAA,UAClD,OAAO;AAAA,YACL,IAAI;AAAA,cACF,EAAE,kBAAkB,qBAAqB;AAAA,cACzC;AAAA,gBACE,kBAAkB;AAAA,gBAClB,GAAI,sBAAsB,uBACtB,CAAC,IACD,EAAE,IAAI,OAAO;AAAA;AAAA,cACnB;AAAA,YACF;AAAA,UACF;AAAA,UACA,SAAS;AAAA,YACP,MAAM;AAAA,UACR;AAAA,QACF,CAAC;AAED,mBAAW,YAAY,OAAO;AAE5B,gBAAM,YAAY,oBAAI,KAAK;AAC3B,oBAAU,QAAQ,UAAU,QAAQ,IAAI,CAAC;AAEzC,gBAAM,gBAAgB,MAAMA,QAAO,aAAa,SAAS;AAAA,YACvD,OAAO;AAAA,cACL,QAAQ,SAAS;AAAA,cACjB,QAAQ;AAAA,cACR,WAAW;AAAA,cACX,WAAW,EAAE,KAAK,UAAU;AAAA,YAC9B;AAAA,YACA,SAAS,EAAE,WAAW,OAAO;AAAA,UAC/B,CAAC;AAED,cAAI,cAAc,SAAS,GAAG;AAC5B,kBAAM,YAAY,IAAI,qBAAqB;AAAA,cACzC,QAAQ,SAAS;AAAA,cACjB,eAAe,cAAc,IAAI,CAAC,OAAO;AAAA,gBACvC,IAAI,EAAE;AAAA,gBACN,OAAO,EAAE;AAAA,gBACT,SAAS,EAAE;AAAA,gBACX,WAAW,EAAE;AAAA,cACf,EAAE;AAAA,YACJ,CAAC;AAAA,UACH;AAAA,QACF;AAEA,gBAAQ,IAAI,8BAA8B,MAAM,MAAM,QAAQ;AAAA,MAChE,SAAS,OAAO;AACd,gBAAQ,MAAM,gCAAgC,KAAK;AACnD,cAAM;AAAA,MACR;AACA;AAAA,IAEF;AACE,YAAM,IAAI,MAAM,qBAAqB,IAAI,IAAI,EAAE;AAAA,EACnD;AACF;AAEA,IAAI,SAAwB;AAG5B,IAAME,eAAc,YAAY;AAC9B,MAAI,gBAAkB;AACpB,aAAS,IAAI,sBAAO,yBAAyBD,YAAW;AAAA,MACtD,YAAY;AAAA,MACZ,aAAa;AAAA,IACf,CAAC;AAED,WAAO,GAAG,aAAa,CAAC,QAAQ;AAC9B,cAAQ,IAAI,OAAO,IAAI,EAAE,0BAA0B;AAAA,IACrD,CAAC;AAED,WAAO,GAAG,UAAU,CAAC,KAAK,QAAQ;AAChC,cAAQ,MAAM,OAAO,KAAK,EAAE,YAAY,GAAG;AAAA,IAC7C,CAAC;AAED,WAAO,GAAG,SAAS,CAAC,QAAQ;AAC1B,cAAQ,MAAM,iBAAiB,GAAG;AAAA,IACpC,CAAC;AAED,YAAQ;AAAA,MACN,0CAA0C,uBAAuB;AAAA,IACnE;AAAA,EACF,OAAO;AACL,YAAQ;AAAA,MACN;AAAA,IACF;AAAA,EACF;AAGA,UAAQ,GAAG,UAAU,YAAY;AAC/B,YAAQ,IAAI,sCAAsC;AAClD,QAAI,QAAQ;AACV,YAAM,OAAO,MAAM;AAAA,IACrB;AACA,UAAMD,QAAO,YAAY;AACzB,YAAQ,KAAK,CAAC;AAAA,EAChB,CAAC;AACH;AAGA,IACG,OAAOD,iBAAgB,eACtBA,aAAY,YAAQ,gCAAc,QAAQ,KAAK,CAAC,CAAC,EAAE,SACpD,OAAOA,iBAAgB,eACrBA,aAAoB,QAAQ,SAC/B;AACA,UAAQ,IAAI,gCAAgC;AAC5C,EAAAG,aAAY,EAAE,MAAM,CAAC,QAAQ;AAC3B,YAAQ,MAAM,wCAAwC,GAAG;AACzD,YAAQ,KAAK,CAAC;AAAA,EAChB,CAAC;AACH;;;AC1OA,IAAM,0BAA0B;AAChC,IAAM,0BAA0B;AAEhC,eAAe,eAAe;AAC5B,UAAQ,IAAI,gCAAgC;AAE5C,MAAI,CAAC,iBAAiB,CAAC,mBAAmB;AACxC,YAAQ,MAAM,4DAA4D;AAC1E,YAAQ,KAAK,CAAC;AAAA,EAChB;AAEA,MAAI;AAEF,UAAM,iBAAiB,MAAM,cAAc,kBAAkB;AAC7D,QAAI,eAAe;AACnB,eAAW,OAAO,gBAAgB;AAEhC,UAAI,IAAI,SAAS,sBAAsB;AACrC,gBAAQ;AAAA,UACN,qCAAqC,IAAI,IAAI,eAAe,IAAI,GAAG;AAAA,QACrE;AACA,cAAM,cAAc,sBAAsB,IAAI,GAAG;AACjD;AAAA,MACF;AAAA,IACF;AACA,QAAI,eAAe,GAAG;AACpB,cAAQ,IAAI,WAAW,YAAY,gCAAgC;AAAA,IACrE;AAGA,UAAM,cAAc;AAAA,MAClB;AAAA;AAAA,MACA,CAAC;AAAA;AAAA,MACD;AAAA,QACE,QAAQ;AAAA;AAAA;AAAA,UAGN,SAAS;AAAA;AAAA,QAEX;AAAA,QACA,OAAO;AAAA;AAAA,MACT;AAAA,IACF;AAEA,YAAQ;AAAA,MACN,0CAA0C,oBAAoB,mBAAmB,uBAAuB,eAAe,mBAAmB;AAAA,IAC5I;AAGA,UAAM,6BACJ,MAAM,kBAAkB,kBAAkB;AAC5C,QAAI,2BAA2B;AAC/B,eAAW,OAAO,4BAA4B;AAC5C,UAAI,IAAI,SAAS,uBAAuB;AACtC,gBAAQ;AAAA,UACN,qCAAqC,IAAI,IAAI,eAAe,IAAI,GAAG;AAAA,QACrE;AACA,cAAM,kBAAkB,sBAAsB,IAAI,GAAG;AACrD;AAAA,MACF;AAAA,IACF;AACA,QAAI,2BAA2B,GAAG;AAChC,cAAQ;AAAA,QACN,WAAW,wBAAwB;AAAA,MACrC;AAAA,IACF;AAGA,UAAM,kBAAkB;AAAA,MACtB;AAAA,MACA,CAAC;AAAA,MACD;AAAA,QACE,QAAQ;AAAA,UACN,SAAS;AAAA,QACX;AAAA,QACA,OAAO;AAAA,MACT;AAAA,IACF;AAEA,YAAQ;AAAA,MACN,0CAA0C,qBAAqB,mBAAmB,uBAAuB,eAAe,uBAAuB;AAAA,IACjJ;AAAA,EACF,SAAS,OAAO;AACd,YAAQ,MAAM,0BAA0B,KAAK;AAC7C,YAAQ,KAAK,CAAC;AAAA,EAChB;AACF;AAGA,aAAa,EACV,KAAK,MAAM;AACV,UAAQ,IAAI,0CAA0C;AAItD,UAAQ,KAAK,CAAC;AAChB,CAAC,EACA,MAAM,CAAC,QAAQ;AACd,UAAQ,MAAM,0CAA0C,GAAG;AAC3D,UAAQ,KAAK,CAAC;AAChB,CAAC;",
  "names": ["IORedis", "import_bullmq", "import_client", "import_client", "prisma", "prisma", "import_client", "prisma", "prisma", "import_client", "prisma", "import_client", "prisma", "prisma", "import_client", "prisma", "prisma", "import_client", "prisma", "prisma", "prisma", "prisma", "prisma", "prisma", "worker", "import_bullmq", "import_client", "import_node_url", "import_meta", "prisma", "processor", "startWorker"]
}
